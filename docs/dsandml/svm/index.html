<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rafiq Islam">
<meta name="dcterms.date" content="2024-11-05">

<title>Support Vector Machine (SVM) Algorithm – Mohammad Rafiqul Islam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//_assets/images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-listing/list.min.js"></script>
<script src="../../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-image','listing-date','listing-title','listing-author','listing-reading-time',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      page: 18,
    pagination: { item: "<li class='page-item'><a class='page page-link' href='#'></a></li>" },
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description","listing-categories"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z5NP67GHFC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Z5NP67GHFC', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6878992848042528" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Support Vector Machine (SVM) Algorithm – Mohammad Rafiqul Islam">
<meta property="og:description" content="">
<meta property="og:image" content="https://mrislambd.github.io/dsandml/svm/svm.png">
<meta property="og:site_name" content="Mohammad Rafiqul Islam">
<meta property="og:image:height" content="384">
<meta property="og:image:width" content="758">
<meta name="twitter:title" content="Support Vector Machine (SVM) Algorithm – Mohammad Rafiqul Islam">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mrislambd.github.io/dsandml/svm/svm.png">
<meta name="twitter:image-height" content="384">
<meta name="twitter:image-width" content="758">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../dsandml/svm/index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../_assets/images/fsu-logo.png" alt="Florida State University" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../dsandml/svm/index.html">
    <span class="navbar-title">Mohammad Rafiqul Islam</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html"> 
<span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-blog" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Blog</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-blog">    
        <li>
    <a class="dropdown-item" href="../../posts/machinelearning/index.html">
 <span class="dropdown-text">Data Science and Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/jobandintern/index.html">
 <span class="dropdown-text">Job and Intern</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../blog.html">
 <span class="dropdown-text">All Other Blogs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mohammad-rafiqul-islam/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mrislambd" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-mathematical-foundation-of-svm" id="toc-the-mathematical-foundation-of-svm" class="nav-link" data-scroll-target="#the-mathematical-foundation-of-svm">The Mathematical Foundation of SVM</a>
  <ul>
  <li><a href="#hyperplane-and-dicision-boundary" id="toc-hyperplane-and-dicision-boundary" class="nav-link" data-scroll-target="#hyperplane-and-dicision-boundary">Hyperplane and Dicision Boundary</a></li>
  <li><a href="#margin-and-the-optimal-hyperplane" id="toc-margin-and-the-optimal-hyperplane" class="nav-link" data-scroll-target="#margin-and-the-optimal-hyperplane">Margin and the Optimal Hyperplane</a></li>
  <li><a href="#optimization-of-the-svm" id="toc-optimization-of-the-svm" class="nav-link" data-scroll-target="#optimization-of-the-svm">Optimization of the SVM</a></li>
  <li><a href="#the-dual-form-of-svm" id="toc-the-dual-form-of-svm" class="nav-link" data-scroll-target="#the-dual-form-of-svm">The Dual Form of SVM</a></li>
  </ul></li>
  <li><a href="#nonlinear-support-vector-machines" id="toc-nonlinear-support-vector-machines" class="nav-link" data-scroll-target="#nonlinear-support-vector-machines">Nonlinear Support Vector Machines</a>
  <ul>
  <li><a href="#the-kernel-trick" id="toc-the-kernel-trick" class="nav-link" data-scroll-target="#the-kernel-trick">The Kernel Trick</a>
  <ul class="collapse">
  <li><a href="#polynomial-kernel" id="toc-polynomial-kernel" class="nav-link" data-scroll-target="#polynomial-kernel">Polynomial Kernel</a></li>
  <li><a href="#radial-basis-function-rbf-kernel-gaussian-kernel" id="toc-radial-basis-function-rbf-kernel-gaussian-kernel" class="nav-link" data-scroll-target="#radial-basis-function-rbf-kernel-gaussian-kernel">Radial Basis Function (RBF) Kernel (Gaussian Kernel)</a></li>
  <li><a href="#sigmoid-kernel" id="toc-sigmoid-kernel" class="nav-link" data-scroll-target="#sigmoid-kernel">Sigmoid Kernel</a></li>
  </ul></li>
  <li><a href="#dual-formulation-with-the-kernel-trick" id="toc-dual-formulation-with-the-kernel-trick" class="nav-link" data-scroll-target="#dual-formulation-with-the-kernel-trick">Dual Formulation with the Kernel Trick</a></li>
  <li><a href="#decision-function-with-the-kernel-trick" id="toc-decision-function-with-the-kernel-trick" class="nav-link" data-scroll-target="#decision-function-with-the-kernel-trick">Decision Function with the Kernel Trick</a></li>
  <li><a href="#soft-margin-svm" id="toc-soft-margin-svm" class="nav-link" data-scroll-target="#soft-margin-svm">Soft Margin SVM</a></li>
  </ul></li>
  <li><a href="#python-implementation-of-svm" id="toc-python-implementation-of-svm" class="nav-link" data-scroll-target="#python-implementation-of-svm">Python Implementation of SVM</a>
  <ul>
  <li><a href="#linearsvc" id="toc-linearsvc" class="nav-link" data-scroll-target="#linearsvc">LinearSVC</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a>
  <ul>
  <li><a href="#books" id="toc-books" class="nav-link" data-scroll-target="#books">Books</a></li>
  <li><a href="#lecture-notes" id="toc-lecture-notes" class="nav-link" data-scroll-target="#lecture-notes">Lecture Notes</a></li>
  <li><a href="#journals-and-articles" id="toc-journals-and-articles" class="nav-link" data-scroll-target="#journals-and-articles">Journals and Articles</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.ipynb" download="index.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></li><li><a href="index.epub"><i class="bi bi-file"></i>ePub</a></li><li><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    <h5 class="quarto-listing-category-title">Categories</h5><div class="quarto-listing-category category-default"><div class="category" data-category="">All <span class="quarto-category-count">(64)</span></div><div class="category" data-category="Algorithms">Algorithms <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Artificial Intelligence">Artificial Intelligence <span class="quarto-category-count">(18)</span></div><div class="category" data-category="Bayesian Inference">Bayesian Inference <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Bayesian Statistics">Bayesian Statistics <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Data Engineering">Data Engineering <span class="quarto-category-count">(8)</span></div><div class="category" data-category="Data Science">Data Science <span class="quarto-category-count">(20)</span></div><div class="category" data-category="Machine Learning">Machine Learning <span class="quarto-category-count">(20)</span></div><div class="category" data-category="Programming">Programming <span class="quarto-category-count">(1)</span></div><div class="category" data-category="PyTorch">PyTorch <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Python">Python <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Statistics">Statistics <span class="quarto-category-count">(3)</span></div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Support Vector Machine (SVM) Algorithm</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Statistics</div>
    <div class="quarto-category">Data Science</div>
    <div class="quarto-category">Data Engineering</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Artificial Intelligence</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rafiq Islam </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 5, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Support Vector Machines (SVM) is a powerful non-parametric supervised machine learning algorithm used for classification and, less commonly, regression tasks. Support Vector Machines are designed to find an optimal hyperplane that best separates data points into classes. The key idea behind SVMs is to maximize the margin between data points of different classes while minimizing classification errors. This leads to a robust decision boundary that generalizes well to unseen data.
</p>
</section>
<section id="the-mathematical-foundation-of-svm" class="level2">
<h2 class="anchored" data-anchor-id="the-mathematical-foundation-of-svm">The Mathematical Foundation of SVM</h2>
<p style="text-align:justify">
Consider a classification problem. Given a dataset <span class="math inline">\((\mathbf{x}_i, y_i)\)</span> where <span class="math inline">\(i = 1, 2, \dots, N\)</span>, <span class="math inline">\(x_i\in \mathbb{R}^d\)</span> represents the feature vector of the <span class="math inline">\(i\)</span>-th sample, and <span class="math inline">\(y_i \in \{-1, 1\}\)</span> represents the class label. The goal of SVM is to find a hyperplane that maximally separates the classes.
</p>
<section id="hyperplane-and-dicision-boundary" class="level3">
<h3 class="anchored" data-anchor-id="hyperplane-and-dicision-boundary">Hyperplane and Dicision Boundary</h3>
<dl>
<dt>Definition (Hyperplane)</dt>
<dd>
A hyperplane in an <span class="math inline">\(n\)</span>-dimensional space is defined by: <span class="math display">\[
w^T \mathbf{x} + b = 0
\]</span>
</dd>
</dl>
<p>where:</p>
<ul>
<li><span class="math inline">\(w\)</span> is the weight vector,</li>
<li><span class="math inline">\(b\)</span> is the bias term,</li>
<li><span class="math inline">\(x\)</span> is any point on the hyperplane.</li>
</ul>
<p>For a two-dimensional space, this hyperplane is simply a line. <span class="math display">\[
w^T\mathbf{x}+b=0;\hspace{4mm}\implies w_0x+w_1y+b=0;\hspace{4mm}\implies y=\frac{-w_0x-b}{w_1}
\]</span></p>
<p>and for a three-dimensional space, this hyperplane is simply a 2D plane</p>
<p><span class="math display">\[
w^T\mathbf{x}+b=0;\hspace{4mm}\implies w_0x+w_1y+w_2z+b=0;\hspace{4mm}\implies z=\frac{-w_0x-w_1y-b}{w_2}
\]</span></p>
<div id="f1344194" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>w_2d <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>b_2d <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>w_3d <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>b_3d <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decision_boundary_2d(x):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>w_2d[<span class="dv">0</span>]<span class="op">*</span>x<span class="op">-</span>b_2d) <span class="op">/</span> w_2d[<span class="dv">1</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decision_boundary_3d(x, y):</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>w_3d[<span class="dv">0</span>]<span class="op">*</span>x<span class="op">-</span>w_3d[<span class="dv">1</span>]<span class="op">*</span>y<span class="op">-</span>b_3d) <span class="op">/</span> w_3d[<span class="dv">2</span>]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>class1x_2d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">2</span>))</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>class2x_2d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">2</span>))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>class1x_3d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">90</span>,<span class="dv">3</span>))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>class2x_3d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">90</span>,<span class="dv">3</span>))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure( figsize<span class="op">=</span>(<span class="fl">7.9</span>,<span class="dv">4</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>x_vals_2d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">100</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    x_vals_2d, decision_boundary_2d(x_vals_2d),</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'k-'</span>, label <span class="op">=</span> <span class="st">"Decision Boundary (Hyperplane)"</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>ax1.scatter(</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    class1x_2d[:,<span class="dv">0</span>], class1x_2d[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'o'</span>, label <span class="op">=</span> <span class="st">'Class +1'</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>ax1.scatter(</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    class2x_2d[:,<span class="dv">0</span>], class2x_2d[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>,</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'o'</span>, label <span class="op">=</span> <span class="st">'Class -1'</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Hyperplane (a line) in 2D Space'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>ax1.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>ax1.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>x_vals_3d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">30</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>y_vals_3d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">30</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x_vals_3d, y_vals_3d)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> decision_boundary_3d(X, Y)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>ax2.plot_surface(X, Y, Z, color<span class="op">=</span><span class="st">'k'</span>, alpha <span class="op">=</span> <span class="fl">0.3</span>, rstride<span class="op">=</span><span class="dv">100</span>, cstride<span class="op">=</span><span class="dv">100</span>, edgecolor<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>ax2.scatter(class1x_3d[:,<span class="dv">0</span>], class1x_3d[:,<span class="dv">1</span>],class1x_3d[:,<span class="dv">2</span>], color <span class="op">=</span> <span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Class +1'</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>ax2.scatter(class2x_3d[:,<span class="dv">0</span>], class2x_3d[:,<span class="dv">1</span>],class2x_3d[:,<span class="dv">2</span>], color <span class="op">=</span> <span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Class -1'</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'X'</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Y'</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>ax2.set_zlabel(<span class="st">'Z'</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Hyperplane (a 2D plate) in 3D Space'</span>)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1,ax2]</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/cell-2-output-1.png" width="745" height="374" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="margin-and-the-optimal-hyperplane" class="level3">
<h3 class="anchored" data-anchor-id="margin-and-the-optimal-hyperplane">Margin and the Optimal Hyperplane</h3>
<dl>
<dt>Definition (Margin)</dt>
<dd>
The margin is the distance between the hyperplane and the nearest data points from either class. SVM aims to maximize this margin to achieve better separation, which makes the classifier more robust.
</dd>
</dl>
<p>To define the margin mathematically, we impose that for all points: <span class="math display">\[
y_i (w^T \mathbf{x}_i + b) \geq 1 \quad \forall i
\]</span></p>
<p>For a data vector <span class="math inline">\(\mathbf{x}_i\)</span> with label <span class="math inline">\(y_i\)</span>:</p>
<ul>
<li>If <span class="math inline">\(y_i = +1\)</span>: we want <span class="math inline">\(w^T \mathbf{x}_i + b\ge 1\)</span> (to be on the correct side of the hyperplane)<br>
</li>
<li>If <span class="math inline">\(y_i = -1\)</span>: we want <span class="math inline">\(w^T \mathbf{x}_i + b\le 1\)</span> (to be on the correct side of the hyperplane)</li>
</ul>
<p style="text-align: justify">
These two conditions combaine the equation mention above. That is all points must be at least a unit distance from the hyperplane on the correct side. The data points that satisfy <span class="math inline">\(y_i (w^T x_i + b) = 1\)</span> or <span class="math inline">\(y_i (w^T x_i + b) = -1\)</span> lie on the “support vectors,” or the points closest to the hyperplane.
</p>
<p>We know from the elementary geometry that the distance between two parallel lines <span class="math inline">\(ax+by+c_1=0\)</span> and <span class="math inline">\(ax+by+c_2=0\)</span> is given by</p>
<p><span class="math display">\[
\frac{|c_1-c_2|}{\sqrt{a^2+b^2}}
\]</span></p>
<p>and the distance between two 2D parallel planes <span class="math inline">\(ax+by+cz+d_1=0\)</span> and <span class="math inline">\(ax+by+cz+d_2=0\)</span> in 3D space is given as</p>
<p><span class="math display">\[
\frac{|d_1-d_2|}{\sqrt{a^2+b^2+c^2}}
\]</span></p>
<div id="c5ab1789" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.io <span class="im">as</span> pio</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>pio.renderers</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>z1 <span class="op">=</span> np.array([</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.83</span>,<span class="fl">8.89</span>,<span class="fl">8.81</span>,<span class="fl">8.87</span>,<span class="fl">8.9</span>,<span class="fl">8.87</span>],</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.89</span>,<span class="fl">8.94</span>,<span class="fl">8.85</span>,<span class="fl">8.94</span>,<span class="fl">8.96</span>,<span class="fl">8.92</span>],</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.84</span>,<span class="fl">8.9</span>,<span class="fl">8.82</span>,<span class="fl">8.92</span>,<span class="fl">8.93</span>,<span class="fl">8.91</span>],</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.79</span>,<span class="fl">8.85</span>,<span class="fl">8.79</span>,<span class="fl">8.9</span>,<span class="fl">8.94</span>,<span class="fl">8.92</span>],</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.79</span>,<span class="fl">8.88</span>,<span class="fl">8.81</span>,<span class="fl">8.9</span>,<span class="fl">8.95</span>,<span class="fl">8.92</span>],</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.8</span>,<span class="fl">8.82</span>,<span class="fl">8.78</span>,<span class="fl">8.91</span>,<span class="fl">8.94</span>,<span class="fl">8.92</span>],</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.75</span>,<span class="fl">8.78</span>,<span class="fl">8.77</span>,<span class="fl">8.91</span>,<span class="fl">8.95</span>,<span class="fl">8.92</span>],</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.8</span>,<span class="fl">8.8</span>,<span class="fl">8.77</span>,<span class="fl">8.91</span>,<span class="fl">8.95</span>,<span class="fl">8.94</span>],</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.74</span>,<span class="fl">8.81</span>,<span class="fl">8.76</span>,<span class="fl">8.93</span>,<span class="fl">8.98</span>,<span class="fl">8.99</span>],</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.89</span>,<span class="fl">8.99</span>,<span class="fl">8.92</span>,<span class="fl">9.1</span>,<span class="fl">9.13</span>,<span class="fl">9.11</span>],</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.97</span>,<span class="fl">8.97</span>,<span class="fl">8.91</span>,<span class="fl">9.09</span>,<span class="fl">9.11</span>,<span class="fl">9.11</span>],</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">9.04</span>,<span class="fl">9.08</span>,<span class="fl">9.05</span>,<span class="fl">9.25</span>,<span class="fl">9.28</span>,<span class="fl">9.27</span>],</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">9</span>,<span class="fl">9.01</span>,<span class="dv">9</span>,<span class="fl">9.2</span>,<span class="fl">9.23</span>,<span class="fl">9.2</span>],</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.99</span>,<span class="fl">8.99</span>,<span class="fl">8.98</span>,<span class="fl">9.18</span>,<span class="fl">9.2</span>,<span class="fl">9.19</span>],</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.93</span>,<span class="fl">8.97</span>,<span class="fl">8.97</span>,<span class="fl">9.18</span>,<span class="fl">9.2</span>,<span class="fl">9.18</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>z2 <span class="op">=</span> z1 <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>z3 <span class="op">=</span> z1 <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> go.Figure(data<span class="op">=</span>[</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z1),</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z2, showscale<span class="op">=</span><span class="va">False</span>, opacity<span class="op">=</span><span class="fl">0.9</span>),</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z3, showscale<span class="op">=</span><span class="va">False</span>, opacity<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>fig.update_layout(</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    scene<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        xaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>),</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        yaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>),</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        zaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    paper_bgcolor <span class="op">=</span> <span class="st">'#f4f4f4'</span>,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    title <span class="op">=</span> <span class="st">"Hyperplanes in higher dimension"</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="fce8ad10-9216-427b-ac08-0ff6ab56c836" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("fce8ad10-9216-427b-ac08-0ff6ab56c836")) {                    Plotly.newPlot(                        "fce8ad10-9216-427b-ac08-0ff6ab56c836",                        [{"z":[[8.83,8.89,8.81,8.87,8.9,8.87],[8.89,8.94,8.85,8.94,8.96,8.92],[8.84,8.9,8.82,8.92,8.93,8.91],[8.79,8.85,8.79,8.9,8.94,8.92],[8.79,8.88,8.81,8.9,8.95,8.92],[8.8,8.82,8.78,8.91,8.94,8.92],[8.75,8.78,8.77,8.91,8.95,8.92],[8.8,8.8,8.77,8.91,8.95,8.94],[8.74,8.81,8.76,8.93,8.98,8.99],[8.89,8.99,8.92,9.1,9.13,9.11],[8.97,8.97,8.91,9.09,9.11,9.11],[9.04,9.08,9.05,9.25,9.28,9.27],[9.0,9.01,9.0,9.2,9.23,9.2],[8.99,8.99,8.98,9.18,9.2,9.19],[8.93,8.97,8.97,9.18,9.2,9.18]],"type":"surface"},{"opacity":0.9,"showscale":false,"z":[[9.83,9.89,9.81,9.87,9.9,9.87],[9.89,9.94,9.85,9.94,9.96,9.92],[9.84,9.9,9.82,9.92,9.93,9.91],[9.79,9.85,9.79,9.9,9.94,9.92],[9.79,9.88,9.81,9.9,9.95,9.92],[9.8,9.82,9.78,9.91,9.94,9.92],[9.75,9.78,9.77,9.91,9.95,9.92],[9.8,9.8,9.77,9.91,9.95,9.94],[9.74,9.81,9.76,9.93,9.98,9.99],[9.89,9.99,9.92,10.1,10.13,10.11],[9.97,9.97,9.91,10.09,10.11,10.11],[10.04,10.08,10.05,10.25,10.28,10.27],[10.0,10.01,10.0,10.2,10.23,10.2],[9.99,9.99,9.98,10.18,10.2,10.19],[9.93,9.97,9.97,10.18,10.2,10.18]],"type":"surface"},{"opacity":0.9,"showscale":false,"z":[[7.83,7.890000000000001,7.8100000000000005,7.869999999999999,7.9,7.869999999999999],[7.890000000000001,7.9399999999999995,7.85,7.9399999999999995,7.960000000000001,7.92],[7.84,7.9,7.82,7.92,7.93,7.91],[7.789999999999999,7.85,7.789999999999999,7.9,7.9399999999999995,7.92],[7.789999999999999,7.880000000000001,7.8100000000000005,7.9,7.949999999999999,7.92],[7.800000000000001,7.82,7.779999999999999,7.91,7.9399999999999995,7.92],[7.75,7.779999999999999,7.77,7.91,7.949999999999999,7.92],[7.800000000000001,7.800000000000001,7.77,7.91,7.949999999999999,7.9399999999999995],[7.74,7.8100000000000005,7.76,7.93,7.98,7.99],[7.890000000000001,7.99,7.92,8.1,8.13,8.11],[7.970000000000001,7.970000000000001,7.91,8.09,8.11,8.11],[8.04,8.08,8.05,8.25,8.28,8.27],[8.0,8.01,8.0,8.2,8.23,8.2],[7.99,7.99,7.98,8.18,8.2,8.19],[7.93,7.970000000000001,7.970000000000001,8.18,8.2,8.18]],"type":"surface"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"scene":{"xaxis":{"backgroundcolor":"#f4f4f4"},"yaxis":{"backgroundcolor":"#f4f4f4"},"zaxis":{"backgroundcolor":"#f4f4f4"}},"paper_bgcolor":"#f4f4f4","title":{"text":"Hyperplanes in higher dimension"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('fce8ad10-9216-427b-ac08-0ff6ab56c836');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>For the hyperplanes in higher dimensions, the distance between two parallel hyperplanes <span class="math inline">\(w^T\mathbf{x}+b=1\)</span> and <span class="math inline">\(w^T\mathbf{x}+b=-1\)</span> is given as</p>
<p><span class="math display">\[
\text{Distance: }M= \frac{|1-(-1)|}{\|w\|}=\frac{2}{\|w\|}
\]</span></p>
<p>This distance, <span class="math inline">\(M\)</span> is the margin and our objective is to maximize <span class="math inline">\(M\)</span>, or equivalently, minimize <span class="math inline">\(\|w\|\)</span> subject to the constraints <span class="math inline">\(y_i (w^T x_i + b) \geq 1\)</span>.</p>
</section>
<section id="optimization-of-the-svm" class="level3">
<h3 class="anchored" data-anchor-id="optimization-of-the-svm">Optimization of the SVM</h3>
<p>The optimization problem can be formulated as follows:</p>
<p><strong>Primal Form:</strong> <span class="math display">\[
\min_{w, b} \frac{1}{2} \|w\|^2
\]</span></p>
<p>subject to: <span class="math display">\[
y_i (w^T x_i + b) \geq 1, \quad \forall i
\]</span></p>
<p>This is a convex optimization problem because the objective function <span class="math inline">\(\frac{1}{2} \|w\|^2\)</span> is convex, and the constraints are linear.</p>
</section>
<section id="the-dual-form-of-svm" class="level3">
<h3 class="anchored" data-anchor-id="the-dual-form-of-svm">The Dual Form of SVM</h3>
<p>To solve the optimization problem, it is often more efficient to use the dual form. By introducing Lagrange multipliers <span class="math inline">\(\alpha_i \geq 0\)</span>, we can construct the Lagrangian:</p>
<p><span class="math display">\[
L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^n \alpha_i \left( y_i (w^T x_i + b) - 1 \right)
\]</span></p>
<p>Taking the partial derivatives of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span> and setting them to zero yields:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w} &amp;= w - \sum_{i=1}^n \alpha_i y_i x_i = 0\\
\implies w &amp;= \sum_{i=1}^n \alpha_i y_i x_i\\
\text{ and } &amp;\\
\frac{\partial L}{\partial b} &amp;= -\sum_{i=1}^n \alpha_i y_i = 0\\
\sum_{i=1}^n \alpha_i y_i &amp;= 0
\end{align*}\]</span></p>
<p>This tells us that <span class="math inline">\(w\)</span> can be expressed as a linear combination of the training points <span class="math inline">\(x_i\)</span> with weights given by <span class="math inline">\(\alpha_i y_i\)</span> and the sum of the weighted labels is zero.</p>
<p>Now we substitute <span class="math inline">\(w = \sum_{i=1}^n \alpha_i y_i x_i\)</span> back into the Lagrangian <span class="math inline">\(L(w, b, \alpha)\)</span>. The primal objective function <span class="math inline">\(\frac{1}{2} \|w\|^2\)</span> becomes:</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{2} \|w\|^2 &amp;= \frac{1}{2} \left( \sum_{i=1}^n \alpha_i y_i x_i \right)^T \left( \sum_{j=1}^n \alpha_j y_j x_j \right)\\
&amp;= \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j
\end{align*}\]</span></p>
<p>Substituting back into the Lagrangian,</p>
<p><span class="math display">\[
L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^n \alpha_i  y_i (w^T x_i + b) + \sum_{i=1}^n \alpha_i
\]</span></p>
<p>we get the dual form as:</p>
<p><span class="math display">\[
\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j
\]</span></p>
<p>subject to:</p>
<p><span class="math display">\[
\alpha_i \geq 0 \quad \forall i, \quad \text{and} \quad \sum_{i=1}^n \alpha_i y_i = 0
\]</span></p>
<p>The solution to the dual form gives the values of <span class="math inline">\(\alpha_i\)</span>, which are used to construct the optimal hyperplane. The final decision boundary is then:</p>
<p><span class="math display">\[
f(x) = \text{sign} \left( \sum_{i=1}^N \alpha_i y_i x_i^T x + b \right)
\]</span></p>
</section>
</section>
<section id="nonlinear-support-vector-machines" class="level2">
<h2 class="anchored" data-anchor-id="nonlinear-support-vector-machines">Nonlinear Support Vector Machines</h2>
<p>Imagine we have a dataset that looks like this.</p>
<div id="b16abb23" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">300</span>, noise<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">0</span>][:,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>][:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>][:,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>][:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/cell-4-output-1.png" width="674" height="503" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p style="text-align: justify">
There is now way that a linear hyperplane seperates the data. Therefore, when the data is not linearly separable, SVMs use the <strong>kernel trick</strong> to map the data into a higher-dimensional space where a linear separation is possible. The idea is to map the original data points <span class="math inline">\(\mathbf{x}\)</span> from the input space to a higher-dimensional feature space using a *feature transformation function <span class="math inline">\(\phi(x)\)</span>.
</p>
<p>For example,</p>
<p><span class="math display">\[
\phi: \mathbb{R}^n\mapsto \mathbb{R}^m, \hspace{4mm} \text{where } m&gt;n
\]</span></p>
<p style="text-align: justify">
In the higher-dimensional space, it’s often easier to find a hyperplane that separates the two classes linearly.<br> <br> However, explicitly calculating and working with this higher-dimensional transformation <span class="math inline">\(\phi(x)\)</span> can be computationally expensive, especially when the dimensionality <span class="math inline">\(m\)</span> is very high or infinite. This is where the <strong>kernel trick</strong> comes in.
</p>
<section id="the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="the-kernel-trick">The Kernel Trick</h3>
<p style="text-align: justify">
The <strong>kernel trick</strong> is a method that allows us to compute the inner product between two transformed data points <span class="math inline">\(\phi(x_i)\)</span> and <span class="math inline">\(\phi(x_j)\)</span> in the higher-dimensional space <strong>without</strong> explicitly computing the transformation <span class="math inline">\(\phi(x)\)</span>.<br> <br> Instead of computing <span class="math inline">\(\phi(x_i)\)</span> and <span class="math inline">\(\phi(x_j)\)</span> separately and then taking their inner product, we define a <strong>kernel function</strong> <span class="math inline">\(K(x_i, x_j)\)</span> that directly computes this inner product in the higher-dimensional space:
</p>
<p><span class="math display">\[
K(x_i, x_j) = \phi(x_i)^T \phi(x_j)
\]</span></p>
<p style="text-align: justify">
By substituting this kernel function into the SVM optimization problem, we can work in the higher-dimensional space implicitly, without ever explicitly mapping the data points to that space. This allows us to handle complex, nonlinear decision boundaries with a more computationally efficient approach.
</p>
<section id="polynomial-kernel" class="level4">
<h4 class="anchored" data-anchor-id="polynomial-kernel">Polynomial Kernel</h4>
<p>The polynomial kernel allows us to model nonlinear decision boundaries using polynomial functions. It is defined as:</p>
<p><span class="math display">\[
K(x_i, x_j) = (x_i^T x_j + c)^d
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(c\)</span> is a constant that controls the influence of higher-order terms.</li>
<li><span class="math inline">\(d\)</span> is the degree of the polynomial.</li>
</ul>
<p style="text-align: justify">
The polynomial kernel creates a feature space that corresponds to all monomials up to degree <span class="math inline">\(d\)</span>. It can model interactions between features, allowing the SVM to classify data with polynomial decision boundaries.
</p>
<p>For example, when we have 1-D data and it is linearly inseperable, we can use polynomial kernel with degree 2 or higher. Say <span class="math inline">\(c=1/2\)</span> and <span class="math inline">\(d=2\)</span>,</p>
<p><span class="math display">\[\begin{align*}
K(x_1,x_2)&amp; = \left(x_1x_2+\frac{1}{2}\right)^2\\
&amp; = \left(x_1x_2+\frac{1}{2}\right)\left(x_1x_2+\frac{1}{2}\right)\\
&amp; = x_1^2x_2^2+\frac{1}{2}x_1x_2+\frac{1}{4}\\
&amp; = x_1x_2+x_1^2x_2^2+\frac{1}{4}\\
&amp; = (x_1,x_1^2,\frac{1}{2})\cdot (x_2,x_2^2,\frac{1}{2})
\end{align*}\]</span></p>
<div id="02b43417" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">11</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">14</span>,<span class="dv">24</span>))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>x3 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">27</span>,<span class="dv">37</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [j <span class="cf">for</span> sub <span class="kw">in</span> [x1,x2,x3] <span class="cf">for</span> j <span class="kw">in</span> sub]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="dv">30</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>]<span class="op">*</span><span class="dv">10</span><span class="op">+</span>[<span class="st">'red'</span>]<span class="op">*</span><span class="dv">10</span><span class="op">+</span> [<span class="st">'blue'</span>]<span class="op">*</span><span class="dv">10</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>y_squared <span class="op">=</span> [i<span class="op">**</span><span class="dv">2</span> <span class="cf">for</span> i <span class="kw">in</span> x]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>slope <span class="op">=</span> (<span class="dv">197</span><span class="op">-</span><span class="fl">529.5</span>)<span class="op">/</span>(<span class="dv">14</span><span class="op">-</span><span class="dv">23</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>line_x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">40</span>,<span class="dv">100</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>line_y <span class="op">=</span> slope<span class="op">*</span> (line_x <span class="op">-</span> <span class="dv">14</span>) <span class="op">+</span> <span class="dv">197</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>,<span class="dv">4</span>))</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x,y, c<span class="op">=</span>colors, label<span class="op">=</span><span class="st">'Actual Data in 1D'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="vs">r'$feature$'</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(<span class="dv">0</span>,<span class="dv">40</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>ax1.set_ylim(<span class="op">-</span><span class="dv">50</span>,<span class="dv">50</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x,y, c<span class="op">=</span>colors, label<span class="op">=</span><span class="st">'Actual Data in 1D'</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x,y_squared, c<span class="op">=</span> colors, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Transformed Data in 2D'</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>ax2.plot(line_x,line_y, color<span class="op">=</span><span class="st">'green'</span>,label<span class="op">=</span><span class="st">'1D Hyperplane'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(<span class="dv">0</span>,<span class="dv">40</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(<span class="op">-</span><span class="dv">100</span>,<span class="dv">1400</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="vs">r'$feature$'</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="vs">r'$feature^2$'</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1,ax2]</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/cell-5-output-1.png" width="748" height="373" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>or for a 2D data to 3D transformation along with 2D hyperplane</p>
<div id="c3e3019b" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a dataset that is not linearly separable</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">300</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original dataset</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>, <span class="dv">4</span>))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>ax1.scatter(X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>ax1.scatter(X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Data'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'feature 1'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'feature 2'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply polynomial kernel transformation</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>X_transformed <span class="op">=</span> np.hstack((X, (X[:, <span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> X[:, <span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the transformed dataset in 3D</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>ax2.scatter(X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">2</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>ax2.scatter(X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">2</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'2D to 3D transformed'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>ax2.set_zlabel(<span class="st">'Poly Feature'</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1, ax2]</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/cell-6-output-1.png" width="690" height="376" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="radial-basis-function-rbf-kernel-gaussian-kernel" class="level4">
<h4 class="anchored" data-anchor-id="radial-basis-function-rbf-kernel-gaussian-kernel">Radial Basis Function (RBF) Kernel (Gaussian Kernel)</h4>
<p style="text-align: justify">
The RBF kernel, also known as the Gaussian kernel, is one of the most popular kernels because it can map the data to an infinite-dimensional space, allowing the model to capture highly complex relationships. It’s defined as:
</p>
<p><span class="math display">\[
K(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right)
\]</span></p>
<p>or equivalently:</p>
<p><span class="math display">\[
K(x_i, x_j) = \exp\left(-\gamma \|x_i - x_j\|^2\right)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\|x_i - x_j\|^2\)</span> is the squared Euclidean distance between the points <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>.</li>
<li><span class="math inline">\(\sigma\)</span> (or <span class="math inline">\(\gamma = \frac{1}{2\sigma^2}\)</span>) controls the width of the Gaussian function and, thus, the influence of each training example.</li>
</ul>
<p style="text-align: justify">
The RBF kernel is particularly effective when the relationship between classes is highly nonlinear. It maps each data point to an infinite-dimensional space, allowing the SVM to capture fine-grained patterns.
</p>
</section>
<section id="sigmoid-kernel" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid-kernel">Sigmoid Kernel</h4>
<p>The sigmoid kernel is related to neural networks and is defined as:</p>
<p><span class="math display">\[
K(x_i, x_j) = \tanh(\kappa x_i^T x_j + \theta)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\theta\)</span> are parameters that control the shape of the kernel.</li>
</ul>
<p>This kernel can be interpreted as simulating a neural network with a single hidden layer, where <span class="math inline">\(\tanh\)</span> serves as the activation function.</p>
</section>
</section>
<section id="dual-formulation-with-the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="dual-formulation-with-the-kernel-trick">Dual Formulation with the Kernel Trick</h3>
<p style="text-align: justify">
In the dual form of the SVM optimization problem, we only require the inner products <span class="math inline">\(x_i^T x_j\)</span> between data points. By replacing these inner products with <span class="math inline">\(K(x_i, x_j) = \phi(x_i)^T \phi(x_j)\)</span>, we obtain the dual form of the optimization problem for a kernelized SVM:
</p>
<p><span class="math display">\[
\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(x_i, x_j)
\]</span></p>
<p>subject to:</p>
<p><span class="math display">\[
\alpha_i \geq 0 \quad \forall i, \quad \text{and} \quad \sum_{i=1}^n \alpha_i y_i = 0
\]</span></p>
<p>Using the kernel function <span class="math inline">\(K(x_i, x_j)\)</span>, we can compute the decision boundary in the original space without explicitly mapping to the higher-dimensional space.</p>
</section>
<section id="decision-function-with-the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="decision-function-with-the-kernel-trick">Decision Function with the Kernel Trick</h3>
<p>Once we solve for <span class="math inline">\(\alpha\)</span> and determine the support vectors, the decision function for a new point <span class="math inline">\(x\)</span> becomes:</p>
<p><span class="math display">\[
f(x) = \sum_{i=1}^n \alpha_i y_i K(x_i, x) + b
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\alpha_i\)</span> are the Lagrange multipliers found from the optimization.</li>
<li><span class="math inline">\(y_i\)</span> are the labels of the support vectors.</li>
<li><span class="math inline">\(K(x_i, x)\)</span> is the kernel function that calculates the inner product between the support vector <span class="math inline">\(x_i\)</span> and the new data point <span class="math inline">\(x\)</span>.</li>
</ul>
<p>This decision function allows us to classify new data points by evaluating their relationship with the support vectors in the original input space, using the kernel to measure similarity.</p>
</section>
<section id="soft-margin-svm" class="level3">
<h3 class="anchored" data-anchor-id="soft-margin-svm">Soft Margin SVM</h3>
<p style="text-align: justify">
The concept of <strong>soft margin SVM</strong> extends the hard margin SVM approach to handle cases where data is not perfectly separable. In real-world datasets, it’s often impossible to perfectly separate classes without allowing some misclassification or overlap. Soft margin SVM addresses this by introducing a <strong>margin of tolerance</strong>—it allows some data points to lie within the margin or even on the wrong side of the decision boundary.
</p>
<p>In hard margin SVM, we strictly enforced that: <span class="math display">\[
y_i (w^T x_i + b) \ge 1, \quad \forall i
\]</span></p>
<p>which means that each point is correctly classified and outside the margin.</p>
<p>In soft margin SVM, we introduce <strong>slack variables</strong> <span class="math inline">\(\xi_i\)</span>, which allow some points to violate this constraint. The constraints become: <span class="math display">\[
y_i (w^T x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\xi_i\)</span> measures the degree of misclassification for each data point <span class="math inline">\(x_i\)</span>.</li>
<li>If <span class="math inline">\(\xi_i = 0\)</span>, then <span class="math inline">\(x_i\)</span> lies on or outside the margin (correct classification).</li>
<li>If <span class="math inline">\(0 &lt; \xi_i \le 1\)</span>, then <span class="math inline">\(x_i\)</span> lies within the margin but is still correctly classified.</li>
<li>If <span class="math inline">\(\xi_i &gt; 1\)</span>, then <span class="math inline">\(x_i\)</span> is misclassified.</li>
</ul>
<p style="text-align: justify">
To find the optimal hyperplane with a soft margin, we modify the objective function to include a <strong>penalty</strong> for misclassifications. The goal is to balance maximizing the margin and minimizing the misclassification error. The objective function becomes:
</p>
<p><span class="math display">\[
\min_{w, b, \xi} \quad \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \xi_i
\]</span></p>
<p>where:</p>
<ul>
<li>The term <span class="math inline">\(\frac{1}{2} \|w\|^2\)</span> encourages a large margin, just as in hard margin SVM.</li>
<li>The term <span class="math inline">\(C \sum_{i=1}^n \xi_i\)</span> penalizes misclassified points, where <span class="math inline">\(C\)</span> is a <strong>regularization parameter</strong> that controls the trade-off between maximizing the margin and minimizing the classification error.</li>
</ul>
<p>The <strong>parameter <span class="math inline">\(C\)</span></strong>:</p>
<ul>
<li>If <span class="math inline">\(C\)</span> is large, the optimization emphasizes minimizing misclassifications (more sensitive to individual data points), which leads to a narrower margin with fewer violations.</li>
<li>If <span class="math inline">\(C\)</span> is small, the optimization focuses more on maximizing the margin, allowing more misclassifications.</li>
</ul>
<p>The optimization problem for soft margin SVM can be written as:</p>
<p><span class="math display">\[
\min_{w, b, \xi} \quad \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \xi_i
\]</span> subject to: <span class="math display">\[
y_i (w^T x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0 \quad \forall i
\]</span></p>
<p>This problem is still convex and can be solved using Lagrange multipliers, though it becomes slightly more complex due to the introduction of slack variables <span class="math inline">\(\xi_i\)</span>.</p>
<p>The dual form of the soft margin SVM, similar to the hard margin case, can be derived using Lagrange multipliers. The dual problem becomes:</p>
<p><span class="math display">\[
\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(x_i, x_j)
\]</span> subject to: <span class="math display">\[
0 \leq \alpha_i \leq C, \quad \sum_{i=1}^n \alpha_i y_i = 0
\]</span></p>
<p>The main difference here is that each <span class="math inline">\(\alpha_i\)</span> is now bounded by <span class="math inline">\(C\)</span> instead of being unrestricted, which introduces a balance between the margin maximization and error tolerance.</p>
<p style="text-align: justify">
In soft margin SVM, the margin is not strict. Some points are allowed to lie within the margin or even be misclassified. Points that lie on the wrong side of the margin are called <strong>support vectors</strong> with non-zero slack values <span class="math inline">\(\xi_i\)</span>.
</p>
<ul>
<li><strong>High <span class="math inline">\(C\)</span></strong>: A larger <span class="math inline">\(C\)</span> results in a narrower margin with fewer violations, meaning fewer points within the margin or misclassified. This leads to a more complex model that might overfit if <span class="math inline">\(C\)</span> is too high.</li>
<li><strong>Low <span class="math inline">\(C\)</span></strong>: A smaller <span class="math inline">\(C\)</span> results in a wider margin with more allowed violations, meaning more tolerance to misclassifications. This generally leads to a simpler, more robust model that might underfit if <span class="math inline">\(C\)</span> is too low.</li>
</ul>
<p style="text-align: justify">
The regularization parameter <span class="math inline">\(C\)</span> controls the trade-off between margin width and classification accuracy. <strong>Cross-validation</strong> is commonly used to select the optimal value of <span class="math inline">\(C\)</span> by evaluating the model’s performance across different values of <span class="math inline">\(C\)</span> and choosing the one that generalizes best to unseen data.
</p>
<div id="41989635" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic dataset</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">40</span>, centers<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.where(y <span class="op">==</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># Transform labels to -1 and +1 for SVM</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Different values of C for comparison</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>C_values <span class="op">=</span> [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">100</span>]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">15</span>))  <span class="co"># Adjust figure size for vertical layout</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)  <span class="co"># Set background color for the figure</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, C <span class="kw">in</span> <span class="bu">enumerate</span>(C_values):</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit SVM model with the given C value</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span>C)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    model.fit(X, y)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mesh to plot decision boundaries</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv">200</span>), np.linspace(y_min, y_max, <span class="dv">200</span>))</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot decision boundary and margin</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> model.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="bu">len</span>(C_values), <span class="dv">1</span>, i <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adjust to create vertical subplots</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)  <span class="co"># Set background color for the plot area</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    plt.contourf(xx, yy, Z, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    plt.contour(xx, yy, Z, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot training points</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">30</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"SVM with Soft Margin (C=</span><span class="sc">{</span>C<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mark support vectors</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    plt.scatter(model.support_vectors_[:, <span class="dv">0</span>], model.support_vectors_[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">100</span>, facecolors<span class="op">=</span><span class="st">'none'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Effect of Regularization Parameter C on Soft Margin SVM"</span>, y<span class="op">=</span><span class="fl">0.96</span>)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.95</span>])</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="index_files/figure-html/cell-7-output-1.png" width="566" height="1387" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="python-implementation-of-svm" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-of-svm">Python Implementation of SVM</h2>
<section id="linearsvc" class="level3">
<h3 class="anchored" data-anchor-id="linearsvc">LinearSVC</h3>
<p>Let’s first create the data</p>
<div id="2bb91c22" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> np.random.random((n_rows,<span class="dv">2</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>X_1 <span class="op">=</span> X1[(X1[:,<span class="dv">1</span>]<span class="op">-</span>X1[:,<span class="dv">0</span>])<span class="op">&lt;=</span> <span class="op">-</span>diff,:]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_2 <span class="op">=</span> X1[(X1[:,<span class="dv">1</span>]<span class="op">-</span>X1[:,<span class="dv">0</span>])<span class="op">&gt;=</span> diff,:]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.append(X_1, X_2, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.empty(np.shape(X)[<span class="dv">0</span>])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>y[(X[:,<span class="dv">1</span>]<span class="op">-</span>X[:,<span class="dv">0</span>])<span class="op">&lt;=</span> <span class="op">-</span>diff] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>y[(X[:,<span class="dv">1</span>]<span class="op">-</span>X[:,<span class="dv">0</span>])<span class="op">&gt;=</span> diff] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="index_files/figure-html/cell-8-output-1.png" width="589" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Now we apply linear SVM classifier</p>
<div id="f52d2d55" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>maximum_margin_SVC <span class="op">=</span> LinearSVC(C<span class="op">=</span> <span class="dv">1000</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, dual<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>maximum_margin_SVC.fit(X,y)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>x1,x2 <span class="op">=</span> np.meshgrid(x1,x2)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>x1x2 <span class="op">=</span> np.vstack([x1.ravel(),x2.ravel()]).T</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> maximum_margin_SVC.decision_function(x1x2).reshape(x1.shape)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">0</span>],X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Training -1'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>],X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Training 1'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.contour(x1,x2,z, colors<span class="op">=</span><span class="st">'k'</span>,levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.7</span>, linestyles<span class="op">=</span>[<span class="st">'--'</span>,<span class="st">'-'</span>,<span class="st">'--'</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="index_files/figure-html/cell-9-output-1.png" width="599" height="434" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The data that we used to explain the polynomial kernels</p>
<div id="a18c7c56" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>np.random.random(<span class="dv">50</span>)<span class="op">-</span><span class="dv">1</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.ones(<span class="bu">len</span>(X))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>y[(X<span class="op">&gt;</span><span class="fl">0.35</span>) <span class="op">|</span> (X<span class="op">&lt;-</span><span class="fl">0.35</span>)] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>svc <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">2</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>svc.fit(X.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>),y)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>],np.ones(<span class="bu">sum</span>(y<span class="op">==-</span><span class="dv">1</span>)), c<span class="op">=</span><span class="st">'blue'</span>,label<span class="op">=</span><span class="st">'class -1'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>],np.ones(<span class="bu">sum</span>(y<span class="op">==</span><span class="dv">1</span>)), c<span class="op">=</span><span class="st">'red'</span>,label<span class="op">=</span><span class="st">'class 1'</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>dcsns <span class="op">=</span> svc.decision_function(np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10000</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10000</span>)[dcsns<span class="op">==</span><span class="dv">0</span>],</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    np.ones(<span class="dv">10000</span>)[dcsns<span class="op">==</span><span class="dv">0</span>],</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'|'</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span> <span class="dv">400</span>,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span><span class="st">'green'</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">'Decision Boundary'</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="index_files/figure-html/cell-10-output-1.png" width="579" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For the higher dimensions</p>
<div id="fac42bd0" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-overflow-wrap code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">300</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create SVM models with polynomial and RBF kernels</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model_poly <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">2</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>model_rbf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="dv">1</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>model_poly.fit(X, y)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>model_rbf.fit(X, y)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mesh to plot decision boundaries</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv">300</span>), np.linspace(y_min, y_max, <span class="dv">300</span>))</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>, <span class="dv">4</span>))</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Polynomial Kernel</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>Z_poly <span class="op">=</span> model_poly.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>Z_poly <span class="op">=</span> Z_poly.reshape(xx.shape)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z_poly, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>plt.contour(xx, yy, Z_poly, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">20</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"SVM with Polynomial Kernel"</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># RBF Kernel</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>Z_rbf <span class="op">=</span> model_rbf.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>Z_rbf <span class="op">=</span> Z_rbf.reshape(xx.shape)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z_rbf, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>plt.contour(xx, yy, Z_rbf, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">20</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"SVM with RBF Kernel"</span>)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Polynomial and RBF Kernels on Nonlinear Data"</span>)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="index_files/figure-html/cell-11-output-1.png" width="748" height="381" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<section id="books" class="level3">
<h3 class="anchored" data-anchor-id="books">Books</h3>
<ul>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd Edition. Springer.<br>
</li>
<li>Boyd, S., &amp; Vandenberghe, L. (2004). <em>Convex Optimization</em>. Cambridge University Press.<br>
</li>
<li>Schölkopf, B., &amp; Smola, A. J. (2002). <em>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</em>. MIT Press.<br>
</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.<br>
</li>
<li>Vapnik, V. (1998). <em>Statistical Learning Theory</em>. Wiley-Interscience.</li>
</ul>
</section>
<section id="lecture-notes" class="level3">
<h3 class="anchored" data-anchor-id="lecture-notes">Lecture Notes</h3>
<ul>
<li>Andrew Ng’s <em>Machine Learning</em> course on Coursera, particularly the lectures on Support Vector Machines, covering linear SVMs, geometric interpretation, and constraints.<br>
</li>
<li>StatQuest with Josh Starmer</li>
<li>Data Science Bootcamp by <em>The Erdos Institute</em></li>
</ul>
</section>
<section id="journals-and-articles" class="level3">
<h3 class="anchored" data-anchor-id="journals-and-articles">Journals and Articles</h3>
<ul>
<li>Cortes, C., &amp; Vapnik, V. (1995). “Support-vector networks.” <em>Machine Learning</em>, 20(3), 273-297.<br>
</li>
<li>Aizerman, M. A., Braverman, E. M., &amp; Rozonoer, L. I. (1964). “Theoretical foundations of the potential function method in pattern recognition learning.” <em>Automation and Remote Control</em>, 25, 821-837.</li>
</ul>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/svm/" data-width="800" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1730179317257" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../dsandml/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1728684641298" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../dsandml/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="../lda/lda.png" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1729137600000" data-listing-file-modified-sort="1730179690185" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="27" data-listing-word-count-sort="5383">
<a href="../../dsandml/lda/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/lda/lda.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Linear Discriminant Analysis (LDA)
</h5>
<div class="listing-reading-time card-text text-muted">
27 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 17, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Support {Vector} {Machine} {(SVM)} {Algorithm}},
  date = {2024-11-05},
  url = {https://mrislambd.github.io/dsandml/svm/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Islam, Rafiq. 2024. <span>“Support Vector Machine (SVM)
Algorithm.”</span> November 5, 2024. <a href="https://mrislambd.github.io/dsandml/svm/">https://mrislambd.github.io/dsandml/svm/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrislambd\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb11" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Support Vector Machine (SVM) Algorithm"</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-11-05"</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Rafiq Islam</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Statistics, Data Science, Data Engineering, Machine Learning, Artificial Intelligence]</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span><span class="co"> true</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="an">search:</span><span class="co"> true</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="an">lightbox:</span><span class="co"> true</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> svm.png</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="an">listing:</span><span class="co"> </span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    contents: "/../../dsandml"</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">    max-items: 3</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    type: grid</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">    categories: true</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">    date-format: full</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    fields: [image, date, title, author, reading-time]</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">    html: default</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">    ipynb: default</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">    docx: </span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">      toc: true</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co">      adsense:</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">        enable-ads: false</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co">    epub:</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">      toc: true</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co">      adsense:</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="co">        enable-ads: false</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co">    pdf: </span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="co">      toc: true</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="co">      pdf-engine: pdflatex</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="co">      adsense:</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="co">        enable-ads: false</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="co">      number-sections: false</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a><span class="co">      colorlinks: true</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="co">      cite-method: biblatex</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 4</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="co">---</span>  </span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction  </span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>Support Vector Machines (SVM) is a powerful non-parametric supervised machine learning algorithm used for classification and, less commonly, regression tasks. Support Vector Machines are designed to find an optimal hyperplane that best separates data points into classes. The key idea behind SVMs is to maximize the margin between data points of different classes while minimizing classification errors. This leads to a robust decision boundary that generalizes well to unseen data.&lt;/p&gt;</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Mathematical Foundation of SVM</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align:justify"&gt;</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>Consider a classification problem. Given a dataset $(\mathbf{x}_i, y_i)$ where $i = 1, 2, \dots, N$, $x_i\in \mathbb{R}^d$ represents the feature vector of the $i$-th sample, and $y_i \in <span class="sc">\{</span>-1, 1<span class="sc">\}</span>$ represents the class label. The goal of SVM is to find a hyperplane that maximally separates the classes.&lt;/p&gt;  </span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperplane and Dicision Boundary  </span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>Definition (Hyperplane)  </span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>: A hyperplane in an $n$-dimensional space is defined by:</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>w^T \mathbf{x} + b = 0</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$w$ is the weight vector,</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$b$ is the bias term,</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$x$ is any point on the hyperplane.</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>For a two-dimensional space, this hyperplane is simply a line. </span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>w^T\mathbf{x}+b=0;\hspace{4mm}\implies w_0x+w_1y+b=0;\hspace{4mm}\implies y=\frac{-w_0x-b}{w_1}</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>and for a three-dimensional space, this hyperplane is simply a 2D plane</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>w^T\mathbf{x}+b=0;\hspace{4mm}\implies w_0x+w_1y+w_2z+b=0;\hspace{4mm}\implies z=\frac{-w_0x-w_1y-b}{w_2}</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>w_2d <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>b_2d <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>w_3d <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>b_3d <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decision_boundary_2d(x):</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>w_2d[<span class="dv">0</span>]<span class="op">*</span>x<span class="op">-</span>b_2d) <span class="op">/</span> w_2d[<span class="dv">1</span>]</span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decision_boundary_3d(x, y):</span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>w_3d[<span class="dv">0</span>]<span class="op">*</span>x<span class="op">-</span>w_3d[<span class="dv">1</span>]<span class="op">*</span>y<span class="op">-</span>b_3d) <span class="op">/</span> w_3d[<span class="dv">2</span>]</span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a>class1x_2d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">2</span>))</span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>class2x_2d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">2</span>))</span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>class1x_3d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">90</span>,<span class="dv">3</span>))</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>class2x_3d <span class="op">=</span> np.random.normal(loc<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>],scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(<span class="dv">90</span>,<span class="dv">3</span>))</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure( figsize<span class="op">=</span>(<span class="fl">7.9</span>,<span class="dv">4</span>))</span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>x_vals_2d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">100</span>)</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>    x_vals_2d, decision_boundary_2d(x_vals_2d),</span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a>    <span class="st">'k-'</span>, label <span class="op">=</span> <span class="st">"Decision Boundary (Hyperplane)"</span></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>ax1.scatter(</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>    class1x_2d[:,<span class="dv">0</span>], class1x_2d[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'o'</span>, label <span class="op">=</span> <span class="st">'Class +1'</span></span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a>ax1.scatter(</span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a>    class2x_2d[:,<span class="dv">0</span>], class2x_2d[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>,</span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'o'</span>, label <span class="op">=</span> <span class="st">'Class -1'</span></span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Hyperplane (a line) in 2D Space'</span>)</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>ax1.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a>ax1.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>x_vals_3d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">30</span>)</span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>y_vals_3d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">30</span>)</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x_vals_3d, y_vals_3d)</span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> decision_boundary_3d(X, Y)</span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a>ax2.plot_surface(X, Y, Z, color<span class="op">=</span><span class="st">'k'</span>, alpha <span class="op">=</span> <span class="fl">0.3</span>, rstride<span class="op">=</span><span class="dv">100</span>, cstride<span class="op">=</span><span class="dv">100</span>, edgecolor<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>ax2.scatter(class1x_3d[:,<span class="dv">0</span>], class1x_3d[:,<span class="dv">1</span>],class1x_3d[:,<span class="dv">2</span>], color <span class="op">=</span> <span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Class +1'</span>)</span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>ax2.scatter(class2x_3d[:,<span class="dv">0</span>], class2x_3d[:,<span class="dv">1</span>],class2x_3d[:,<span class="dv">2</span>], color <span class="op">=</span> <span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Class -1'</span>)</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'X'</span>)</span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Y'</span>)</span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a>ax2.set_zlabel(<span class="st">'Z'</span>)</span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Hyperplane (a 2D plate) in 3D Space'</span>)</span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1,ax2]</span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-145"><a href="#cb11-145" aria-hidden="true" tabindex="-1"></a><span class="fu">### Margin and the Optimal Hyperplane</span></span>
<span id="cb11-146"><a href="#cb11-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-147"><a href="#cb11-147" aria-hidden="true" tabindex="-1"></a>Definition (Margin)  </span>
<span id="cb11-148"><a href="#cb11-148" aria-hidden="true" tabindex="-1"></a>: The margin is the distance between the hyperplane and the nearest data points from either class. SVM aims to maximize this margin to achieve better separation, which makes the classifier more robust. </span>
<span id="cb11-149"><a href="#cb11-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-150"><a href="#cb11-150" aria-hidden="true" tabindex="-1"></a>To define the margin mathematically, we impose that for all points:</span>
<span id="cb11-151"><a href="#cb11-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-152"><a href="#cb11-152" aria-hidden="true" tabindex="-1"></a>y_i (w^T \mathbf{x}_i + b) \geq 1 \quad \forall i</span>
<span id="cb11-153"><a href="#cb11-153" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-154"><a href="#cb11-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-155"><a href="#cb11-155" aria-hidden="true" tabindex="-1"></a>For a data vector $\mathbf{x}_i$ with label $y_i$:  </span>
<span id="cb11-156"><a href="#cb11-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-157"><a href="#cb11-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $y_i = +1$: we want $w^T \mathbf{x}_i + b\ge 1$ (to be on the correct side of the hyperplane)  </span>
<span id="cb11-158"><a href="#cb11-158" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $y_i = -1$: we want $w^T \mathbf{x}_i + b\le 1$ (to be on the correct side of the hyperplane)  </span>
<span id="cb11-159"><a href="#cb11-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-160"><a href="#cb11-160" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-161"><a href="#cb11-161" aria-hidden="true" tabindex="-1"></a>These two conditions combaine the equation mention above. That is all points must be at least a unit distance from the hyperplane on the correct side. The data points that satisfy $y_i (w^T x_i + b) = 1$ or $y_i (w^T x_i + b) = -1$ lie on the "support vectors," or the points closest to the hyperplane.&lt;/p&gt;   </span>
<span id="cb11-162"><a href="#cb11-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-163"><a href="#cb11-163" aria-hidden="true" tabindex="-1"></a>We know from the elementary geometry that the distance between two parallel lines $ax+by+c_1=0$ and $ax+by+c_2=0$ is given by </span>
<span id="cb11-164"><a href="#cb11-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-165"><a href="#cb11-165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-166"><a href="#cb11-166" aria-hidden="true" tabindex="-1"></a>\frac{|c_1-c_2|}{\sqrt{a^2+b^2}}</span>
<span id="cb11-167"><a href="#cb11-167" aria-hidden="true" tabindex="-1"></a>$$  </span>
<span id="cb11-168"><a href="#cb11-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-169"><a href="#cb11-169" aria-hidden="true" tabindex="-1"></a>and the distance between two 2D parallel planes $ax+by+cz+d_1=0$ and $ax+by+cz+d_2=0$  in 3D space is given as </span>
<span id="cb11-170"><a href="#cb11-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-171"><a href="#cb11-171" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-172"><a href="#cb11-172" aria-hidden="true" tabindex="-1"></a>\frac{|d_1-d_2|}{\sqrt{a^2+b^2+c^2}}</span>
<span id="cb11-173"><a href="#cb11-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-174"><a href="#cb11-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-175"><a href="#cb11-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-178"><a href="#cb11-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-179"><a href="#cb11-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-180"><a href="#cb11-180" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb11-181"><a href="#cb11-181" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.io <span class="im">as</span> pio</span>
<span id="cb11-182"><a href="#cb11-182" aria-hidden="true" tabindex="-1"></a>pio.renderers</span>
<span id="cb11-183"><a href="#cb11-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-184"><a href="#cb11-184" aria-hidden="true" tabindex="-1"></a>z1 <span class="op">=</span> np.array([</span>
<span id="cb11-185"><a href="#cb11-185" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.83</span>,<span class="fl">8.89</span>,<span class="fl">8.81</span>,<span class="fl">8.87</span>,<span class="fl">8.9</span>,<span class="fl">8.87</span>],</span>
<span id="cb11-186"><a href="#cb11-186" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.89</span>,<span class="fl">8.94</span>,<span class="fl">8.85</span>,<span class="fl">8.94</span>,<span class="fl">8.96</span>,<span class="fl">8.92</span>],</span>
<span id="cb11-187"><a href="#cb11-187" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.84</span>,<span class="fl">8.9</span>,<span class="fl">8.82</span>,<span class="fl">8.92</span>,<span class="fl">8.93</span>,<span class="fl">8.91</span>],</span>
<span id="cb11-188"><a href="#cb11-188" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.79</span>,<span class="fl">8.85</span>,<span class="fl">8.79</span>,<span class="fl">8.9</span>,<span class="fl">8.94</span>,<span class="fl">8.92</span>],</span>
<span id="cb11-189"><a href="#cb11-189" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.79</span>,<span class="fl">8.88</span>,<span class="fl">8.81</span>,<span class="fl">8.9</span>,<span class="fl">8.95</span>,<span class="fl">8.92</span>],</span>
<span id="cb11-190"><a href="#cb11-190" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.8</span>,<span class="fl">8.82</span>,<span class="fl">8.78</span>,<span class="fl">8.91</span>,<span class="fl">8.94</span>,<span class="fl">8.92</span>],</span>
<span id="cb11-191"><a href="#cb11-191" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.75</span>,<span class="fl">8.78</span>,<span class="fl">8.77</span>,<span class="fl">8.91</span>,<span class="fl">8.95</span>,<span class="fl">8.92</span>],</span>
<span id="cb11-192"><a href="#cb11-192" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.8</span>,<span class="fl">8.8</span>,<span class="fl">8.77</span>,<span class="fl">8.91</span>,<span class="fl">8.95</span>,<span class="fl">8.94</span>],</span>
<span id="cb11-193"><a href="#cb11-193" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.74</span>,<span class="fl">8.81</span>,<span class="fl">8.76</span>,<span class="fl">8.93</span>,<span class="fl">8.98</span>,<span class="fl">8.99</span>],</span>
<span id="cb11-194"><a href="#cb11-194" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.89</span>,<span class="fl">8.99</span>,<span class="fl">8.92</span>,<span class="fl">9.1</span>,<span class="fl">9.13</span>,<span class="fl">9.11</span>],</span>
<span id="cb11-195"><a href="#cb11-195" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.97</span>,<span class="fl">8.97</span>,<span class="fl">8.91</span>,<span class="fl">9.09</span>,<span class="fl">9.11</span>,<span class="fl">9.11</span>],</span>
<span id="cb11-196"><a href="#cb11-196" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">9.04</span>,<span class="fl">9.08</span>,<span class="fl">9.05</span>,<span class="fl">9.25</span>,<span class="fl">9.28</span>,<span class="fl">9.27</span>],</span>
<span id="cb11-197"><a href="#cb11-197" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">9</span>,<span class="fl">9.01</span>,<span class="dv">9</span>,<span class="fl">9.2</span>,<span class="fl">9.23</span>,<span class="fl">9.2</span>],</span>
<span id="cb11-198"><a href="#cb11-198" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.99</span>,<span class="fl">8.99</span>,<span class="fl">8.98</span>,<span class="fl">9.18</span>,<span class="fl">9.2</span>,<span class="fl">9.19</span>],</span>
<span id="cb11-199"><a href="#cb11-199" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">8.93</span>,<span class="fl">8.97</span>,<span class="fl">8.97</span>,<span class="fl">9.18</span>,<span class="fl">9.2</span>,<span class="fl">9.18</span>]</span>
<span id="cb11-200"><a href="#cb11-200" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-201"><a href="#cb11-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-202"><a href="#cb11-202" aria-hidden="true" tabindex="-1"></a>z2 <span class="op">=</span> z1 <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-203"><a href="#cb11-203" aria-hidden="true" tabindex="-1"></a>z3 <span class="op">=</span> z1 <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb11-204"><a href="#cb11-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-205"><a href="#cb11-205" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> go.Figure(data<span class="op">=</span>[</span>
<span id="cb11-206"><a href="#cb11-206" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z1),</span>
<span id="cb11-207"><a href="#cb11-207" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z2, showscale<span class="op">=</span><span class="va">False</span>, opacity<span class="op">=</span><span class="fl">0.9</span>),</span>
<span id="cb11-208"><a href="#cb11-208" aria-hidden="true" tabindex="-1"></a>    go.Surface(z<span class="op">=</span>z3, showscale<span class="op">=</span><span class="va">False</span>, opacity<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb11-209"><a href="#cb11-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-210"><a href="#cb11-210" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-211"><a href="#cb11-211" aria-hidden="true" tabindex="-1"></a>fig.update_layout(</span>
<span id="cb11-212"><a href="#cb11-212" aria-hidden="true" tabindex="-1"></a>    scene<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb11-213"><a href="#cb11-213" aria-hidden="true" tabindex="-1"></a>        xaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>),</span>
<span id="cb11-214"><a href="#cb11-214" aria-hidden="true" tabindex="-1"></a>        yaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>),</span>
<span id="cb11-215"><a href="#cb11-215" aria-hidden="true" tabindex="-1"></a>        zaxis<span class="op">=</span><span class="bu">dict</span>(backgroundcolor<span class="op">=</span><span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-216"><a href="#cb11-216" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb11-217"><a href="#cb11-217" aria-hidden="true" tabindex="-1"></a>    paper_bgcolor <span class="op">=</span> <span class="st">'#f4f4f4'</span>,</span>
<span id="cb11-218"><a href="#cb11-218" aria-hidden="true" tabindex="-1"></a>    title <span class="op">=</span> <span class="st">"Hyperplanes in higher dimension"</span></span>
<span id="cb11-219"><a href="#cb11-219" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-220"><a href="#cb11-220" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb11-221"><a href="#cb11-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb11-222"><a href="#cb11-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-223"><a href="#cb11-223" aria-hidden="true" tabindex="-1"></a>For the hyperplanes in higher dimensions, the distance between two parallel hyperplanes $w^T\mathbf{x}+b=1$ and $w^T\mathbf{x}+b=-1$ is given as</span>
<span id="cb11-224"><a href="#cb11-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-225"><a href="#cb11-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-226"><a href="#cb11-226" aria-hidden="true" tabindex="-1"></a>\text{Distance: }M= \frac{|1-(-1)|}{\|w\|}=\frac{2}{\|w\|}</span>
<span id="cb11-227"><a href="#cb11-227" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-228"><a href="#cb11-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-229"><a href="#cb11-229" aria-hidden="true" tabindex="-1"></a>This distance, $M$ is the margin and our objective is to maximize $M$, or equivalently, minimize $\|w\|$ subject to the constraints $y_i (w^T x_i + b) \geq 1$.</span>
<span id="cb11-230"><a href="#cb11-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-231"><a href="#cb11-231" aria-hidden="true" tabindex="-1"></a><span class="fu">### Optimization of the SVM</span></span>
<span id="cb11-232"><a href="#cb11-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-233"><a href="#cb11-233" aria-hidden="true" tabindex="-1"></a>The optimization problem can be formulated as follows:</span>
<span id="cb11-234"><a href="#cb11-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-235"><a href="#cb11-235" aria-hidden="true" tabindex="-1"></a>**Primal Form:**</span>
<span id="cb11-236"><a href="#cb11-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-237"><a href="#cb11-237" aria-hidden="true" tabindex="-1"></a>\min_{w, b} \frac{1}{2} \|w\|^2</span>
<span id="cb11-238"><a href="#cb11-238" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-239"><a href="#cb11-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-240"><a href="#cb11-240" aria-hidden="true" tabindex="-1"></a>subject to:</span>
<span id="cb11-241"><a href="#cb11-241" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-242"><a href="#cb11-242" aria-hidden="true" tabindex="-1"></a>y_i (w^T x_i + b) \geq 1, \quad \forall i</span>
<span id="cb11-243"><a href="#cb11-243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-244"><a href="#cb11-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-245"><a href="#cb11-245" aria-hidden="true" tabindex="-1"></a>This is a convex optimization problem because the objective function $\frac{1}{2} \|w\|^2$ is convex, and the constraints are linear.</span>
<span id="cb11-246"><a href="#cb11-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-247"><a href="#cb11-247" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Dual Form of SVM</span></span>
<span id="cb11-248"><a href="#cb11-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-249"><a href="#cb11-249" aria-hidden="true" tabindex="-1"></a>To solve the optimization problem, it is often more efficient to use the dual form. By introducing Lagrange multipliers $\alpha_i \geq 0$, we can construct the Lagrangian:</span>
<span id="cb11-250"><a href="#cb11-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-251"><a href="#cb11-251" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-252"><a href="#cb11-252" aria-hidden="true" tabindex="-1"></a>L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^n \alpha_i \left( y_i (w^T x_i + b) - 1 \right)</span>
<span id="cb11-253"><a href="#cb11-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-254"><a href="#cb11-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-255"><a href="#cb11-255" aria-hidden="true" tabindex="-1"></a>Taking the partial derivatives of $L$ with respect to $w$ and $b$ and setting them to zero yields:  </span>
<span id="cb11-256"><a href="#cb11-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-257"><a href="#cb11-257" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb11-258"><a href="#cb11-258" aria-hidden="true" tabindex="-1"></a>\frac{\partial L}{\partial w} &amp;= w - \sum_{i=1}^n \alpha_i y_i x_i = 0<span class="sc">\\</span></span>
<span id="cb11-259"><a href="#cb11-259" aria-hidden="true" tabindex="-1"></a>\implies w &amp;= \sum_{i=1}^n \alpha_i y_i x_i<span class="sc">\\</span></span>
<span id="cb11-260"><a href="#cb11-260" aria-hidden="true" tabindex="-1"></a>\text{ and } &amp;<span class="sc">\\</span></span>
<span id="cb11-261"><a href="#cb11-261" aria-hidden="true" tabindex="-1"></a>\frac{\partial L}{\partial b} &amp;= -\sum_{i=1}^n \alpha_i y_i = 0<span class="sc">\\</span></span>
<span id="cb11-262"><a href="#cb11-262" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^n \alpha_i y_i &amp;= 0</span>
<span id="cb11-263"><a href="#cb11-263" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb11-264"><a href="#cb11-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-265"><a href="#cb11-265" aria-hidden="true" tabindex="-1"></a>This tells us that $w$ can be expressed as a linear combination of the training points $x_i$ with weights given by $\alpha_i y_i$ and the sum of the weighted labels is zero.</span>
<span id="cb11-266"><a href="#cb11-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-267"><a href="#cb11-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-268"><a href="#cb11-268" aria-hidden="true" tabindex="-1"></a>Now we substitute $w = \sum_{i=1}^n \alpha_i y_i x_i$ back into the Lagrangian $L(w, b, \alpha)$. The primal objective function $\frac{1}{2} \|w\|^2$ becomes:</span>
<span id="cb11-269"><a href="#cb11-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-270"><a href="#cb11-270" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb11-271"><a href="#cb11-271" aria-hidden="true" tabindex="-1"></a>\frac{1}{2} \|w\|^2 &amp;= \frac{1}{2} \left( \sum_{i=1}^n \alpha_i y_i x_i \right)^T \left( \sum_{j=1}^n \alpha_j y_j x_j \right)<span class="sc">\\</span></span>
<span id="cb11-272"><a href="#cb11-272" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j</span>
<span id="cb11-273"><a href="#cb11-273" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb11-274"><a href="#cb11-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-275"><a href="#cb11-275" aria-hidden="true" tabindex="-1"></a>Substituting back into the Lagrangian, </span>
<span id="cb11-276"><a href="#cb11-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-277"><a href="#cb11-277" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-278"><a href="#cb11-278" aria-hidden="true" tabindex="-1"></a>L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^n \alpha_i  y_i (w^T x_i + b) + \sum_{i=1}^n \alpha_i </span>
<span id="cb11-279"><a href="#cb11-279" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-280"><a href="#cb11-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-281"><a href="#cb11-281" aria-hidden="true" tabindex="-1"></a>we get the dual form as:</span>
<span id="cb11-282"><a href="#cb11-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-283"><a href="#cb11-283" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-284"><a href="#cb11-284" aria-hidden="true" tabindex="-1"></a>\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j</span>
<span id="cb11-285"><a href="#cb11-285" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-286"><a href="#cb11-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-287"><a href="#cb11-287" aria-hidden="true" tabindex="-1"></a>subject to:</span>
<span id="cb11-288"><a href="#cb11-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-289"><a href="#cb11-289" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-290"><a href="#cb11-290" aria-hidden="true" tabindex="-1"></a>\alpha_i \geq 0 \quad \forall i, \quad \text{and} \quad \sum_{i=1}^n \alpha_i y_i = 0</span>
<span id="cb11-291"><a href="#cb11-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-292"><a href="#cb11-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-293"><a href="#cb11-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-294"><a href="#cb11-294" aria-hidden="true" tabindex="-1"></a>The solution to the dual form gives the values of $\alpha_i$, which are used to construct the optimal hyperplane. The final decision boundary is then:</span>
<span id="cb11-295"><a href="#cb11-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-296"><a href="#cb11-296" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-297"><a href="#cb11-297" aria-hidden="true" tabindex="-1"></a>f(x) = \text{sign} \left( \sum_{i=1}^N \alpha_i y_i x_i^T x + b \right)</span>
<span id="cb11-298"><a href="#cb11-298" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-299"><a href="#cb11-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-300"><a href="#cb11-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Nonlinear Support Vector Machines</span></span>
<span id="cb11-301"><a href="#cb11-301" aria-hidden="true" tabindex="-1"></a>Imagine we have a dataset that looks like this.  </span>
<span id="cb11-302"><a href="#cb11-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-305"><a href="#cb11-305" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-306"><a href="#cb11-306" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-307"><a href="#cb11-307" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb11-308"><a href="#cb11-308" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">300</span>, noise<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-309"><a href="#cb11-309" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb11-310"><a href="#cb11-310" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">0</span>][:,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>][:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb11-311"><a href="#cb11-311" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>][:,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>][:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb11-312"><a href="#cb11-312" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb11-313"><a href="#cb11-313" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb11-314"><a href="#cb11-314" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-315"><a href="#cb11-315" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-316"><a href="#cb11-316" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-317"><a href="#cb11-317" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-318"><a href="#cb11-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-319"><a href="#cb11-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-320"><a href="#cb11-320" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-321"><a href="#cb11-321" aria-hidden="true" tabindex="-1"></a>There is now way that a linear hyperplane seperates the data. Therefore, when the data is not linearly separable, SVMs use the **kernel trick** to map the data into a higher-dimensional space where a linear separation is possible. The idea is to map the original data points $\mathbf{x}$ from the input space to a higher-dimensional feature space using a *feature transformation function $\phi(x)$. &lt;/p&gt;  </span>
<span id="cb11-322"><a href="#cb11-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-323"><a href="#cb11-323" aria-hidden="true" tabindex="-1"></a>For example,</span>
<span id="cb11-324"><a href="#cb11-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-325"><a href="#cb11-325" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-326"><a href="#cb11-326" aria-hidden="true" tabindex="-1"></a>\phi: \mathbb{R}^n\mapsto \mathbb{R}^m, \hspace{4mm} \text{where } m&gt;n</span>
<span id="cb11-327"><a href="#cb11-327" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-328"><a href="#cb11-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-329"><a href="#cb11-329" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-330"><a href="#cb11-330" aria-hidden="true" tabindex="-1"></a>In the higher-dimensional space, it’s often easier to find a hyperplane that separates the two classes linearly.&lt;br&gt;</span>
<span id="cb11-331"><a href="#cb11-331" aria-hidden="true" tabindex="-1"></a>&lt;br&gt;</span>
<span id="cb11-332"><a href="#cb11-332" aria-hidden="true" tabindex="-1"></a>However, explicitly calculating and working with this higher-dimensional transformation $\phi(x)$ can be computationally expensive, especially when the dimensionality $m$ is very high or infinite. This is where the **kernel trick** comes in.&lt;/p&gt;</span>
<span id="cb11-333"><a href="#cb11-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-334"><a href="#cb11-334" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Kernel Trick</span></span>
<span id="cb11-335"><a href="#cb11-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-336"><a href="#cb11-336" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-337"><a href="#cb11-337" aria-hidden="true" tabindex="-1"></a>The **kernel trick** is a method that allows us to compute the inner product between two transformed data points $\phi(x_i)$ and $\phi(x_j)$ in the higher-dimensional space **without** explicitly computing the transformation $\phi(x)$.&lt;br&gt;</span>
<span id="cb11-338"><a href="#cb11-338" aria-hidden="true" tabindex="-1"></a>&lt;br&gt;</span>
<span id="cb11-339"><a href="#cb11-339" aria-hidden="true" tabindex="-1"></a>Instead of computing $\phi(x_i)$ and $\phi(x_j)$ separately and then taking their inner product, we define a **kernel function** $K(x_i, x_j)$ that directly computes this inner product in the higher-dimensional space:&lt;/p&gt;</span>
<span id="cb11-340"><a href="#cb11-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-341"><a href="#cb11-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-342"><a href="#cb11-342" aria-hidden="true" tabindex="-1"></a>K(x_i, x_j) = \phi(x_i)^T \phi(x_j)</span>
<span id="cb11-343"><a href="#cb11-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-344"><a href="#cb11-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-345"><a href="#cb11-345" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-346"><a href="#cb11-346" aria-hidden="true" tabindex="-1"></a>By substituting this kernel function into the SVM optimization problem, we can work in the higher-dimensional space implicitly, without ever explicitly mapping the data points to that space. This allows us to handle complex, nonlinear decision boundaries with a more computationally efficient approach.&lt;/p&gt;</span>
<span id="cb11-347"><a href="#cb11-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-348"><a href="#cb11-348" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Polynomial Kernel</span></span>
<span id="cb11-349"><a href="#cb11-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-350"><a href="#cb11-350" aria-hidden="true" tabindex="-1"></a>The polynomial kernel allows us to model nonlinear decision boundaries using polynomial functions. It is defined as:</span>
<span id="cb11-351"><a href="#cb11-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-352"><a href="#cb11-352" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-353"><a href="#cb11-353" aria-hidden="true" tabindex="-1"></a>K(x_i, x_j) = (x_i^T x_j + c)^d</span>
<span id="cb11-354"><a href="#cb11-354" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-355"><a href="#cb11-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-356"><a href="#cb11-356" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-357"><a href="#cb11-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-358"><a href="#cb11-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$c$ is a constant that controls the influence of higher-order terms.</span>
<span id="cb11-359"><a href="#cb11-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$d$ is the degree of the polynomial.</span>
<span id="cb11-360"><a href="#cb11-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-361"><a href="#cb11-361" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-362"><a href="#cb11-362" aria-hidden="true" tabindex="-1"></a>The polynomial kernel creates a feature space that corresponds to all monomials up to degree $d$. It can model interactions between features, allowing the SVM to classify data with polynomial decision boundaries.</span>
<span id="cb11-363"><a href="#cb11-363" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb11-364"><a href="#cb11-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-365"><a href="#cb11-365" aria-hidden="true" tabindex="-1"></a>For example, when we have 1-D data and it is linearly inseperable, we can use polynomial kernel with degree 2 or higher. Say $c=1/2$ and $d=2$, </span>
<span id="cb11-366"><a href="#cb11-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-367"><a href="#cb11-367" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb11-368"><a href="#cb11-368" aria-hidden="true" tabindex="-1"></a>K(x_1,x_2)&amp; = \left(x_1x_2+\frac{1}{2}\right)^2<span class="sc">\\</span></span>
<span id="cb11-369"><a href="#cb11-369" aria-hidden="true" tabindex="-1"></a>&amp; = \left(x_1x_2+\frac{1}{2}\right)\left(x_1x_2+\frac{1}{2}\right)<span class="sc">\\</span></span>
<span id="cb11-370"><a href="#cb11-370" aria-hidden="true" tabindex="-1"></a>&amp; = x_1^2x_2^2+\frac{1}{2}x_1x_2+\frac{1}{4}<span class="sc">\\</span></span>
<span id="cb11-371"><a href="#cb11-371" aria-hidden="true" tabindex="-1"></a>&amp; = x_1x_2+x_1^2x_2^2+\frac{1}{4}<span class="sc">\\</span></span>
<span id="cb11-372"><a href="#cb11-372" aria-hidden="true" tabindex="-1"></a>&amp; = (x_1,x_1^2,\frac{1}{2})\cdot (x_2,x_2^2,\frac{1}{2})</span>
<span id="cb11-373"><a href="#cb11-373" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb11-374"><a href="#cb11-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-377"><a href="#cb11-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-378"><a href="#cb11-378" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-379"><a href="#cb11-379" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">11</span>))</span>
<span id="cb11-380"><a href="#cb11-380" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">14</span>,<span class="dv">24</span>))</span>
<span id="cb11-381"><a href="#cb11-381" aria-hidden="true" tabindex="-1"></a>x3 <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">27</span>,<span class="dv">37</span>))</span>
<span id="cb11-382"><a href="#cb11-382" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [j <span class="cf">for</span> sub <span class="kw">in</span> [x1,x2,x3] <span class="cf">for</span> j <span class="kw">in</span> sub]</span>
<span id="cb11-383"><a href="#cb11-383" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="dv">30</span></span>
<span id="cb11-384"><a href="#cb11-384" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>]<span class="op">*</span><span class="dv">10</span><span class="op">+</span>[<span class="st">'red'</span>]<span class="op">*</span><span class="dv">10</span><span class="op">+</span> [<span class="st">'blue'</span>]<span class="op">*</span><span class="dv">10</span></span>
<span id="cb11-385"><a href="#cb11-385" aria-hidden="true" tabindex="-1"></a>y_squared <span class="op">=</span> [i<span class="op">**</span><span class="dv">2</span> <span class="cf">for</span> i <span class="kw">in</span> x]</span>
<span id="cb11-386"><a href="#cb11-386" aria-hidden="true" tabindex="-1"></a>slope <span class="op">=</span> (<span class="dv">197</span><span class="op">-</span><span class="fl">529.5</span>)<span class="op">/</span>(<span class="dv">14</span><span class="op">-</span><span class="dv">23</span>)</span>
<span id="cb11-387"><a href="#cb11-387" aria-hidden="true" tabindex="-1"></a>line_x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">40</span>,<span class="dv">100</span>)</span>
<span id="cb11-388"><a href="#cb11-388" aria-hidden="true" tabindex="-1"></a>line_y <span class="op">=</span> slope<span class="op">*</span> (line_x <span class="op">-</span> <span class="dv">14</span>) <span class="op">+</span> <span class="dv">197</span></span>
<span id="cb11-389"><a href="#cb11-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-390"><a href="#cb11-390" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>,<span class="dv">4</span>))</span>
<span id="cb11-391"><a href="#cb11-391" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb11-392"><a href="#cb11-392" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x,y, c<span class="op">=</span>colors, label<span class="op">=</span><span class="st">'Actual Data in 1D'</span>)</span>
<span id="cb11-393"><a href="#cb11-393" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="vs">r'$feature$'</span>)</span>
<span id="cb11-394"><a href="#cb11-394" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(<span class="dv">0</span>,<span class="dv">40</span>)</span>
<span id="cb11-395"><a href="#cb11-395" aria-hidden="true" tabindex="-1"></a>ax1.set_ylim(<span class="op">-</span><span class="dv">50</span>,<span class="dv">50</span>)</span>
<span id="cb11-396"><a href="#cb11-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-397"><a href="#cb11-397" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb11-398"><a href="#cb11-398" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x,y, c<span class="op">=</span>colors, label<span class="op">=</span><span class="st">'Actual Data in 1D'</span>)</span>
<span id="cb11-399"><a href="#cb11-399" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x,y_squared, c<span class="op">=</span> colors, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Transformed Data in 2D'</span>)</span>
<span id="cb11-400"><a href="#cb11-400" aria-hidden="true" tabindex="-1"></a>ax2.plot(line_x,line_y, color<span class="op">=</span><span class="st">'green'</span>,label<span class="op">=</span><span class="st">'1D Hyperplane'</span>)</span>
<span id="cb11-401"><a href="#cb11-401" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(<span class="dv">0</span>,<span class="dv">40</span>)</span>
<span id="cb11-402"><a href="#cb11-402" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(<span class="op">-</span><span class="dv">100</span>,<span class="dv">1400</span>)</span>
<span id="cb11-403"><a href="#cb11-403" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="vs">r'$feature$'</span>)</span>
<span id="cb11-404"><a href="#cb11-404" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="vs">r'$feature^2$'</span>)</span>
<span id="cb11-405"><a href="#cb11-405" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb11-406"><a href="#cb11-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-407"><a href="#cb11-407" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-408"><a href="#cb11-408" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1,ax2]</span>
<span id="cb11-409"><a href="#cb11-409" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb11-410"><a href="#cb11-410" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-411"><a href="#cb11-411" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-412"><a href="#cb11-412" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-413"><a href="#cb11-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb11-414"><a href="#cb11-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-415"><a href="#cb11-415" aria-hidden="true" tabindex="-1"></a>or for a 2D data to 3D transformation along with 2D hyperplane</span>
<span id="cb11-416"><a href="#cb11-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-419"><a href="#cb11-419" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-420"><a href="#cb11-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-421"><a href="#cb11-421" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span>
<span id="cb11-422"><a href="#cb11-422" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb11-423"><a href="#cb11-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-424"><a href="#cb11-424" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a dataset that is not linearly separable</span></span>
<span id="cb11-425"><a href="#cb11-425" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">300</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-426"><a href="#cb11-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-427"><a href="#cb11-427" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original dataset</span></span>
<span id="cb11-428"><a href="#cb11-428" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>, <span class="dv">4</span>))</span>
<span id="cb11-429"><a href="#cb11-429" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb11-430"><a href="#cb11-430" aria-hidden="true" tabindex="-1"></a>ax1.scatter(X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb11-431"><a href="#cb11-431" aria-hidden="true" tabindex="-1"></a>ax1.scatter(X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb11-432"><a href="#cb11-432" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Data'</span>)</span>
<span id="cb11-433"><a href="#cb11-433" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'feature 1'</span>)</span>
<span id="cb11-434"><a href="#cb11-434" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'feature 2'</span>)</span>
<span id="cb11-435"><a href="#cb11-435" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb11-436"><a href="#cb11-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-437"><a href="#cb11-437" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply polynomial kernel transformation</span></span>
<span id="cb11-438"><a href="#cb11-438" aria-hidden="true" tabindex="-1"></a>X_transformed <span class="op">=</span> np.hstack((X, (X[:, <span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> X[:, <span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb11-439"><a href="#cb11-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-440"><a href="#cb11-440" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the transformed dataset in 3D</span></span>
<span id="cb11-441"><a href="#cb11-441" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb11-442"><a href="#cb11-442" aria-hidden="true" tabindex="-1"></a>ax2.scatter(X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">0</span>], X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">1</span>], X_transformed[y <span class="op">==</span> <span class="dv">0</span>][:, <span class="dv">2</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Class 0'</span>)</span>
<span id="cb11-443"><a href="#cb11-443" aria-hidden="true" tabindex="-1"></a>ax2.scatter(X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">0</span>], X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">1</span>], X_transformed[y <span class="op">==</span> <span class="dv">1</span>][:, <span class="dv">2</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Class 1'</span>)</span>
<span id="cb11-444"><a href="#cb11-444" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'2D to 3D transformed'</span>)</span>
<span id="cb11-445"><a href="#cb11-445" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb11-446"><a href="#cb11-446" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb11-447"><a href="#cb11-447" aria-hidden="true" tabindex="-1"></a>ax2.set_zlabel(<span class="st">'Poly Feature'</span>)</span>
<span id="cb11-448"><a href="#cb11-448" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb11-449"><a href="#cb11-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-450"><a href="#cb11-450" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> [ax1, ax2]</span>
<span id="cb11-451"><a href="#cb11-451" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes:</span>
<span id="cb11-452"><a href="#cb11-452" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-453"><a href="#cb11-453" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-454"><a href="#cb11-454" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-455"><a href="#cb11-455" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-456"><a href="#cb11-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-457"><a href="#cb11-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-458"><a href="#cb11-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-459"><a href="#cb11-459" aria-hidden="true" tabindex="-1"></a><span class="fu">####  Radial Basis Function (RBF) Kernel (Gaussian Kernel)</span></span>
<span id="cb11-460"><a href="#cb11-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-461"><a href="#cb11-461" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-462"><a href="#cb11-462" aria-hidden="true" tabindex="-1"></a>The RBF kernel, also known as the Gaussian kernel, is one of the most popular kernels because it can map the data to an infinite-dimensional space, allowing the model to capture highly complex relationships. It’s defined as:&lt;/p&gt;</span>
<span id="cb11-463"><a href="#cb11-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-464"><a href="#cb11-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-465"><a href="#cb11-465" aria-hidden="true" tabindex="-1"></a>K(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right)</span>
<span id="cb11-466"><a href="#cb11-466" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-467"><a href="#cb11-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-468"><a href="#cb11-468" aria-hidden="true" tabindex="-1"></a>or equivalently:</span>
<span id="cb11-469"><a href="#cb11-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-470"><a href="#cb11-470" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-471"><a href="#cb11-471" aria-hidden="true" tabindex="-1"></a>K(x_i, x_j) = \exp\left(-\gamma \|x_i - x_j\|^2\right)</span>
<span id="cb11-472"><a href="#cb11-472" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-473"><a href="#cb11-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-474"><a href="#cb11-474" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-475"><a href="#cb11-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-476"><a href="#cb11-476" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\|x_i - x_j\|^2$ is the squared Euclidean distance between the points $x_i$ and $x_j$.</span>
<span id="cb11-477"><a href="#cb11-477" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\sigma$ (or $\gamma = \frac{1}{2\sigma^2}$) controls the width of the Gaussian function and, thus, the influence of each training example.</span>
<span id="cb11-478"><a href="#cb11-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-479"><a href="#cb11-479" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-480"><a href="#cb11-480" aria-hidden="true" tabindex="-1"></a>The RBF kernel is particularly effective when the relationship between classes is highly nonlinear. It maps each data point to an infinite-dimensional space, allowing the SVM to capture fine-grained patterns.&lt;/p&gt;</span>
<span id="cb11-481"><a href="#cb11-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-482"><a href="#cb11-482" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Sigmoid Kernel</span></span>
<span id="cb11-483"><a href="#cb11-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-484"><a href="#cb11-484" aria-hidden="true" tabindex="-1"></a>The sigmoid kernel is related to neural networks and is defined as:</span>
<span id="cb11-485"><a href="#cb11-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-486"><a href="#cb11-486" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-487"><a href="#cb11-487" aria-hidden="true" tabindex="-1"></a>K(x_i, x_j) = \tanh(\kappa x_i^T x_j + \theta)</span>
<span id="cb11-488"><a href="#cb11-488" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-489"><a href="#cb11-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-490"><a href="#cb11-490" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-491"><a href="#cb11-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-492"><a href="#cb11-492" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\kappa$ and $\theta$ are parameters that control the shape of the kernel.</span>
<span id="cb11-493"><a href="#cb11-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-494"><a href="#cb11-494" aria-hidden="true" tabindex="-1"></a>This kernel can be interpreted as simulating a neural network with a single hidden layer, where $\tanh$ serves as the activation function.</span>
<span id="cb11-495"><a href="#cb11-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-496"><a href="#cb11-496" aria-hidden="true" tabindex="-1"></a><span class="fu">###  Dual Formulation with the Kernel Trick</span></span>
<span id="cb11-497"><a href="#cb11-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-498"><a href="#cb11-498" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-499"><a href="#cb11-499" aria-hidden="true" tabindex="-1"></a>In the dual form of the SVM optimization problem, we only require the inner products $x_i^T x_j$ between data points. By replacing these inner products with $K(x_i, x_j) = \phi(x_i)^T \phi(x_j)$, we obtain the dual form of the optimization problem for a kernelized SVM:&lt;/p&gt;</span>
<span id="cb11-500"><a href="#cb11-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-501"><a href="#cb11-501" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-502"><a href="#cb11-502" aria-hidden="true" tabindex="-1"></a>\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(x_i, x_j)</span>
<span id="cb11-503"><a href="#cb11-503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-504"><a href="#cb11-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-505"><a href="#cb11-505" aria-hidden="true" tabindex="-1"></a>subject to:</span>
<span id="cb11-506"><a href="#cb11-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-507"><a href="#cb11-507" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-508"><a href="#cb11-508" aria-hidden="true" tabindex="-1"></a>\alpha_i \geq 0 \quad \forall i, \quad \text{and} \quad \sum_{i=1}^n \alpha_i y_i = 0</span>
<span id="cb11-509"><a href="#cb11-509" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-510"><a href="#cb11-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-511"><a href="#cb11-511" aria-hidden="true" tabindex="-1"></a>Using the kernel function $K(x_i, x_j)$, we can compute the decision boundary in the original space without explicitly mapping to the higher-dimensional space.</span>
<span id="cb11-512"><a href="#cb11-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-513"><a href="#cb11-513" aria-hidden="true" tabindex="-1"></a><span class="fu">### Decision Function with the Kernel Trick</span></span>
<span id="cb11-514"><a href="#cb11-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-515"><a href="#cb11-515" aria-hidden="true" tabindex="-1"></a>Once we solve for $\alpha$ and determine the support vectors, the decision function for a new point $x$ becomes:</span>
<span id="cb11-516"><a href="#cb11-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-517"><a href="#cb11-517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-518"><a href="#cb11-518" aria-hidden="true" tabindex="-1"></a>f(x) = \sum_{i=1}^n \alpha_i y_i K(x_i, x) + b</span>
<span id="cb11-519"><a href="#cb11-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-520"><a href="#cb11-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-521"><a href="#cb11-521" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-522"><a href="#cb11-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-523"><a href="#cb11-523" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\alpha_i$ are the Lagrange multipliers found from the optimization.</span>
<span id="cb11-524"><a href="#cb11-524" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$y_i$ are the labels of the support vectors.</span>
<span id="cb11-525"><a href="#cb11-525" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$K(x_i, x)$ is the kernel function that calculates the inner product between the support vector $x_i$ and the new data point $x$.</span>
<span id="cb11-526"><a href="#cb11-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-527"><a href="#cb11-527" aria-hidden="true" tabindex="-1"></a>This decision function allows us to classify new data points by evaluating their relationship with the support vectors in the original input space, using the kernel to measure similarity.  </span>
<span id="cb11-528"><a href="#cb11-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-529"><a href="#cb11-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### Soft Margin SVM  </span></span>
<span id="cb11-530"><a href="#cb11-530" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-531"><a href="#cb11-531" aria-hidden="true" tabindex="-1"></a>The concept of **soft margin SVM** extends the hard margin SVM approach to handle cases where data is not perfectly separable. In real-world datasets, it’s often impossible to perfectly separate classes without allowing some misclassification or overlap. Soft margin SVM addresses this by introducing a **margin of tolerance**—it allows some data points to lie within the margin or even on the wrong side of the decision boundary.&lt;/p&gt;</span>
<span id="cb11-532"><a href="#cb11-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-533"><a href="#cb11-533" aria-hidden="true" tabindex="-1"></a>In hard margin SVM, we strictly enforced that:</span>
<span id="cb11-534"><a href="#cb11-534" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-535"><a href="#cb11-535" aria-hidden="true" tabindex="-1"></a>y_i (w^T x_i + b) \ge 1, \quad \forall i</span>
<span id="cb11-536"><a href="#cb11-536" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-537"><a href="#cb11-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-538"><a href="#cb11-538" aria-hidden="true" tabindex="-1"></a>which means that each point is correctly classified and outside the margin.</span>
<span id="cb11-539"><a href="#cb11-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-540"><a href="#cb11-540" aria-hidden="true" tabindex="-1"></a>In soft margin SVM, we introduce **slack variables** $\xi_i$, which allow some points to violate this constraint. The constraints become:</span>
<span id="cb11-541"><a href="#cb11-541" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-542"><a href="#cb11-542" aria-hidden="true" tabindex="-1"></a>y_i (w^T x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0</span>
<span id="cb11-543"><a href="#cb11-543" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-544"><a href="#cb11-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-545"><a href="#cb11-545" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-546"><a href="#cb11-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-547"><a href="#cb11-547" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\xi_i$ measures the degree of misclassification for each data point $x_i$.</span>
<span id="cb11-548"><a href="#cb11-548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $\xi_i = 0$, then $x_i$ lies on or outside the margin (correct classification).</span>
<span id="cb11-549"><a href="#cb11-549" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $0 &lt; \xi_i \le 1$, then $x_i$ lies within the margin but is still correctly classified.</span>
<span id="cb11-550"><a href="#cb11-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $\xi_i &gt; 1$, then $x_i$ is misclassified.</span>
<span id="cb11-551"><a href="#cb11-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-552"><a href="#cb11-552" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-553"><a href="#cb11-553" aria-hidden="true" tabindex="-1"></a>To find the optimal hyperplane with a soft margin, we modify the objective function to include a **penalty** for misclassifications. The goal is to balance maximizing the margin and minimizing the misclassification error. The objective function becomes:&lt;/p&gt;</span>
<span id="cb11-554"><a href="#cb11-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-555"><a href="#cb11-555" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-556"><a href="#cb11-556" aria-hidden="true" tabindex="-1"></a>\min_{w, b, \xi} \quad \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \xi_i</span>
<span id="cb11-557"><a href="#cb11-557" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-558"><a href="#cb11-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-559"><a href="#cb11-559" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb11-560"><a href="#cb11-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-561"><a href="#cb11-561" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The term $\frac{1}{2} \|w\|^2$ encourages a large margin, just as in hard margin SVM.</span>
<span id="cb11-562"><a href="#cb11-562" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The term $C \sum_{i=1}^n \xi_i$ penalizes misclassified points, where $C$ is a **regularization parameter** that controls the trade-off between maximizing the margin and minimizing the classification error.</span>
<span id="cb11-563"><a href="#cb11-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-564"><a href="#cb11-564" aria-hidden="true" tabindex="-1"></a>The **parameter $C$**:</span>
<span id="cb11-565"><a href="#cb11-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-566"><a href="#cb11-566" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $C$ is large, the optimization emphasizes minimizing misclassifications (more sensitive to individual data points), which leads to a narrower margin with fewer violations.</span>
<span id="cb11-567"><a href="#cb11-567" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $C$ is small, the optimization focuses more on maximizing the margin, allowing more misclassifications.</span>
<span id="cb11-568"><a href="#cb11-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-569"><a href="#cb11-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-570"><a href="#cb11-570" aria-hidden="true" tabindex="-1"></a>The optimization problem for soft margin SVM can be written as:</span>
<span id="cb11-571"><a href="#cb11-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-572"><a href="#cb11-572" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-573"><a href="#cb11-573" aria-hidden="true" tabindex="-1"></a>\min_{w, b, \xi} \quad \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \xi_i</span>
<span id="cb11-574"><a href="#cb11-574" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-575"><a href="#cb11-575" aria-hidden="true" tabindex="-1"></a>subject to:</span>
<span id="cb11-576"><a href="#cb11-576" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-577"><a href="#cb11-577" aria-hidden="true" tabindex="-1"></a>y_i (w^T x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0 \quad \forall i</span>
<span id="cb11-578"><a href="#cb11-578" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-579"><a href="#cb11-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-580"><a href="#cb11-580" aria-hidden="true" tabindex="-1"></a>This problem is still convex and can be solved using Lagrange multipliers, though it becomes slightly more complex due to the introduction of slack variables $\xi_i$. </span>
<span id="cb11-581"><a href="#cb11-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-582"><a href="#cb11-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-583"><a href="#cb11-583" aria-hidden="true" tabindex="-1"></a>The dual form of the soft margin SVM, similar to the hard margin case, can be derived using Lagrange multipliers. The dual problem becomes:</span>
<span id="cb11-584"><a href="#cb11-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-585"><a href="#cb11-585" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-586"><a href="#cb11-586" aria-hidden="true" tabindex="-1"></a>\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(x_i, x_j)</span>
<span id="cb11-587"><a href="#cb11-587" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-588"><a href="#cb11-588" aria-hidden="true" tabindex="-1"></a>subject to:</span>
<span id="cb11-589"><a href="#cb11-589" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-590"><a href="#cb11-590" aria-hidden="true" tabindex="-1"></a>0 \leq \alpha_i \leq C, \quad \sum_{i=1}^n \alpha_i y_i = 0</span>
<span id="cb11-591"><a href="#cb11-591" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-592"><a href="#cb11-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-593"><a href="#cb11-593" aria-hidden="true" tabindex="-1"></a>The main difference here is that each $\alpha_i$ is now bounded by $C$ instead of being unrestricted, which introduces a balance between the margin maximization and error tolerance.</span>
<span id="cb11-594"><a href="#cb11-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-595"><a href="#cb11-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-596"><a href="#cb11-596" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-597"><a href="#cb11-597" aria-hidden="true" tabindex="-1"></a>In soft margin SVM, the margin is not strict. Some points are allowed to lie within the margin or even be misclassified. Points that lie on the wrong side of the margin are called **support vectors** with non-zero slack values $\xi_i$.&lt;/p&gt;</span>
<span id="cb11-598"><a href="#cb11-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-599"><a href="#cb11-599" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**High $C$**: A larger $C$ results in a narrower margin with fewer violations, meaning fewer points within the margin or misclassified. This leads to a more complex model that might overfit if $C$ is too high.</span>
<span id="cb11-600"><a href="#cb11-600" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Low $C$**: A smaller $C$ results in a wider margin with more allowed violations, meaning more tolerance to misclassifications. This generally leads to a simpler, more robust model that might underfit if $C$ is too low.</span>
<span id="cb11-601"><a href="#cb11-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-602"><a href="#cb11-602" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb11-603"><a href="#cb11-603" aria-hidden="true" tabindex="-1"></a>The regularization parameter $C$ controls the trade-off between margin width and classification accuracy. **Cross-validation** is commonly used to select the optimal value of $C$ by evaluating the model’s performance across different values of $C$ and choosing the one that generalizes best to unseen data.&lt;/p&gt;</span>
<span id="cb11-604"><a href="#cb11-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-607"><a href="#cb11-607" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-608"><a href="#cb11-608" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb11-609"><a href="#cb11-609" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-610"><a href="#cb11-610" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-611"><a href="#cb11-611" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb11-612"><a href="#cb11-612" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb11-613"><a href="#cb11-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-614"><a href="#cb11-614" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic dataset</span></span>
<span id="cb11-615"><a href="#cb11-615" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">40</span>, centers<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb11-616"><a href="#cb11-616" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.where(y <span class="op">==</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># Transform labels to -1 and +1 for SVM</span></span>
<span id="cb11-617"><a href="#cb11-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-618"><a href="#cb11-618" aria-hidden="true" tabindex="-1"></a><span class="co"># Different values of C for comparison</span></span>
<span id="cb11-619"><a href="#cb11-619" aria-hidden="true" tabindex="-1"></a>C_values <span class="op">=</span> [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">100</span>]</span>
<span id="cb11-620"><a href="#cb11-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-621"><a href="#cb11-621" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb11-622"><a href="#cb11-622" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">15</span>))  <span class="co"># Adjust figure size for vertical layout</span></span>
<span id="cb11-623"><a href="#cb11-623" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)  <span class="co"># Set background color for the figure</span></span>
<span id="cb11-624"><a href="#cb11-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-625"><a href="#cb11-625" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, C <span class="kw">in</span> <span class="bu">enumerate</span>(C_values):</span>
<span id="cb11-626"><a href="#cb11-626" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit SVM model with the given C value</span></span>
<span id="cb11-627"><a href="#cb11-627" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span>C)</span>
<span id="cb11-628"><a href="#cb11-628" aria-hidden="true" tabindex="-1"></a>    model.fit(X, y)</span>
<span id="cb11-629"><a href="#cb11-629" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-630"><a href="#cb11-630" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mesh to plot decision boundaries</span></span>
<span id="cb11-631"><a href="#cb11-631" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-632"><a href="#cb11-632" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-633"><a href="#cb11-633" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv">200</span>), np.linspace(y_min, y_max, <span class="dv">200</span>))</span>
<span id="cb11-634"><a href="#cb11-634" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-635"><a href="#cb11-635" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot decision boundary and margin</span></span>
<span id="cb11-636"><a href="#cb11-636" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> model.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb11-637"><a href="#cb11-637" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb11-638"><a href="#cb11-638" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-639"><a href="#cb11-639" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="bu">len</span>(C_values), <span class="dv">1</span>, i <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adjust to create vertical subplots</span></span>
<span id="cb11-640"><a href="#cb11-640" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#f4f4f4'</span>)  <span class="co"># Set background color for the plot area</span></span>
<span id="cb11-641"><a href="#cb11-641" aria-hidden="true" tabindex="-1"></a>    plt.contourf(xx, yy, Z, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-642"><a href="#cb11-642" aria-hidden="true" tabindex="-1"></a>    plt.contour(xx, yy, Z, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-643"><a href="#cb11-643" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-644"><a href="#cb11-644" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot training points</span></span>
<span id="cb11-645"><a href="#cb11-645" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">30</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-646"><a href="#cb11-646" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"SVM with Soft Margin (C=</span><span class="sc">{</span>C<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb11-647"><a href="#cb11-647" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb11-648"><a href="#cb11-648" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb11-649"><a href="#cb11-649" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-650"><a href="#cb11-650" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mark support vectors</span></span>
<span id="cb11-651"><a href="#cb11-651" aria-hidden="true" tabindex="-1"></a>    plt.scatter(model.support_vectors_[:, <span class="dv">0</span>], model.support_vectors_[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">100</span>, facecolors<span class="op">=</span><span class="st">'none'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-652"><a href="#cb11-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-653"><a href="#cb11-653" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Effect of Regularization Parameter C on Soft Margin SVM"</span>, y<span class="op">=</span><span class="fl">0.96</span>)</span>
<span id="cb11-654"><a href="#cb11-654" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.95</span>])</span>
<span id="cb11-655"><a href="#cb11-655" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-656"><a href="#cb11-656" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-657"><a href="#cb11-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-658"><a href="#cb11-658" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python Implementation of SVM  </span></span>
<span id="cb11-659"><a href="#cb11-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-660"><a href="#cb11-660" aria-hidden="true" tabindex="-1"></a><span class="fu">### LinearSVC  </span></span>
<span id="cb11-661"><a href="#cb11-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-662"><a href="#cb11-662" aria-hidden="true" tabindex="-1"></a>Let's first create the data </span>
<span id="cb11-663"><a href="#cb11-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-666"><a href="#cb11-666" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-667"><a href="#cb11-667" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb11-668"><a href="#cb11-668" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb11-669"><a href="#cb11-669" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb11-670"><a href="#cb11-670" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> np.random.random((n_rows,<span class="dv">2</span>))</span>
<span id="cb11-671"><a href="#cb11-671" aria-hidden="true" tabindex="-1"></a>X_1 <span class="op">=</span> X1[(X1[:,<span class="dv">1</span>]<span class="op">-</span>X1[:,<span class="dv">0</span>])<span class="op">&lt;=</span> <span class="op">-</span>diff,:]</span>
<span id="cb11-672"><a href="#cb11-672" aria-hidden="true" tabindex="-1"></a>X_2 <span class="op">=</span> X1[(X1[:,<span class="dv">1</span>]<span class="op">-</span>X1[:,<span class="dv">0</span>])<span class="op">&gt;=</span> diff,:]</span>
<span id="cb11-673"><a href="#cb11-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-674"><a href="#cb11-674" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.append(X_1, X_2, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-675"><a href="#cb11-675" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.empty(np.shape(X)[<span class="dv">0</span>])</span>
<span id="cb11-676"><a href="#cb11-676" aria-hidden="true" tabindex="-1"></a>y[(X[:,<span class="dv">1</span>]<span class="op">-</span>X[:,<span class="dv">0</span>])<span class="op">&lt;=</span> <span class="op">-</span>diff] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-677"><a href="#cb11-677" aria-hidden="true" tabindex="-1"></a>y[(X[:,<span class="dv">1</span>]<span class="op">-</span>X[:,<span class="dv">0</span>])<span class="op">&gt;=</span> diff] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-678"><a href="#cb11-678" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb11-679"><a href="#cb11-679" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-680"><a href="#cb11-680" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb11-681"><a href="#cb11-681" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb11-682"><a href="#cb11-682" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb11-683"><a href="#cb11-683" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-684"><a href="#cb11-684" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-685"><a href="#cb11-685" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-686"><a href="#cb11-686" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-687"><a href="#cb11-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>   </span>
<span id="cb11-688"><a href="#cb11-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-689"><a href="#cb11-689" aria-hidden="true" tabindex="-1"></a>Now we apply linear SVM classifier  </span>
<span id="cb11-690"><a href="#cb11-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-693"><a href="#cb11-693" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-694"><a href="#cb11-694" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb11-695"><a href="#cb11-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-696"><a href="#cb11-696" aria-hidden="true" tabindex="-1"></a>maximum_margin_SVC <span class="op">=</span> LinearSVC(C<span class="op">=</span> <span class="dv">1000</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, dual<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb11-697"><a href="#cb11-697" aria-hidden="true" tabindex="-1"></a>maximum_margin_SVC.fit(X,y)</span>
<span id="cb11-698"><a href="#cb11-698" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb11-699"><a href="#cb11-699" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb11-700"><a href="#cb11-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-701"><a href="#cb11-701" aria-hidden="true" tabindex="-1"></a>x1,x2 <span class="op">=</span> np.meshgrid(x1,x2)</span>
<span id="cb11-702"><a href="#cb11-702" aria-hidden="true" tabindex="-1"></a>x1x2 <span class="op">=</span> np.vstack([x1.ravel(),x2.ravel()]).T</span>
<span id="cb11-703"><a href="#cb11-703" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> maximum_margin_SVC.decision_function(x1x2).reshape(x1.shape)</span>
<span id="cb11-704"><a href="#cb11-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-705"><a href="#cb11-705" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">0</span>],X[y<span class="op">==-</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Training -1'</span>)</span>
<span id="cb11-706"><a href="#cb11-706" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>],X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Training 1'</span>)</span>
<span id="cb11-707"><a href="#cb11-707" aria-hidden="true" tabindex="-1"></a>plt.contour(x1,x2,z, colors<span class="op">=</span><span class="st">'k'</span>,levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.7</span>, linestyles<span class="op">=</span>[<span class="st">'--'</span>,<span class="st">'-'</span>,<span class="st">'--'</span>])</span>
<span id="cb11-708"><a href="#cb11-708" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-709"><a href="#cb11-709" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb11-710"><a href="#cb11-710" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb11-711"><a href="#cb11-711" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb11-712"><a href="#cb11-712" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb11-713"><a href="#cb11-713" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb11-714"><a href="#cb11-714" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-715"><a href="#cb11-715" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-716"><a href="#cb11-716" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-717"><a href="#cb11-717" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-718"><a href="#cb11-718" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb11-719"><a href="#cb11-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-720"><a href="#cb11-720" aria-hidden="true" tabindex="-1"></a>The data that we used to explain the polynomial kernels  </span>
<span id="cb11-721"><a href="#cb11-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-724"><a href="#cb11-724" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-725"><a href="#cb11-725" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb11-726"><a href="#cb11-726" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>np.random.random(<span class="dv">50</span>)<span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-727"><a href="#cb11-727" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.ones(<span class="bu">len</span>(X))</span>
<span id="cb11-728"><a href="#cb11-728" aria-hidden="true" tabindex="-1"></a>y[(X<span class="op">&gt;</span><span class="fl">0.35</span>) <span class="op">|</span> (X<span class="op">&lt;-</span><span class="fl">0.35</span>)] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb11-729"><a href="#cb11-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-730"><a href="#cb11-730" aria-hidden="true" tabindex="-1"></a>svc <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">2</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb11-731"><a href="#cb11-731" aria-hidden="true" tabindex="-1"></a>svc.fit(X.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>),y)</span>
<span id="cb11-732"><a href="#cb11-732" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==-</span><span class="dv">1</span>],np.ones(<span class="bu">sum</span>(y<span class="op">==-</span><span class="dv">1</span>)), c<span class="op">=</span><span class="st">'blue'</span>,label<span class="op">=</span><span class="st">'class -1'</span>)</span>
<span id="cb11-733"><a href="#cb11-733" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>],np.ones(<span class="bu">sum</span>(y<span class="op">==</span><span class="dv">1</span>)), c<span class="op">=</span><span class="st">'red'</span>,label<span class="op">=</span><span class="st">'class 1'</span>)</span>
<span id="cb11-734"><a href="#cb11-734" aria-hidden="true" tabindex="-1"></a>dcsns <span class="op">=</span> svc.decision_function(np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10000</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb11-735"><a href="#cb11-735" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb11-736"><a href="#cb11-736" aria-hidden="true" tabindex="-1"></a>    np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10000</span>)[dcsns<span class="op">==</span><span class="dv">0</span>],</span>
<span id="cb11-737"><a href="#cb11-737" aria-hidden="true" tabindex="-1"></a>    np.ones(<span class="dv">10000</span>)[dcsns<span class="op">==</span><span class="dv">0</span>],</span>
<span id="cb11-738"><a href="#cb11-738" aria-hidden="true" tabindex="-1"></a>    marker<span class="op">=</span><span class="st">'|'</span>,</span>
<span id="cb11-739"><a href="#cb11-739" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span> <span class="dv">400</span>,</span>
<span id="cb11-740"><a href="#cb11-740" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span><span class="st">'green'</span>,</span>
<span id="cb11-741"><a href="#cb11-741" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">'Decision Boundary'</span></span>
<span id="cb11-742"><a href="#cb11-742" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-743"><a href="#cb11-743" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-744"><a href="#cb11-744" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-745"><a href="#cb11-745" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-746"><a href="#cb11-746" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-747"><a href="#cb11-747" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb11-748"><a href="#cb11-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-749"><a href="#cb11-749" aria-hidden="true" tabindex="-1"></a>For the higher dimensions  </span>
<span id="cb11-750"><a href="#cb11-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-753"><a href="#cb11-753" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb11-754"><a href="#cb11-754" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-overflow: wrap</span></span>
<span id="cb11-755"><a href="#cb11-755" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">300</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-756"><a href="#cb11-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-757"><a href="#cb11-757" aria-hidden="true" tabindex="-1"></a><span class="co"># Create SVM models with polynomial and RBF kernels</span></span>
<span id="cb11-758"><a href="#cb11-758" aria-hidden="true" tabindex="-1"></a>model_poly <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">2</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb11-759"><a href="#cb11-759" aria-hidden="true" tabindex="-1"></a>model_rbf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="dv">1</span>, C<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb11-760"><a href="#cb11-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-761"><a href="#cb11-761" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models</span></span>
<span id="cb11-762"><a href="#cb11-762" aria-hidden="true" tabindex="-1"></a>model_poly.fit(X, y)</span>
<span id="cb11-763"><a href="#cb11-763" aria-hidden="true" tabindex="-1"></a>model_rbf.fit(X, y)</span>
<span id="cb11-764"><a href="#cb11-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-765"><a href="#cb11-765" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mesh to plot decision boundaries</span></span>
<span id="cb11-766"><a href="#cb11-766" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-767"><a href="#cb11-767" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-768"><a href="#cb11-768" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv">300</span>), np.linspace(y_min, y_max, <span class="dv">300</span>))</span>
<span id="cb11-769"><a href="#cb11-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-770"><a href="#cb11-770" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb11-771"><a href="#cb11-771" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">7.9</span>, <span class="dv">4</span>))</span>
<span id="cb11-772"><a href="#cb11-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-773"><a href="#cb11-773" aria-hidden="true" tabindex="-1"></a><span class="co"># Polynomial Kernel</span></span>
<span id="cb11-774"><a href="#cb11-774" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb11-775"><a href="#cb11-775" aria-hidden="true" tabindex="-1"></a>Z_poly <span class="op">=</span> model_poly.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb11-776"><a href="#cb11-776" aria-hidden="true" tabindex="-1"></a>Z_poly <span class="op">=</span> Z_poly.reshape(xx.shape)</span>
<span id="cb11-777"><a href="#cb11-777" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z_poly, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-778"><a href="#cb11-778" aria-hidden="true" tabindex="-1"></a>plt.contour(xx, yy, Z_poly, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-779"><a href="#cb11-779" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">20</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-780"><a href="#cb11-780" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"SVM with Polynomial Kernel"</span>)</span>
<span id="cb11-781"><a href="#cb11-781" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb11-782"><a href="#cb11-782" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb11-783"><a href="#cb11-783" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-784"><a href="#cb11-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-785"><a href="#cb11-785" aria-hidden="true" tabindex="-1"></a><span class="co"># RBF Kernel</span></span>
<span id="cb11-786"><a href="#cb11-786" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb11-787"><a href="#cb11-787" aria-hidden="true" tabindex="-1"></a>Z_rbf <span class="op">=</span> model_rbf.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb11-788"><a href="#cb11-788" aria-hidden="true" tabindex="-1"></a>Z_rbf <span class="op">=</span> Z_rbf.reshape(xx.shape)</span>
<span id="cb11-789"><a href="#cb11-789" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z_rbf, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], colors<span class="op">=</span>[<span class="st">'#FFAAAA'</span>, <span class="st">'#AAAAFF'</span>, <span class="st">'#AAAAFF'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-790"><a href="#cb11-790" aria-hidden="true" tabindex="-1"></a>plt.contour(xx, yy, Z_rbf, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], linestyles<span class="op">=</span>[<span class="st">'--'</span>, <span class="st">'-'</span>, <span class="st">'--'</span>], colors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-791"><a href="#cb11-791" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>plt.cm.bwr, s<span class="op">=</span><span class="dv">20</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb11-792"><a href="#cb11-792" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"SVM with RBF Kernel"</span>)</span>
<span id="cb11-793"><a href="#cb11-793" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb11-794"><a href="#cb11-794" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb11-795"><a href="#cb11-795" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-796"><a href="#cb11-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-797"><a href="#cb11-797" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Polynomial and RBF Kernels on Nonlinear Data"</span>)</span>
<span id="cb11-798"><a href="#cb11-798" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])</span>
<span id="cb11-799"><a href="#cb11-799" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-800"><a href="#cb11-800" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-801"><a href="#cb11-801" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-802"><a href="#cb11-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-803"><a href="#cb11-803" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-804"><a href="#cb11-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-805"><a href="#cb11-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-806"><a href="#cb11-806" aria-hidden="true" tabindex="-1"></a><span class="fu">## References  </span></span>
<span id="cb11-807"><a href="#cb11-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-808"><a href="#cb11-808" aria-hidden="true" tabindex="-1"></a><span class="fu">### Books</span></span>
<span id="cb11-809"><a href="#cb11-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-810"><a href="#cb11-810" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer</span>
<span id="cb11-811"><a href="#cb11-811" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. 2nd Edition. Springer.  </span>
<span id="cb11-812"><a href="#cb11-812" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Boyd, S., &amp; Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.  </span>
<span id="cb11-813"><a href="#cb11-813" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Schölkopf, B., &amp; Smola, A. J. (2002). *Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond*. MIT Press.  </span>
<span id="cb11-814"><a href="#cb11-814" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.  </span>
<span id="cb11-815"><a href="#cb11-815" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Vapnik, V. (1998). *Statistical Learning Theory*. Wiley-Interscience.</span>
<span id="cb11-816"><a href="#cb11-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-817"><a href="#cb11-817" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lecture Notes</span></span>
<span id="cb11-818"><a href="#cb11-818" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Andrew Ng's *Machine Learning* course on Coursera, particularly the lectures on Support Vector Machines, covering linear SVMs, geometric interpretation, and constraints.  </span>
<span id="cb11-819"><a href="#cb11-819" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>StatQuest with Josh Starmer</span>
<span id="cb11-820"><a href="#cb11-820" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data Science Bootcamp by *The Erdos Institute*</span>
<span id="cb11-821"><a href="#cb11-821" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-822"><a href="#cb11-822" aria-hidden="true" tabindex="-1"></a><span class="fu">### Journals and Articles</span></span>
<span id="cb11-823"><a href="#cb11-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-824"><a href="#cb11-824" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Cortes, C., &amp; Vapnik, V. (1995). "Support-vector networks." *Machine Learning*, 20(3), 273-297.  </span>
<span id="cb11-825"><a href="#cb11-825" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Aizerman, M. A., Braverman, E. M., &amp; Rozonoer, L. I. (1964). "Theoretical foundations of the potential function method in pattern recognition learning." *Automation and Remote Control*, 25, 821-837.  </span>
<span id="cb11-826"><a href="#cb11-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-827"><a href="#cb11-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-828"><a href="#cb11-828" aria-hidden="true" tabindex="-1"></a>---  </span>
<span id="cb11-829"><a href="#cb11-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-830"><a href="#cb11-830" aria-hidden="true" tabindex="-1"></a>**Share on**</span>
<span id="cb11-831"><a href="#cb11-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-832"><a href="#cb11-832" aria-hidden="true" tabindex="-1"></a>::::{.columns}</span>
<span id="cb11-833"><a href="#cb11-833" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb11-834"><a href="#cb11-834" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1877F2; text-decoration: none;"&gt;</span>
<span id="cb11-835"><a href="#cb11-835" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-836"><a href="#cb11-836" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands facebook size=3x &gt;}}</span>
<span id="cb11-837"><a href="#cb11-837" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb11-838"><a href="#cb11-838" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-839"><a href="#cb11-839" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb11-840"><a href="#cb11-840" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-841"><a href="#cb11-841" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb11-842"><a href="#cb11-842" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#0077B5; text-decoration: none;"&gt;</span>
<span id="cb11-843"><a href="#cb11-843" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-844"><a href="#cb11-844" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands linkedin size=3x &gt;}}</span>
<span id="cb11-845"><a href="#cb11-845" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb11-846"><a href="#cb11-846" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-847"><a href="#cb11-847" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb11-848"><a href="#cb11-848" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-849"><a href="#cb11-849" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb11-850"><a href="#cb11-850" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;"&gt;</span>
<span id="cb11-851"><a href="#cb11-851" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-852"><a href="#cb11-852" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands twitter size=3x &gt;}}</span>
<span id="cb11-853"><a href="#cb11-853" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb11-854"><a href="#cb11-854" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-855"><a href="#cb11-855" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb11-856"><a href="#cb11-856" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb11-857"><a href="#cb11-857" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-858"><a href="#cb11-858" aria-hidden="true" tabindex="-1"></a>&lt;script src="https://giscus.app/client.js"</span>
<span id="cb11-859"><a href="#cb11-859" aria-hidden="true" tabindex="-1"></a>        data-repo="mrislambd/mrislambd.github.io" </span>
<span id="cb11-860"><a href="#cb11-860" aria-hidden="true" tabindex="-1"></a>        data-repo-id="R_kgDOMV8crA"</span>
<span id="cb11-861"><a href="#cb11-861" aria-hidden="true" tabindex="-1"></a>        data-category="Announcements"</span>
<span id="cb11-862"><a href="#cb11-862" aria-hidden="true" tabindex="-1"></a>        data-category-id="DIC_kwDOMV8crM4CjbQW"</span>
<span id="cb11-863"><a href="#cb11-863" aria-hidden="true" tabindex="-1"></a>        data-mapping="pathname"</span>
<span id="cb11-864"><a href="#cb11-864" aria-hidden="true" tabindex="-1"></a>        data-strict="0"</span>
<span id="cb11-865"><a href="#cb11-865" aria-hidden="true" tabindex="-1"></a>        data-reactions-enabled="1"</span>
<span id="cb11-866"><a href="#cb11-866" aria-hidden="true" tabindex="-1"></a>        data-emit-metadata="0"</span>
<span id="cb11-867"><a href="#cb11-867" aria-hidden="true" tabindex="-1"></a>        data-input-position="bottom"</span>
<span id="cb11-868"><a href="#cb11-868" aria-hidden="true" tabindex="-1"></a>        data-theme="light"</span>
<span id="cb11-869"><a href="#cb11-869" aria-hidden="true" tabindex="-1"></a>        data-lang="en"</span>
<span id="cb11-870"><a href="#cb11-870" aria-hidden="true" tabindex="-1"></a>        crossorigin="anonymous"</span>
<span id="cb11-871"><a href="#cb11-871" aria-hidden="true" tabindex="-1"></a>        async&gt;</span>
<span id="cb11-872"><a href="#cb11-872" aria-hidden="true" tabindex="-1"></a>&lt;/script&gt;</span>
<span id="cb11-873"><a href="#cb11-873" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-874"><a href="#cb11-874" aria-hidden="true" tabindex="-1"></a>&lt;div id="fb-root"&gt;&lt;/div&gt;</span>
<span id="cb11-875"><a href="#cb11-875" aria-hidden="true" tabindex="-1"></a>&lt;script async defer crossorigin="anonymous"</span>
<span id="cb11-876"><a href="#cb11-876" aria-hidden="true" tabindex="-1"></a> src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"&gt;&lt;/script&gt;</span>
<span id="cb11-877"><a href="#cb11-877" aria-hidden="true" tabindex="-1"></a>&lt;div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/svm/" data-width="800" data-numposts="5"&gt;&lt;/div&gt;  </span>
<span id="cb11-878"><a href="#cb11-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-879"><a href="#cb11-879" aria-hidden="true" tabindex="-1"></a>**You may also like**</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Powered by <a href="https://quarto.org/">Quarto</a> 1.5.54</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024 @ Rafiq Islam
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.txt">
<p>License</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/rafiqr35" target="_blank">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://youtube.com/@quanttube" target="_blank">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:rafiqfsu@gmail.com?subject&amp;body" target="_blank">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"loop":false,"closeEffect":"zoom","descPosition":"bottom","selector":".lightbox","openEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rafiq Islam">
<meta name="dcterms.date" content="2024-09-28">

<title>Unsupervised Learning: K-Means Clustering – Mohammad Rafiqul Islam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//_assets/images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-listing/list.min.js"></script>
<script src="../../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-image','listing-date','listing-title','listing-author','listing-reading-time',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      page: 18,
    pagination: { item: "<li class='page-item'><a class='page page-link' href='#'></a></li>" },
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z5NP67GHFC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Z5NP67GHFC', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6878992848042528" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Unsupervised Learning: K-Means Clustering – Mohammad Rafiqul Islam">
<meta property="og:description" content="">
<meta property="og:image" content="https://mrislambd.github.io/dsandml/kmeans/kmeans.png">
<meta property="og:site_name" content="Mohammad Rafiqul Islam">
<meta property="og:image:height" content="480">
<meta property="og:image:width" content="672">
<meta name="twitter:title" content="Unsupervised Learning: K-Means Clustering – Mohammad Rafiqul Islam">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mrislambd.github.io/dsandml/kmeans/kmeans.png">
<meta name="twitter:image-height" content="480">
<meta name="twitter:image-width" content="672">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../dsandml/kmeans/index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../_assets/images/fsu-logo.png" alt="Florida State University" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../dsandml/kmeans/index.html">
    <span class="navbar-title">Mohammad Rafiqul Islam</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html"> 
<span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mohammad-rafiqul-islam/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mrislambd" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#mathematics-behind-k-means" id="toc-mathematics-behind-k-means" class="nav-link" data-scroll-target="#mathematics-behind-k-means">Mathematics Behind K-Means</a>
  <ul class="collapse">
  <li><a href="#objective-function-inertia" id="toc-objective-function-inertia" class="nav-link" data-scroll-target="#objective-function-inertia">Objective Function (Inertia)</a></li>
  <li><a href="#how-to-choose-the-best-k-value" id="toc-how-to-choose-the-best-k-value" class="nav-link" data-scroll-target="#how-to-choose-the-best-k-value">How to Choose the Best <span class="math inline">\(k\)</span> Value?</a></li>
  </ul></li>
  <li><a href="#python-implementation-of-k-means" id="toc-python-implementation-of-k-means" class="nav-link" data-scroll-target="#python-implementation-of-k-means">Python Implementation of K-Means</a>
  <ul class="collapse">
  <li><a href="#synthetic-data" id="toc-synthetic-data" class="nav-link" data-scroll-target="#synthetic-data">Synthetic Data</a></li>
  <li><a href="#real-data" id="toc-real-data" class="nav-link" data-scroll-target="#real-data">Real Data</a></li>
  </ul></li>
  <li><a href="#limitations-of-k-means-clustering" id="toc-limitations-of-k-means-clustering" class="nav-link" data-scroll-target="#limitations-of-k-means-clustering">Limitations of K-Means Clustering</a>
  <ul class="collapse">
  <li><a href="#assumption-of-spherical-clusters" id="toc-assumption-of-spherical-clusters" class="nav-link" data-scroll-target="#assumption-of-spherical-clusters">1. <strong>Assumption of Spherical Clusters</strong></a></li>
  <li><a href="#sensitivity-to-initialization" id="toc-sensitivity-to-initialization" class="nav-link" data-scroll-target="#sensitivity-to-initialization">2. <strong>Sensitivity to Initialization</strong></a></li>
  <li><a href="#needs-to-specify-k-in-advance" id="toc-needs-to-specify-k-in-advance" class="nav-link" data-scroll-target="#needs-to-specify-k-in-advance">3. <strong>Needs to Specify <code>k</code> in Advance</strong></a></li>
  <li><a href="#outliers-and-noise-sensitivity" id="toc-outliers-and-noise-sensitivity" class="nav-link" data-scroll-target="#outliers-and-noise-sensitivity">4. <strong>Outliers and Noise Sensitivity</strong></a></li>
  <li><a href="#equal-cluster-size-assumption" id="toc-equal-cluster-size-assumption" class="nav-link" data-scroll-target="#equal-cluster-size-assumption">5. <strong>Equal Cluster Size Assumption</strong></a></li>
  <li><a href="#non-convex-shapes" id="toc-non-convex-shapes" class="nav-link" data-scroll-target="#non-convex-shapes">6. <strong>Non-Convex Shapes</strong></a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Unsupervised Learning: K-Means Clustering</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Data Science</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Artificial Intelligence</div>
    <div class="quarto-category">Data Engineering</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rafiq Islam </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 28, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Clustering is a fundamental technique in unsupervised learning where the goal is to group similar data points into clusters. One of the most popular algorithms for clustering is <strong>K-Means</strong>. K-Means is a centroid-based algorithm that partitions the dataset into <span class="math inline">\(k\)</span> clusters. The algorithm iterates over data points, assigning each to one of <span class="math inline">\(k\)</span> centroids (cluster centers), and then updates the centroids based on the current assignments. The objective is to minimize the sum of squared distances (also known as inertia) between each data point and its assigned centroid.
</p>
</section>
<section id="mathematics-behind-k-means" class="level2">
<h2 class="anchored" data-anchor-id="mathematics-behind-k-means">Mathematics Behind K-Means</h2>
<p>The K-Means algorithm works through the following key steps:</p>
<ol type="1">
<li><p><strong>Initialization</strong>: Randomly select <span class="math inline">\(k\)</span> points from the dataset as initial centroids.</p></li>
<li><p><strong>Assignment Step</strong>: For each data point, assign it to the closest centroid based on the Euclidean distance:</p>
<p><span class="math display">\[
\text{distance}(x_i, \mu_j) = \sqrt{\sum_{d=1}^{D} (x_i^d - \mu_j^d)^2}
\]</span></p></li>
</ol>
<p>where:</p>
<ul>
<li><span class="math inline">\(x_i\)</span> is the i-th data point.</li>
<li><span class="math inline">\(\mu_j\)</span> is the j-th centroid.</li>
<li><span class="math inline">\(D\)</span> is the number of features (dimensions).</li>
</ul>
<ol start="3" type="1">
<li><p><strong>Update Step</strong>: After all data points are assigned, recalculate the centroid of each cluster as the mean of all data points assigned to it:</p>
<p><span class="math display">\[
\mu_j = \frac{1}{n_j} \sum_{i=1}^{n_j} x_i
\]</span> where <span class="math inline">\(n_j\)</span> is the number of points in cluster <code>j</code>.</p></li>
<li><p><strong>Repeat</strong>: The assignment and update steps are repeated until the centroids no longer change or the maximum number of iterations is reached.</p></li>
</ol>
<section id="objective-function-inertia" class="level3">
<h3 class="anchored" data-anchor-id="objective-function-inertia">Objective Function (Inertia)</h3>
<p>The objective of K-Means is to minimize the following cost function, also called inertia or within-cluster sum of squares:</p>
<p><span class="math display">\[
J = \sum_{j=1}^{k} \sum_{i=1}^{n_j} \|x_i - \mu_j\|^2
\]</span></p>
<p>This measures how compact the clusters are, i.e., how close the points within each cluster are to their centroid.</p>
</section>
<section id="how-to-choose-the-best-k-value" class="level3">
<h3 class="anchored" data-anchor-id="how-to-choose-the-best-k-value">How to Choose the Best <span class="math inline">\(k\)</span> Value?</h3>
<p>One of the critical tasks in K-Means clustering is selecting the optimal number of clusters (<span class="math inline">\(k\)</span>). Several methods can be used:</p>
<section id="the-elbow-method" class="level4">
<h4 class="anchored" data-anchor-id="the-elbow-method">1. The Elbow Method</h4>
<p>The most common way to determine the best <span class="math inline">\(k\)</span> is the <strong>elbow method</strong>. It involves plotting the inertia (the sum of squared distances from each point to its assigned cluster centroid) for different values of <span class="math inline">\(k\)</span>. The point where the inertia starts to flatten out (forming an elbow) is considered a good choice for <span class="math inline">\(k\)</span>.</p>
</section>
<section id="silhouette-score" class="level4">
<h4 class="anchored" data-anchor-id="silhouette-score">2. Silhouette Score</h4>
<p>The <strong>silhouette score</strong> measures how similar each point is to its own cluster (cohesion) compared to other clusters (separation). It ranges from -1 to 1:</p>
<ul>
<li><span class="math inline">\(1\)</span> indicates that the point is well inside its cluster.<br>
</li>
<li><span class="math inline">\(0\)</span> means the point is on the boundary between two clusters.<br>
</li>
<li>Negative values indicate the point may have been assigned to the wrong cluster.</li>
</ul>
</section>
<section id="gap-statistic" class="level4">
<h4 class="anchored" data-anchor-id="gap-statistic">3. Gap Statistic</h4>
<p>The <strong>gap statistic</strong> compares the total within-cluster variation for different values of <span class="math inline">\(k\)</span> with the expected value under null reference distribution. The optimal number of clusters is where the gap statistic is the largest.</p>
<hr>
</section>
</section>
</section>
<section id="python-implementation-of-k-means" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-of-k-means">Python Implementation of K-Means</h2>
<section id="synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data">Synthetic Data</h3>
<p>Let’s implement K-Means clustering using Python with visualizations and explore how to choose the best value of <span class="math inline">\(k\)</span> using the elbow method.</p>
<div id="471ceda5" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># For plotting purposes</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll create a simple dataset with 4 distinct clusters for visualization.</p>
<div id="24bcde9d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset with 4 clusters</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">500</span>, centers<span class="op">=</span><span class="dv">4</span>, cluster_std<span class="op">=</span><span class="fl">0.60</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the dataset</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Dataset with 4 Clusters'</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/cell-3-output-1.png" width="576" height="435" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can now apply K-Means clustering with different values of <span class="math inline">\(k\)</span> and observe how the clusters are formed.</p>
<div id="28e7c3ed" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit KMeans with k=4 (since we know we generated 4 clusters)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict clusters</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>y_kmeans <span class="op">=</span> kmeans.predict(X)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the clustered data</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y_kmeans, s<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the centroids</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(centers[:, <span class="dv">0</span>], centers[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'K-Means Clustering with k=4'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'kmeans.png'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/cell-4-output-1.png" width="576" height="435" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>To determine the optimal number of clusters, we’ll plot the inertia for different values of <span class="math inline">\(k\)</span> using the elbow method.</p>
<div id="dc03a0b9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test multiple k values</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>inertia <span class="op">=</span> []</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    inertia.append(kmeans.inertia_)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the inertia vs. k values</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, inertia, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow Method: Choosing the Optimal k'</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertia'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/cell-5-output-1.png" width="611" height="456" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We see that the curve starts to flatten at <span class="math inline">\(k=4\)</span>, suggesting this is a good choice for the number of clusters. Let’s also compute the silhouette score for different values of <span class="math inline">\(k\)</span> to confirm our choice.</p>
<div id="841cb367" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>sil_scores <span class="op">=</span> []</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">10</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.predict(X)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    sil_scores.append(silhouette_score(X, labels))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Silhouette Score vs. k</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">10</span>), sil_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhouette Score for Different k Values'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/cell-6-output-1.png" width="606" height="456" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="real-data" class="level3">
<h3 class="anchored" data-anchor-id="real-data">Real Data</h3>
<strong>Description</strong>:<br>

<p style="text-align:justify">
This dataset contains information about customers of a shopping mall, including their annual income, spending score, gender, and age.
</p>
<p><strong>Goal:</strong> Our goal is to segment customers into different groups based on their spending behavior and income.</p>
<p><strong>Columns</strong>:<br>
- <code>CustomerID</code>: Unique identifier for each customer.<br>
- <code>Gender</code>: The gender of the customer (Male or Female).<br>
- <code>Age</code>: Age of the customer.<br>
- <code>Annual Income</code>: Annual income of the customer in thousands of dollars.<br>
- <code>Spending Score</code>: A score assigned by the mall based on customer behavior and spending patterns.</p>
<p><strong>Data Source:</strong> You can find the Mall Customer Segmentation data on <a href="https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python" style="text-decoration:none" target="_blank">Kaggle</a>.</p>
<div id="9c213778" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mall <span class="op">=</span> pd.read_csv(<span class="st">'Mall_Customers.csv'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>mall.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Annual Income (k$)</th>
<th data-quarto-table-cell-role="th">Spending Score (1-100)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Male</td>
<td>19</td>
<td>15</td>
<td>39</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Male</td>
<td>21</td>
<td>15</td>
<td>81</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Female</td>
<td>20</td>
<td>16</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Female</td>
<td>23</td>
<td>16</td>
<td>77</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Female</td>
<td>31</td>
<td>17</td>
<td>40</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="5edf40a8" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Information</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.info())</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for Missing Data</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.isnull().<span class="bu">sum</span>())</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Description</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>mall.rename(columns<span class="op">=</span>{<span class="st">'CustomerID'</span>:<span class="st">'ID'</span>,<span class="st">'Annual Income (k$)'</span>:<span class="st">'Income'</span>,<span class="st">'Spending Score (1-100)'</span>:<span class="st">'SpendingScore'</span>},inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>cmall <span class="op">=</span> mall.drop(<span class="st">'ID'</span>,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cmall.describe().loc[[<span class="st">'mean'</span>,<span class="st">'std'</span>,<span class="st">'min'</span>,<span class="st">'max'</span>]].T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 200 entries, 0 to 199
Data columns (total 5 columns):
 #   Column                  Non-Null Count  Dtype 
---  ------                  --------------  ----- 
 0   CustomerID              200 non-null    int64 
 1   Gender                  200 non-null    object
 2   Age                     200 non-null    int64 
 3   Annual Income (k$)      200 non-null    int64 
 4   Spending Score (1-100)  200 non-null    int64 
dtypes: int64(4), object(1)
memory usage: 7.9+ KB
None


CustomerID                0
Gender                    0
Age                       0
Annual Income (k$)        0
Spending Score (1-100)    0
dtype: int64


                mean        std   min    max
Age            38.85  13.969007  18.0   70.0
Income         60.56  26.264721  15.0  137.0
SpendingScore  50.20  25.823522   1.0   99.0</code></pre>
</div>
</div>
<p><strong>Pre-Process:</strong> Since our data contains categorical variable <code>Gender</code>, we need to encode this column and scale the numerical features like <code>Age</code>, <code>Annual Income</code>, and <code>Spending Score</code>.</p>
<div id="6ed13b7d" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mall[[<span class="st">'Age'</span>,<span class="st">'Income'</span>,<span class="st">'SpendingScore'</span>]]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_scaled[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[-1.42456879 -1.73899919 -0.43480148]
 [-1.28103541 -1.73899919  1.19570407]
 [-1.3528021  -1.70082976 -1.71591298]
 [-1.13750203 -1.70082976  1.04041783]
 [-0.56336851 -1.66266033 -0.39597992]]</code></pre>
</div>
</div>
<p>Next we use the <code>Elbow</code> method to find the best <span class="math inline">\(k\)</span>, the number of clusters</p>
<div id="2e59d17b" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">15</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>inertia <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X_scaled)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    inertia.append(kmeans.inertia_)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values,inertia, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow method to find $k$'</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters $k$'</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertia'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.show() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="index_files/figure-html/cell-10-output-1.png" width="602" height="456" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The elbow point in the plot (where the decrease in inertia starts to slow) helps determine the optimal number of clusters. Let’s say we find that <span class="math inline">\(k=5\)</span> looks like a reasonable choice from the plot.</p>
<p>To further validate the choice of <span class="math inline">\(k\)</span>, let’s compute the <code>silhouette</code> score for different cluster numbers. A higher <code>silhouette</code> score indicates better-defined clusters</p>
<div id="12bc53bd" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>sil_scores <span class="op">=</span> []</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">15</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    sil_scores.append(silhouette_score(X_scaled,labels))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">15</span>),sil_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhoutte method to find $k$'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters $k$'</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhoutte Score'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>plt.show() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="index_files/figure-html/cell-11-output-1.png" width="606" height="456" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Next, we apply <span class="math inline">\(k=5\)</span> clusters</p>
<div id="7ba01171" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">9.5</span>,<span class="dv">6</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>mall[<span class="st">'Cluster'</span>] <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.head())</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'Income'</span>, y<span class="op">=</span><span class="st">'SpendingScore'</span>, hue<span class="op">=</span><span class="st">'Cluster'</span>,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>mall, palette<span class="op">=</span><span class="st">'viridis'</span>, s<span class="op">=</span><span class="dv">100</span>, alpha<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Customer Segmentation Based on Income and Spending Score'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   ID  Gender  Age  Income  SpendingScore  Cluster
0   1    Male   19      15             39        2
1   2    Male   21      15             81        2
2   3  Female   20      16              6        4
3   4  Female   23      16             77        2
4   5  Female   31      17             40        2</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-12-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="index_files/figure-html/cell-12-output-2.png" width="788" height="530" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Analyze the segments</p>
<div id="0ac9a2a0" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>cluster_summary <span class="op">=</span> mall.drop(columns<span class="op">=</span>[<span class="st">'Gender'</span>,<span class="st">'ID'</span>]).groupby(<span class="st">'Cluster'</span>).mean()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Age     Income  SpendingScore
Cluster                                     
0        32.875000  86.100000      81.525000
1        55.638298  54.382979      48.851064
2        25.185185  41.092593      62.240741
3        39.871795  86.102564      19.358974
4        46.250000  26.750000      18.350000</code></pre>
</div>
</div>
<p>Now say we have two new customers</p>
<div id="00ac5fe5" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>new_customer <span class="op">=</span> {<span class="st">'ID'</span>:[<span class="dv">201</span>,<span class="dv">202</span>],<span class="st">'Gender'</span>:[<span class="st">'Male'</span>,<span class="st">'Female'</span>],<span class="st">'Age'</span>: [<span class="dv">30</span>,<span class="dv">50</span>],<span class="st">'Income'</span>:[<span class="dv">40</span>,<span class="dv">70</span>],<span class="st">'SpendingScore'</span>:[<span class="dv">70</span>,<span class="dv">20</span>]}</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>new_customer <span class="op">=</span> pd.DataFrame(new_customer)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_customer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    ID  Gender  Age  Income  SpendingScore
0  201    Male   30      40             70
1  202  Female   50      70             20</code></pre>
</div>
</div>
<p>We would like to know in which cluster they belong.</p>
<div id="be4564fc" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> new_customer[[<span class="st">'Age'</span>, <span class="st">'Income'</span>,<span class="st">'SpendingScore'</span>]]</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>X_new_sc <span class="op">=</span> scaler.transform(X_new)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>cluster_labels <span class="op">=</span> kmeans.predict(X_new_sc)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[2 3]</code></pre>
</div>
</div>
<p>K-Means is a powerful and widely used clustering algorithm, but it has limitations, such as assuming spherical clusters of equal sizes.</p>
<hr>
</section>
</section>
<section id="limitations-of-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-k-means-clustering">Limitations of K-Means Clustering</h2>
<p>While K-Means is a widely used clustering algorithm due to its simplicity and scalability, it has several notable limitations:</p>
<section id="assumption-of-spherical-clusters" class="level3">
<h3 class="anchored" data-anchor-id="assumption-of-spherical-clusters">1. <strong>Assumption of Spherical Clusters</strong></h3>
<p>K-Means assumes that clusters are spherical and have roughly the same size. This assumption may not hold true in real-world datasets, where clusters may have different shapes and densities. For example, if clusters are elongated or irregularly shaped, K-Means may not perform well.</p>
<ul>
<li><strong>Solution</strong>: Use algorithms like <strong>DBSCAN</strong> (Density-Based Spatial Clustering of Applications with Noise) or <strong>Spectral Clustering</strong>, which do not assume any specific shape for the clusters.</li>
</ul>
</section>
<section id="sensitivity-to-initialization" class="level3">
<h3 class="anchored" data-anchor-id="sensitivity-to-initialization">2. <strong>Sensitivity to Initialization</strong></h3>
<p>K-Means is sensitive to the initial selection of centroids. Different initializations can lead to different final clusters, and in some cases, the algorithm may converge to suboptimal solutions. To address this, the algorithm is often run multiple times with different initializations (e.g., using the <code>k-means++</code> initialization method).</p>
<ul>
<li><strong>Solution</strong>: Use the <code>k-means++</code> initialization, which ensures that centroids are chosen in a way that increases the likelihood of converging to an optimal solution.</li>
</ul>
</section>
<section id="needs-to-specify-k-in-advance" class="level3">
<h3 class="anchored" data-anchor-id="needs-to-specify-k-in-advance">3. <strong>Needs to Specify <code>k</code> in Advance</strong></h3>
<p>One of the main limitations is that K-Means requires the number of clusters (<code>k</code>) to be specified in advance. This can be a challenge when the number of clusters is unknown, and choosing the wrong <code>k</code> can lead to poor clustering results.</p>
<ul>
<li><strong>Solution</strong>: Use the <strong>Elbow Method</strong>, <strong>Silhouette Score</strong>, or the <strong>Gap Statistic</strong> to estimate the best value for <code>k</code>.</li>
</ul>
</section>
<section id="outliers-and-noise-sensitivity" class="level3">
<h3 class="anchored" data-anchor-id="outliers-and-noise-sensitivity">4. <strong>Outliers and Noise Sensitivity</strong></h3>
<p>K-Means is highly sensitive to outliers, as they can significantly affect the position of centroids. An outlier will either form its own cluster or distort the positions of nearby centroids, leading to incorrect clustering.</p>
<ul>
<li><strong>Solution</strong>: Preprocess your data by removing outliers or use clustering methods like <strong>DBSCAN</strong>, which can handle outliers more effectively by considering them as noise.</li>
</ul>
</section>
<section id="equal-cluster-size-assumption" class="level3">
<h3 class="anchored" data-anchor-id="equal-cluster-size-assumption">5. <strong>Equal Cluster Size Assumption</strong></h3>
<p>The algorithm tends to assign roughly equal-sized clusters because it minimizes variance. This can be a problem if clusters in your data have highly varying sizes. Small clusters might be absorbed into larger ones.</p>
<ul>
<li><strong>Solution</strong>: Use <strong>Hierarchical Clustering</strong>, which can naturally handle different cluster sizes.</li>
</ul>
</section>
<section id="non-convex-shapes" class="level3">
<h3 class="anchored" data-anchor-id="non-convex-shapes">6. <strong>Non-Convex Shapes</strong></h3>
<p>K-Means struggles with data where clusters have non-convex shapes, such as two overlapping rings or crescent shapes. It partitions the space into Voronoi cells, which are convex, leading to poor clustering results in non-convex structures.</p>
<ul>
<li><strong>Solution</strong>: Algorithms like <strong>Spectral Clustering</strong> or <strong>Gaussian Mixture Models (GMM)</strong> can better handle non-convex clusters.</li>
</ul>
<hr>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>K-Means Algorithm</strong>:
<ul>
<li>MacQueen, J. B. (1967). “Some Methods for Classification and Analysis of Multivariate Observations”. Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics.</li>
<li>Hartigan, J. A., &amp; Wong, M. A. (1979). “Algorithm AS 136: A K-means clustering algorithm”. Journal of the Royal Statistical Society. Series C (Applied Statistics), 28(1), 100-108.</li>
</ul></li>
<li><strong>Choosing <code>k</code> (Elbow Method &amp; Silhouette Score)</strong>:
<ul>
<li>Rousseeuw, P. J. (1987). “Silhouettes: A graphical aid to the interpretation and validation of cluster analysis”. Journal of Computational and Applied Mathematics, 20, 53-65.</li>
</ul></li>
<li><strong>Inertia and the Elbow Method</strong>:
<ul>
<li>Tibshirani, R., Walther, G., &amp; Hastie, T. (2001). “Estimating the number of clusters in a dataset via the gap statistic”. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2), 411-423.</li>
</ul></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="share-buttons">
<div class="fb-share-button" data-href="https://mrislambd.github.io/dsandml/kmeans/index.html" data-layout="button_count" data-size="small">
<a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmrislambd.github.io%2Fdsandml%2Fkmeans%2Findex.html&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">Share</a>
</div>
<script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
<script type="IN/Share" data-url="https://mrislambd.github.io/dsandml/kmeans/index.html"></script>
<a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-url="https://mrislambd.github.io/dsandml/kmeans/index.html" data-show-count="true">Tweet</a>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/kmeans/index.html" data-width="" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Data Science,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728259200000" data-listing-file-modified-sort="1728428177555" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1345">
<a href="../../dsandml/logreg/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/logreg/logreg.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, October 7, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1723593600000" data-listing-file-modified-sort="1728428177549" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1261">
<a href="../../dsandml/datacollection/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/datacollection/ws.jpg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Data collection through Webscraping
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Wednesday, August 14, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1728428177557" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="8" data-listing-word-count-sort="1429">
<a href="../../dsandml/pca/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/pca/pca.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Dimensionality Reduction: Principle Component Analysis (PCA)
</h5>
<div class="listing-reading-time card-text text-muted">
8 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, September 24, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Unsupervised {Learning:} {K-Means} {Clustering}},
  date = {2024-09-28},
  url = {https://mrislambd.github.io/dsandml/kmeans/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Islam, Rafiq. 2024. <span>“Unsupervised Learning: K-Means
Clustering.”</span> September 28, 2024. <a href="https://mrislambd.github.io/dsandml/kmeans/">https://mrislambd.github.io/dsandml/kmeans/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrislambd\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb21" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Unsupervised Learning: K-Means Clustering"</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-09-28"</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Rafiq Islam</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Data Science, Machine Learning, Artificial Intelligence, Data Engineering]</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span><span class="co"> true</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="an">search:</span><span class="co"> true</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="an">lightbox:</span><span class="co"> true</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> kmeans.png</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="an">listing:</span><span class="co"> </span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">    contents: "/../../dsandml"</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    max-items: 3</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">    type: grid</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co">    categories: false</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co">    date-format: full</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co">    fields: [image, date, title, author, reading-time]  </span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co">    html: </span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co">      toc: true</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co">---</span>  </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>&lt;p style ="text-align: justify"&gt;</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>Clustering is a fundamental technique in unsupervised learning where the goal is to group similar data points into clusters. One of the most popular algorithms for clustering is **K-Means**. K-Means is a centroid-based algorithm that partitions the dataset into $k$ clusters. The algorithm iterates over data points, assigning each to one of $k$ centroids (cluster centers), and then updates the centroids based on the current assignments. The objective is to minimize the sum of squared distances (also known as inertia) between each data point and its assigned centroid.</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mathematics Behind K-Means</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>The K-Means algorithm works through the following key steps:</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Initialization**: Randomly select $k$ points from the dataset as initial centroids.</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Assignment Step**: For each data point, assign it to the closest centroid based on the Euclidean distance:</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>   $$</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>   \text{distance}(x_i, \mu_j) = \sqrt{\sum_{d=1}^{D} (x_i^d - \mu_j^d)^2}</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>   $$  </span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>where:  </span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$x_i$ is the i-th data point.</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\mu_j$ is the j-th centroid.</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$D$ is the number of features (dimensions).</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Update Step**: After all data points are assigned, recalculate the centroid of each cluster as the mean of all data points assigned to it:</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>   $$</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>   \mu_j = \frac{1}{n_j} \sum_{i=1}^{n_j} x_i</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>   $$</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>   where $n_j$ is the number of points in cluster <span class="in">`j`</span>.</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Repeat**: The assignment and update steps are repeated until the centroids no longer change or the maximum number of iterations is reached.</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="fu">### Objective Function (Inertia)</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>The objective of K-Means is to minimize the following cost function, also called inertia or within-cluster sum of squares:</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>J = \sum_{j=1}^{k} \sum_{i=1}^{n_j} \|x_i - \mu_j\|^2</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>This measures how compact the clusters are, i.e., how close the points within each cluster are to their centroid.</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### How to Choose the Best $k$ Value?</span></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>One of the critical tasks in K-Means clustering is selecting the optimal number of clusters ($k$). Several methods can be used:</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. The Elbow Method</span></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>The most common way to determine the best $k$ is the **elbow method**. It involves plotting the inertia (the sum of squared distances from each point to its assigned cluster centroid) for different values of $k$. The point where the inertia starts to flatten out (forming an elbow) is considered a good choice for $k$.</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2. Silhouette Score</span></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>The **silhouette score** measures how similar each point is to its own cluster (cohesion) compared to other clusters (separation). It ranges from -1 to 1:  </span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$1$ indicates that the point is well inside its cluster.  </span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$0$ means the point is on the boundary between two clusters.  </span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Negative values indicate the point may have been assigned to the wrong cluster.</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3. Gap Statistic</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>The **gap statistic** compares the total within-cluster variation for different values of $k$ with the expected value under null reference distribution. The optimal number of clusters is where the gap statistic is the largest.</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python Implementation of K-Means  </span></span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a><span class="fu">### Synthetic Data</span></span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>Let’s implement K-Means clustering using Python with visualizations and explore how to choose the best value of $k$ using the elbow method.</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a><span class="co"># For plotting purposes</span></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>We’ll create a simple dataset with 4 distinct clusters for visualization.</span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset with 4 clusters</span></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">500</span>, centers<span class="op">=</span><span class="dv">4</span>, cluster_std<span class="op">=</span><span class="fl">0.60</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the dataset</span></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Dataset with 4 Clusters'</span>)</span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a>We can now apply K-Means clustering with different values of $k$ and observe how the clusters are formed.</span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit KMeans with k=4 (since we know we generated 4 clusters)</span></span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict clusters</span></span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a>y_kmeans <span class="op">=</span> kmeans.predict(X)</span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the clustered data</span></span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y_kmeans, s<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the centroids</span></span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a>plt.scatter(centers[:, <span class="dv">0</span>], centers[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'K-Means Clustering with k=4'</span>)</span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'kmeans.png'</span>)</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a>To determine the optimal number of clusters, we’ll plot the inertia for different values of $k$ using the elbow method.</span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Test multiple k values</span></span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>inertia <span class="op">=</span> []</span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a>    inertia.append(kmeans.inertia_)</span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the inertia vs. k values</span></span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, inertia, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow Method: Choosing the Optimal k'</span>)</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertia'</span>)</span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>We see that the curve starts to flatten at $k=4$, suggesting this is a good choice for the number of clusters. Let’s also compute the silhouette score for different values of $k$ to confirm our choice.</span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a>sil_scores <span class="op">=</span> []</span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">10</span>):</span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</span>
<span id="cb21-185"><a href="#cb21-185" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb21-186"><a href="#cb21-186" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.predict(X)</span>
<span id="cb21-187"><a href="#cb21-187" aria-hidden="true" tabindex="-1"></a>    sil_scores.append(silhouette_score(X, labels))</span>
<span id="cb21-188"><a href="#cb21-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-189"><a href="#cb21-189" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Silhouette Score vs. k</span></span>
<span id="cb21-190"><a href="#cb21-190" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">10</span>), sil_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-191"><a href="#cb21-191" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhouette Score for Different k Values'</span>)</span>
<span id="cb21-192"><a href="#cb21-192" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb21-193"><a href="#cb21-193" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb21-194"><a href="#cb21-194" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-195"><a href="#cb21-195" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-196"><a href="#cb21-196" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-197"><a href="#cb21-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-198"><a href="#cb21-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-199"><a href="#cb21-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### Real Data  </span></span>
<span id="cb21-200"><a href="#cb21-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-201"><a href="#cb21-201" aria-hidden="true" tabindex="-1"></a>**Description**:  </span>
<span id="cb21-202"><a href="#cb21-202" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align:justify"&gt;</span>
<span id="cb21-203"><a href="#cb21-203" aria-hidden="true" tabindex="-1"></a>This dataset contains information about customers of a shopping mall, including their annual income, spending score, gender, and age. &lt;/p&gt;  </span>
<span id="cb21-204"><a href="#cb21-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-205"><a href="#cb21-205" aria-hidden="true" tabindex="-1"></a>**Goal:** Our goal is to segment customers into different groups based on their spending behavior and income.</span>
<span id="cb21-206"><a href="#cb21-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-207"><a href="#cb21-207" aria-hidden="true" tabindex="-1"></a>**Columns**:  </span>
<span id="cb21-208"><a href="#cb21-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`CustomerID`</span>: Unique identifier for each customer.  </span>
<span id="cb21-209"><a href="#cb21-209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Gender`</span>: The gender of the customer (Male or Female).  </span>
<span id="cb21-210"><a href="#cb21-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Age`</span>: Age of the customer.  </span>
<span id="cb21-211"><a href="#cb21-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Annual Income`</span>: Annual income of the customer in thousands of dollars.  </span>
<span id="cb21-212"><a href="#cb21-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Spending Score`</span>: A score assigned by the mall based on customer behavior and spending patterns.</span>
<span id="cb21-213"><a href="#cb21-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-214"><a href="#cb21-214" aria-hidden="true" tabindex="-1"></a>**Data Source:** You can find the Mall Customer Segmentation data on <span class="co">[</span><span class="ot">Kaggle</span><span class="co">](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)</span>{style="text-decoration:none" target="_blank"}. </span>
<span id="cb21-215"><a href="#cb21-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-218"><a href="#cb21-218" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-219"><a href="#cb21-219" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-220"><a href="#cb21-220" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb21-221"><a href="#cb21-221" aria-hidden="true" tabindex="-1"></a>mall <span class="op">=</span> pd.read_csv(<span class="st">'Mall_Customers.csv'</span>)</span>
<span id="cb21-222"><a href="#cb21-222" aria-hidden="true" tabindex="-1"></a>mall.head()</span>
<span id="cb21-223"><a href="#cb21-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-224"><a href="#cb21-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-227"><a href="#cb21-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-228"><a href="#cb21-228" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-229"><a href="#cb21-229" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Information</span></span>
<span id="cb21-230"><a href="#cb21-230" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.info())</span>
<span id="cb21-231"><a href="#cb21-231" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb21-232"><a href="#cb21-232" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for Missing Data</span></span>
<span id="cb21-233"><a href="#cb21-233" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.isnull().<span class="bu">sum</span>())</span>
<span id="cb21-234"><a href="#cb21-234" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb21-235"><a href="#cb21-235" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Description</span></span>
<span id="cb21-236"><a href="#cb21-236" aria-hidden="true" tabindex="-1"></a>mall.rename(columns<span class="op">=</span>{<span class="st">'CustomerID'</span>:<span class="st">'ID'</span>,<span class="st">'Annual Income (k$)'</span>:<span class="st">'Income'</span>,<span class="st">'Spending Score (1-100)'</span>:<span class="st">'SpendingScore'</span>},inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-237"><a href="#cb21-237" aria-hidden="true" tabindex="-1"></a>cmall <span class="op">=</span> mall.drop(<span class="st">'ID'</span>,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-238"><a href="#cb21-238" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cmall.describe().loc[[<span class="st">'mean'</span>,<span class="st">'std'</span>,<span class="st">'min'</span>,<span class="st">'max'</span>]].T)</span>
<span id="cb21-239"><a href="#cb21-239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-240"><a href="#cb21-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-241"><a href="#cb21-241" aria-hidden="true" tabindex="-1"></a>**Pre-Process:** Since our data contains categorical variable <span class="in">`Gender`</span>, we need to encode this column and scale the numerical features like <span class="in">`Age`</span>, <span class="in">`Annual Income`</span>, and <span class="in">`Spending Score`</span>.  </span>
<span id="cb21-242"><a href="#cb21-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-245"><a href="#cb21-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-246"><a href="#cb21-246" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-247"><a href="#cb21-247" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb21-248"><a href="#cb21-248" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mall[[<span class="st">'Age'</span>,<span class="st">'Income'</span>,<span class="st">'SpendingScore'</span>]]</span>
<span id="cb21-249"><a href="#cb21-249" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb21-250"><a href="#cb21-250" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb21-251"><a href="#cb21-251" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_scaled[:<span class="dv">5</span>])</span>
<span id="cb21-252"><a href="#cb21-252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-253"><a href="#cb21-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-254"><a href="#cb21-254" aria-hidden="true" tabindex="-1"></a>Next we use the <span class="in">`Elbow`</span> method to find the best $k$, the number of clusters  </span>
<span id="cb21-255"><a href="#cb21-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-258"><a href="#cb21-258" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-259"><a href="#cb21-259" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-260"><a href="#cb21-260" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">15</span>)</span>
<span id="cb21-261"><a href="#cb21-261" aria-hidden="true" tabindex="-1"></a>inertia <span class="op">=</span> []</span>
<span id="cb21-262"><a href="#cb21-262" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb21-263"><a href="#cb21-263" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb21-264"><a href="#cb21-264" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X_scaled)</span>
<span id="cb21-265"><a href="#cb21-265" aria-hidden="true" tabindex="-1"></a>    inertia.append(kmeans.inertia_)</span>
<span id="cb21-266"><a href="#cb21-266" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values,inertia, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-267"><a href="#cb21-267" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow method to find $k$'</span>)</span>
<span id="cb21-268"><a href="#cb21-268" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters $k$'</span>)</span>
<span id="cb21-269"><a href="#cb21-269" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertia'</span>)</span>
<span id="cb21-270"><a href="#cb21-270" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-271"><a href="#cb21-271" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-272"><a href="#cb21-272" aria-hidden="true" tabindex="-1"></a>plt.show() </span>
<span id="cb21-273"><a href="#cb21-273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-274"><a href="#cb21-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-275"><a href="#cb21-275" aria-hidden="true" tabindex="-1"></a>The elbow point in the plot (where the decrease in inertia starts to slow) helps determine the optimal number of clusters. Let’s say we find that $k=5$ looks like a reasonable choice from the plot.  </span>
<span id="cb21-276"><a href="#cb21-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-277"><a href="#cb21-277" aria-hidden="true" tabindex="-1"></a>To further validate the choice of $k$, let’s compute the <span class="in">`silhouette`</span> score for different cluster numbers. A higher <span class="in">`silhouette`</span> score indicates better-defined clusters</span>
<span id="cb21-278"><a href="#cb21-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-281"><a href="#cb21-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-282"><a href="#cb21-282" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-283"><a href="#cb21-283" aria-hidden="true" tabindex="-1"></a>sil_scores <span class="op">=</span> []</span>
<span id="cb21-284"><a href="#cb21-284" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">15</span>):</span>
<span id="cb21-285"><a href="#cb21-285" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb21-286"><a href="#cb21-286" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb21-287"><a href="#cb21-287" aria-hidden="true" tabindex="-1"></a>    sil_scores.append(silhouette_score(X_scaled,labels))</span>
<span id="cb21-288"><a href="#cb21-288" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">15</span>),sil_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-289"><a href="#cb21-289" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhoutte method to find $k$'</span>)</span>
<span id="cb21-290"><a href="#cb21-290" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters $k$'</span>)</span>
<span id="cb21-291"><a href="#cb21-291" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhoutte Score'</span>)</span>
<span id="cb21-292"><a href="#cb21-292" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-293"><a href="#cb21-293" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-294"><a href="#cb21-294" aria-hidden="true" tabindex="-1"></a>plt.show() </span>
<span id="cb21-295"><a href="#cb21-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-296"><a href="#cb21-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-297"><a href="#cb21-297" aria-hidden="true" tabindex="-1"></a>Next, we apply $k=5$ clusters  </span>
<span id="cb21-298"><a href="#cb21-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-301"><a href="#cb21-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-302"><a href="#cb21-302" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-303"><a href="#cb21-303" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">9.5</span>,<span class="dv">6</span>))</span>
<span id="cb21-304"><a href="#cb21-304" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb21-305"><a href="#cb21-305" aria-hidden="true" tabindex="-1"></a>mall[<span class="st">'Cluster'</span>] <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb21-306"><a href="#cb21-306" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mall.head())</span>
<span id="cb21-307"><a href="#cb21-307" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb21-308"><a href="#cb21-308" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">'Income'</span>, y<span class="op">=</span><span class="st">'SpendingScore'</span>, hue<span class="op">=</span><span class="st">'Cluster'</span>,</span>
<span id="cb21-309"><a href="#cb21-309" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>mall, palette<span class="op">=</span><span class="st">'viridis'</span>, s<span class="op">=</span><span class="dv">100</span>, alpha<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb21-310"><a href="#cb21-310" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-311"><a href="#cb21-311" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Customer Segmentation Based on Income and Spending Score'</span>)</span>
<span id="cb21-312"><a href="#cb21-312" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb21-313"><a href="#cb21-313" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb21-314"><a href="#cb21-314" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb21-315"><a href="#cb21-315" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-316"><a href="#cb21-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-317"><a href="#cb21-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-318"><a href="#cb21-318" aria-hidden="true" tabindex="-1"></a>Analyze the segments  </span>
<span id="cb21-319"><a href="#cb21-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-322"><a href="#cb21-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-323"><a href="#cb21-323" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-324"><a href="#cb21-324" aria-hidden="true" tabindex="-1"></a>cluster_summary <span class="op">=</span> mall.drop(columns<span class="op">=</span>[<span class="st">'Gender'</span>,<span class="st">'ID'</span>]).groupby(<span class="st">'Cluster'</span>).mean()</span>
<span id="cb21-325"><a href="#cb21-325" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_summary)</span>
<span id="cb21-326"><a href="#cb21-326" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-327"><a href="#cb21-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-328"><a href="#cb21-328" aria-hidden="true" tabindex="-1"></a>Now say we have two new customers  </span>
<span id="cb21-331"><a href="#cb21-331" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-332"><a href="#cb21-332" aria-hidden="true" tabindex="-1"></a>new_customer <span class="op">=</span> {<span class="st">'ID'</span>:[<span class="dv">201</span>,<span class="dv">202</span>],<span class="st">'Gender'</span>:[<span class="st">'Male'</span>,<span class="st">'Female'</span>],<span class="st">'Age'</span>: [<span class="dv">30</span>,<span class="dv">50</span>],<span class="st">'Income'</span>:[<span class="dv">40</span>,<span class="dv">70</span>],<span class="st">'SpendingScore'</span>:[<span class="dv">70</span>,<span class="dv">20</span>]}</span>
<span id="cb21-333"><a href="#cb21-333" aria-hidden="true" tabindex="-1"></a>new_customer <span class="op">=</span> pd.DataFrame(new_customer)</span>
<span id="cb21-334"><a href="#cb21-334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_customer)</span>
<span id="cb21-335"><a href="#cb21-335" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb21-336"><a href="#cb21-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-337"><a href="#cb21-337" aria-hidden="true" tabindex="-1"></a>We would like to know in which cluster they belong.  </span>
<span id="cb21-338"><a href="#cb21-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-341"><a href="#cb21-341" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-342"><a href="#cb21-342" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb21-343"><a href="#cb21-343" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> new_customer[[<span class="st">'Age'</span>, <span class="st">'Income'</span>,<span class="st">'SpendingScore'</span>]]</span>
<span id="cb21-344"><a href="#cb21-344" aria-hidden="true" tabindex="-1"></a>X_new_sc <span class="op">=</span> scaler.transform(X_new)</span>
<span id="cb21-345"><a href="#cb21-345" aria-hidden="true" tabindex="-1"></a>cluster_labels <span class="op">=</span> kmeans.predict(X_new_sc)</span>
<span id="cb21-346"><a href="#cb21-346" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_labels)</span>
<span id="cb21-347"><a href="#cb21-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-348"><a href="#cb21-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-349"><a href="#cb21-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-350"><a href="#cb21-350" aria-hidden="true" tabindex="-1"></a>K-Means is a powerful and widely used clustering algorithm, but it has limitations, such as assuming spherical clusters of equal sizes. </span>
<span id="cb21-351"><a href="#cb21-351" aria-hidden="true" tabindex="-1"></a>--- </span>
<span id="cb21-352"><a href="#cb21-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-353"><a href="#cb21-353" aria-hidden="true" tabindex="-1"></a><span class="fu">## Limitations of K-Means Clustering</span></span>
<span id="cb21-354"><a href="#cb21-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-355"><a href="#cb21-355" aria-hidden="true" tabindex="-1"></a>While K-Means is a widely used clustering algorithm due to its simplicity and scalability, it has several notable limitations:</span>
<span id="cb21-356"><a href="#cb21-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-357"><a href="#cb21-357" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1. **Assumption of Spherical Clusters**</span></span>
<span id="cb21-358"><a href="#cb21-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-359"><a href="#cb21-359" aria-hidden="true" tabindex="-1"></a>K-Means assumes that clusters are spherical and have roughly the same size. This assumption may not hold true in real-world datasets, where clusters may have different shapes and densities. For example, if clusters are elongated or irregularly shaped, K-Means may not perform well.</span>
<span id="cb21-360"><a href="#cb21-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-361"><a href="#cb21-361" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Use algorithms like **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) or **Spectral Clustering**, which do not assume any specific shape for the clusters.</span>
<span id="cb21-362"><a href="#cb21-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-363"><a href="#cb21-363" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2. **Sensitivity to Initialization**</span></span>
<span id="cb21-364"><a href="#cb21-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-365"><a href="#cb21-365" aria-hidden="true" tabindex="-1"></a>K-Means is sensitive to the initial selection of centroids. Different initializations can lead to different final clusters, and in some cases, the algorithm may converge to suboptimal solutions. To address this, the algorithm is often run multiple times with different initializations (e.g., using the <span class="in">`k-means++`</span> initialization method).</span>
<span id="cb21-366"><a href="#cb21-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-367"><a href="#cb21-367" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Use the <span class="in">`k-means++`</span> initialization, which ensures that centroids are chosen in a way that increases the likelihood of converging to an optimal solution.</span>
<span id="cb21-368"><a href="#cb21-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-369"><a href="#cb21-369" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3. **Needs to Specify `k` in Advance**</span></span>
<span id="cb21-370"><a href="#cb21-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-371"><a href="#cb21-371" aria-hidden="true" tabindex="-1"></a>One of the main limitations is that K-Means requires the number of clusters (<span class="in">`k`</span>) to be specified in advance. This can be a challenge when the number of clusters is unknown, and choosing the wrong <span class="in">`k`</span> can lead to poor clustering results.</span>
<span id="cb21-372"><a href="#cb21-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-373"><a href="#cb21-373" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Use the **Elbow Method**, **Silhouette Score**, or the **Gap Statistic** to estimate the best value for <span class="in">`k`</span>.</span>
<span id="cb21-374"><a href="#cb21-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-375"><a href="#cb21-375" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4. **Outliers and Noise Sensitivity**</span></span>
<span id="cb21-376"><a href="#cb21-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-377"><a href="#cb21-377" aria-hidden="true" tabindex="-1"></a>K-Means is highly sensitive to outliers, as they can significantly affect the position of centroids. An outlier will either form its own cluster or distort the positions of nearby centroids, leading to incorrect clustering.</span>
<span id="cb21-378"><a href="#cb21-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-379"><a href="#cb21-379" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Preprocess your data by removing outliers or use clustering methods like **DBSCAN**, which can handle outliers more effectively by considering them as noise.</span>
<span id="cb21-380"><a href="#cb21-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-381"><a href="#cb21-381" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5. **Equal Cluster Size Assumption**</span></span>
<span id="cb21-382"><a href="#cb21-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-383"><a href="#cb21-383" aria-hidden="true" tabindex="-1"></a>The algorithm tends to assign roughly equal-sized clusters because it minimizes variance. This can be a problem if clusters in your data have highly varying sizes. Small clusters might be absorbed into larger ones.</span>
<span id="cb21-384"><a href="#cb21-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-385"><a href="#cb21-385" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Use **Hierarchical Clustering**, which can naturally handle different cluster sizes.</span>
<span id="cb21-386"><a href="#cb21-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-387"><a href="#cb21-387" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6. **Non-Convex Shapes**</span></span>
<span id="cb21-388"><a href="#cb21-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-389"><a href="#cb21-389" aria-hidden="true" tabindex="-1"></a>K-Means struggles with data where clusters have non-convex shapes, such as two overlapping rings or crescent shapes. It partitions the space into Voronoi cells, which are convex, leading to poor clustering results in non-convex structures.</span>
<span id="cb21-390"><a href="#cb21-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-391"><a href="#cb21-391" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution**: Algorithms like **Spectral Clustering** or **Gaussian Mixture Models (GMM)** can better handle non-convex clusters.</span>
<span id="cb21-392"><a href="#cb21-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-393"><a href="#cb21-393" aria-hidden="true" tabindex="-1"></a>---  </span>
<span id="cb21-394"><a href="#cb21-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-395"><a href="#cb21-395" aria-hidden="true" tabindex="-1"></a><span class="fu">## References  </span></span>
<span id="cb21-396"><a href="#cb21-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-397"><a href="#cb21-397" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**K-Means Algorithm**: </span>
<span id="cb21-398"><a href="#cb21-398" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>MacQueen, J. B. (1967). "Some Methods for Classification and Analysis of Multivariate Observations". Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics.</span>
<span id="cb21-399"><a href="#cb21-399" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Hartigan, J. A., &amp; Wong, M. A. (1979). "Algorithm AS 136: A K-means clustering algorithm". Journal of the Royal Statistical Society. Series C (Applied Statistics), 28(1), 100-108.</span>
<span id="cb21-400"><a href="#cb21-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-401"><a href="#cb21-401" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Choosing `k` (Elbow Method &amp; Silhouette Score)**:</span>
<span id="cb21-402"><a href="#cb21-402" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Rousseeuw, P. J. (1987). "Silhouettes: A graphical aid to the interpretation and validation of cluster analysis". Journal of Computational and Applied Mathematics, 20, 53-65.</span>
<span id="cb21-403"><a href="#cb21-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-404"><a href="#cb21-404" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Inertia and the Elbow Method**:</span>
<span id="cb21-405"><a href="#cb21-405" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Tibshirani, R., Walther, G., &amp; Hastie, T. (2001). "Estimating the number of clusters in a dataset via the gap statistic". Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2), 411-423.</span>
<span id="cb21-406"><a href="#cb21-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-407"><a href="#cb21-407" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb21-408"><a href="#cb21-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-409"><a href="#cb21-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-410"><a href="#cb21-410" aria-hidden="true" tabindex="-1"></a>**Share on**  </span>
<span id="cb21-411"><a href="#cb21-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-412"><a href="#cb21-412" aria-hidden="true" tabindex="-1"></a>&lt;div id="fb-root"&gt;&lt;/div&gt;</span>
<span id="cb21-413"><a href="#cb21-413" aria-hidden="true" tabindex="-1"></a>&lt;script async defer crossorigin="anonymous"</span>
<span id="cb21-414"><a href="#cb21-414" aria-hidden="true" tabindex="-1"></a> src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"&gt;&lt;/script&gt;</span>
<span id="cb21-415"><a href="#cb21-415" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-416"><a href="#cb21-416" aria-hidden="true" tabindex="-1"></a>&lt;div class="share-buttons"&gt;</span>
<span id="cb21-417"><a href="#cb21-417" aria-hidden="true" tabindex="-1"></a>&lt;div class="fb-share-button" data-href="https://mrislambd.github.io/dsandml/kmeans/index.html"</span>
<span id="cb21-418"><a href="#cb21-418" aria-hidden="true" tabindex="-1"></a>data-layout="button_count" data-size="small"&gt;&lt;a target="_blank" </span>
<span id="cb21-419"><a href="#cb21-419" aria-hidden="true" tabindex="-1"></a> href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmrislambd.github.io%2Fdsandml%2Fkmeans%2Findex.html<span class="dv">&amp;amp;</span>src=sdkpreparse" </span>
<span id="cb21-420"><a href="#cb21-420" aria-hidden="true" tabindex="-1"></a> class="fb-xfbml-parse-ignore"&gt;Share&lt;/a&gt;&lt;/div&gt;</span>
<span id="cb21-421"><a href="#cb21-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-422"><a href="#cb21-422" aria-hidden="true" tabindex="-1"></a>&lt;script src="https://platform.linkedin.com/in.js" type="text/javascript"&gt;lang<span class="op">:</span> en_US&lt;/script&gt;</span>
<span id="cb21-423"><a href="#cb21-423" aria-hidden="true" tabindex="-1"></a>&lt;script type="IN/Share" data-url="https://mrislambd.github.io/dsandml/kmeans/index.html"&gt;&lt;/script&gt; </span>
<span id="cb21-424"><a href="#cb21-424" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-425"><a href="#cb21-425" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" </span>
<span id="cb21-426"><a href="#cb21-426" aria-hidden="true" tabindex="-1"></a> data-url="https://mrislambd.github.io/dsandml/kmeans/index.html" data-show-count="true"&gt;Tweet&lt;/a&gt;</span>
<span id="cb21-427"><a href="#cb21-427" aria-hidden="true" tabindex="-1"></a>&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;</span>
<span id="cb21-428"><a href="#cb21-428" aria-hidden="true" tabindex="-1"></a>&lt;/div&gt;</span>
<span id="cb21-429"><a href="#cb21-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-430"><a href="#cb21-430" aria-hidden="true" tabindex="-1"></a>&lt;div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/kmeans/index.html"</span>
<span id="cb21-431"><a href="#cb21-431" aria-hidden="true" tabindex="-1"></a> data-width="" data-numposts="5"&gt;&lt;/div&gt;</span>
<span id="cb21-432"><a href="#cb21-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-433"><a href="#cb21-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-434"><a href="#cb21-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-435"><a href="#cb21-435" aria-hidden="true" tabindex="-1"></a>**You may also like**</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Powered by <a href="https://quarto.org/">Quarto</a> 1.5.57</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024 @ Rafiq Islam
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.txt">
<p>License</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/rafiqr35" target="_blank">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://youtube.com/@quanttube" target="_blank">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:rafiqfsu@gmail.com?subject&amp;body" target="_blank">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"selector":".lightbox","descPosition":"bottom","openEffect":"zoom","loop":false,"closeEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>
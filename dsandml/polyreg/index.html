<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rafiq Islam">
<meta name="dcterms.date" content="2024-09-20">

<title>Polynomial Regression – Mohammad Rafiqul Islam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//_assets/images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-listing/list.min.js"></script>
<script src="../../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-image','listing-date','listing-title','listing-author','listing-reading-time',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      page: 18,
    pagination: { item: "<li class='page-item'><a class='page page-link' href='#'></a></li>" },
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z5NP67GHFC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Z5NP67GHFC', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6878992848042528" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Polynomial Regression – Mohammad Rafiqul Islam">
<meta property="og:description" content="">
<meta property="og:image" content="https://mrislambd.github.io/dsandml/polyreg/poly.jpeg">
<meta property="og:site_name" content="Mohammad Rafiqul Islam">
<meta name="twitter:title" content="Polynomial Regression – Mohammad Rafiqul Islam">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mrislambd.github.io/dsandml/polyreg/poly.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../dsandml/polyreg/index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../_assets/images/fsu-logo.png" alt="Florida State University" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../dsandml/polyreg/index.html">
    <span class="navbar-title">Mohammad Rafiqul Islam</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html"> 
<span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mohammad-rafiqul-islam/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mrislambd" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#what-is-polynomial-regression" id="toc-what-is-polynomial-regression" class="nav-link" data-scroll-target="#what-is-polynomial-regression">What is Polynomial Regression?</a></li>
  <li><a href="#mathematical-derivation-of-polynomial-regression" id="toc-mathematical-derivation-of-polynomial-regression" class="nav-link" data-scroll-target="#mathematical-derivation-of-polynomial-regression">Mathematical Derivation of Polynomial Regression</a></li>
  <li><a href="#python-implementation-of-polynomial-regression-one-variable" id="toc-python-implementation-of-polynomial-regression-one-variable" class="nav-link" data-scroll-target="#python-implementation-of-polynomial-regression-one-variable">Python Implementation of Polynomial Regression (One Variable)</a></li>
  <li><a href="#python-implementation-of-polynomial-regression-two-variables" id="toc-python-implementation-of-polynomial-regression-two-variables" class="nav-link" data-scroll-target="#python-implementation-of-polynomial-regression-two-variables">Python Implementation of Polynomial Regression (Two Variables)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Polynomial Regression</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Data Science</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Artificial Intelligence</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rafiq Islam </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 20, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Polynomial regression is an extension of linear regression that captures the relationship between the dependent and independent variables by fitting a polynomial equation. Unlike linear regression, where the model assumes a straight-line relationship, polynomial regression allows for more complex relationships, enabling the model to fit non-linear data more accurately.
</p>
<section id="what-is-polynomial-regression" class="level3">
<h3 class="anchored" data-anchor-id="what-is-polynomial-regression">What is Polynomial Regression?</h3>
<p>Polynomial regression is a type of regression where the relationship between the independent variable <span class="math inline">\(X\)</span> and the dependent variable <span class="math inline">\(y\)</span> is modeled as an <span class="math inline">\(n\)</span>th degree polynomial. The general form of a polynomial regression model is:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \dots + \beta_n X^n + \epsilon
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(y\)</span> is the predicted output (dependent variable),</li>
<li><span class="math inline">\(X\)</span> is the input feature (independent variable),</li>
<li><span class="math inline">\(\beta_0, \beta_1, \dots, \beta_n\)</span> are the coefficients to be learned,</li>
<li><span class="math inline">\(\epsilon\)</span> is the error term (the difference between the actual and predicted values),</li>
<li><span class="math inline">\(n\)</span> is the degree of the polynomial.</li>
</ul>
<p style="text-align:justify">
Polynomial regression can model non-linear data by introducing polynomial terms (such as <span class="math inline">\(X^2, X^3\)</span>, etc.), but the model is still linear in terms of the coefficients, which is why it is often treated as a type of linear regression.
</p>
</section>
<section id="mathematical-derivation-of-polynomial-regression" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-derivation-of-polynomial-regression">Mathematical Derivation of Polynomial Regression</h3>
<p style="text-align: justify">
The objective of polynomial regression, like linear regression, is to minimize the <strong>sum of squared errors (SSE)</strong> between the observed values <span class="math inline">\(y_i\)</span> and the predicted values <span class="math inline">\(\hat{y}_i\)</span>. This can be done by applying the <strong>ordinary least squares (OLS)</strong> method.
</p>
<p>For simplicity, let’s assume a second-degree polynomial regression model:</p>
<p><span class="math display">\[
\hat{y} = \beta_0 + \beta_1 X + \beta_2 X^2
\]</span></p>
<p>The error for each data point is the difference between the actual value <span class="math inline">\(y_i\)</span> and the predicted value <span class="math inline">\(\hat{y}_i\)</span>:</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i = y_i - (\beta_0 + \beta_1 X_i + \beta_2 X_i^2)
\]</span></p>
<p>We aim to minimize the sum of squared errors (SSE):</p>
<p><span class="math display">\[
SSE = \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{m} (y_i - (\beta_0 + \beta_1 X_i + \beta_2 X_i^2))^2
\]</span></p>
<p>Where <span class="math inline">\(m\)</span> is the number of data points.</p>
<p>We can represent this problem in matrix form to generalize for higher-degree polynomials and simplify the calculation:</p>
<p>Let <span class="math inline">\(X\)</span> represent the <strong>design matrix</strong>, where each column corresponds to a power of the independent variable <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
X =
\begin{bmatrix}
1 &amp; X_1 &amp; X_1^2 \\
1 &amp; X_2 &amp; X_2^2 \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; X_m &amp; X_m^2
\end{bmatrix}
\]</span></p>
<p>Let <span class="math inline">\(\beta\)</span> be the <strong>coefficient vector</strong>:</p>
<p><span class="math display">\[
\beta =
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2
\end{bmatrix}
\]</span></p>
<p>And <span class="math inline">\(y\)</span> be the <strong>output vector</strong>:</p>
<p><span class="math display">\[
y =
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_m
\end{bmatrix}
\]</span></p>
<p>The predicted values can be written as:</p>
<p><span class="math display">\[
\hat{y} = X \beta
\]</span></p>
<p>To find the optimal coefficients <span class="math inline">\(\beta\)</span>, we minimize the SSE, which can be rewritten in matrix form as:</p>
<p><span class="math display">\[
SSE = (y - X\beta)^T(y - X\beta)
\]</span></p>
<p>To minimize this, we take the derivative of the SSE with respect to <span class="math inline">\(\beta\)</span> and set it to zero:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \beta} (y - X\beta)^T(y - X\beta) = -2X^T(y - X\beta) = 0
\]</span></p>
<p>Solving for <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\beta = (X^T X)^{-1} X^T y
\]</span></p>
<p>This gives the optimal solution for the coefficients <span class="math inline">\(\beta\)</span>, which can be used to predict the output <span class="math inline">\(\hat{y}\)</span>. The detail proof of this parameter <span class="math inline">\(\hat{\beta}\)</span> can be found in the <a href="../../dsandml/multiplelinreg/index.html" style="text-decoration:none" target="_blank"> multiple linear regression </a> page.</p>
</section>
<section id="python-implementation-of-polynomial-regression-one-variable" class="level3">
<h3 class="anchored" data-anchor-id="python-implementation-of-polynomial-regression-one-variable">Python Implementation of Polynomial Regression (One Variable)</h3>
<p>We use <code>PolynomialFeatures</code> from <code>Scikit-learn</code> to transform our input data <span class="math inline">\(X\)</span> to include polynomial terms (e.g., <span class="math inline">\(X^2, X^3\)</span>, etc.).</p>
<div id="24012f23" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> X <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> (X <span class="op">**</span> <span class="dv">2</span>) <span class="op">+</span> np.random.normal(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[:, np.newaxis]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, y, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Sample Data"</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/cell-2-output-1.png" width="604" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="b9517c3f" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>poly <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span><span class="dv">2</span>, interaction_only<span class="op">=</span><span class="va">False</span>, include_bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X_poly <span class="op">=</span> poly.fit_transform(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we fit a linear regression model on the transformed polynomial features.</p>
<div id="a89c6d6a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>model.fit(X_poly, y)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_poly)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Coefficients: </span><span class="sc">{</span>model<span class="sc">.</span>coef_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Intercept: </span><span class="sc">{</span>model<span class="sc">.</span>intercept_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mean_squared_error(y, y_pred)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients: [ 0.          0.96597113 -2.02225052]
Intercept: -2.4148356673536284
Mean Squared Error: 9.447441952450275</code></pre>
</div>
</div>
<p>Finally, let’s plot the polynomial curve that fits the data.</p>
<div id="a9e36a97" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> operator</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>sort_axis <span class="op">=</span> operator.itemgetter(<span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>sorted_zip <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">zip</span>(X, y_pred), key<span class="op">=</span>sort_axis)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>X_sorted, y_pred_sorted <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>sorted_zip)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the polynomial curve</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, y, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.plot(X_sorted, y_pred_sorted, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Polynomial Regression Fit"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/cell-5-output-1.png" width="604" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can evaluate the performance of the model by comparing the <strong>mean squared error (MSE)</strong> between the actual and predicted values:</p>
<div id="9b698fca" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y, y_pred)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 9.447441952450275</code></pre>
</div>
</div>
</section>
<section id="python-implementation-of-polynomial-regression-two-variables" class="level3">
<h3 class="anchored" data-anchor-id="python-implementation-of-polynomial-regression-two-variables">Python Implementation of Polynomial Regression (Two Variables)</h3>
<p>We’ll generate some non-linear data and try to fit a polynomial regression model to it.</p>
<div id="21b072a3" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.plotting <span class="im">import</span> scatter_matrix</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> <span class="dv">4</span><span class="op">*</span>np.random.normal(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">100</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">2</span><span class="op">+</span><span class="dv">3</span><span class="op">*</span>x1 <span class="op">-</span><span class="dv">4</span><span class="op">*</span>x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> x2 <span class="op">+</span> np.random.normal(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>{</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>:x1,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x2'</span>:x2,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>:y</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(df)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>scatter_matrix(df)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         x1         x2           y
0 -3.292157   7.065206  -41.206797
1  0.799528 -18.782072  -39.440680
2 -0.936214 -18.163880  -40.343409
3 -4.722680  -0.244826 -102.906711
4 -3.602674 -17.384987  -96.574641</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/cell-7-output-2.png" width="597" height="450" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Since it’s clear that the relationships are not linear. So if we fit a linear regression model, it won’t be a good fit.</p>
<div id="794c4143" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.y</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> LinearRegression()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model1.fit(X,y)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>pred1 <span class="op">=</span> model1.predict(X)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>residual1 <span class="op">=</span> y <span class="op">-</span> pred1</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(residual1)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/cell-8-output-1.png" width="604" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Therefore, we generate some non linear features from the given data.</p>
<div id="3aa1ce61" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x1_squared'</span>]<span class="op">=</span>df.x1<span class="op">**</span><span class="dv">2</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>scatter_matrix(df)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="index_files/figure-html/cell-9-output-1.png" width="597" height="450" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>From this plot, we see that <span class="math inline">\(x1\)</span> is parabolic and <span class="math inline">\(x2\)</span> is linear in relationship with <span class="math inline">\(y\)</span>. So, how about a model that combines a linear and quadratic model?</p>
<div id="3eeaf422" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.y</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> LinearRegression()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>model2.fit(X,y)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>pred2 <span class="op">=</span> model2.predict(X)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>residual2 <span class="op">=</span> y <span class="op">-</span> pred2</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(residual2)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="index_files/figure-html/cell-10-output-1.png" width="587" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>This one is much better.</p>
<p style="text-align:justify">
Polynomial regression is a powerful technique that extends the basic linear regression model to capture non-linear relationships between variables. By transforming the input data into polynomial terms, the model becomes more flexible, allowing it to better fit data that doesn’t follow a linear pattern.<br> <br> The mathematical derivation shows that polynomial regression is still linear in terms of its parameters, allowing us to use simple optimization techniques like ordinary least squares (OLS) for parameter estimation.<br> <br> In Python, using Scikit-learn makes it easy to implement polynomial regression. We can increase the degree of the polynomial to improve model accuracy, but we need to be careful of <strong>overfitting</strong>, where the model becomes too complex and fits the noise in the data rather than the underlying pattern.
</p>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Data Science,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728259200000" data-listing-file-modified-sort="1728424537816" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1345">
<a href="../../dsandml/logreg/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/logreg/logreg.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, October 7, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1723593600000" data-listing-file-modified-sort="1728424537808" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1261">
<a href="../../dsandml/datacollection/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/datacollection/ws.jpg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Data collection through Webscraping
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Wednesday, August 14, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1728424537816" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="8" data-listing-word-count-sort="1429">
<a href="../../dsandml/pca/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/pca/pca.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Dimensionality Reduction: Principle Component Analysis (PCA)
</h5>
<div class="listing-reading-time card-text text-muted">
8 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, September 24, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Polynomial {Regression}},
  date = {2024-09-20},
  url = {https://mrislambd.github.io/dsandml/polyreg/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Islam, Rafiq. 2024. <span>“Polynomial Regression.”</span> September 20,
2024. <a href="https://mrislambd.github.io/dsandml/polyreg/">https://mrislambd.github.io/dsandml/polyreg/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrislambd\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Polynomial Regression"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-09-20"</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Rafiq Islam</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Data Science, Machine Learning, Artificial Intelligence]</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span><span class="co"> true</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> poly.jpeg</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="an">search:</span><span class="co"> true</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="an">lightbox:</span><span class="co"> true</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="an">listing:</span><span class="co"> </span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">    contents: "/../../dsandml"</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    max-items: 3</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">    type: grid</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">    categories: false</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">    date-format: full</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">    fields: [image, date, title, author, reading-time]</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span>  </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    Polynomial regression is an extension of linear regression that captures the relationship between the dependent and independent variables by fitting a polynomial equation. Unlike linear regression, where the model assumes a straight-line relationship, polynomial regression allows for more complex relationships, enabling the model to fit non-linear data more accurately.</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="fu">### What is Polynomial Regression?</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>Polynomial regression is a type of regression where the relationship between the independent variable $X$ and the dependent variable $y$ is modeled as an $n$th degree polynomial. The general form of a polynomial regression model is:</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \dots + \beta_n X^n + \epsilon</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>Where:  </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$y$ is the predicted output (dependent variable),</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$X$ is the input feature (independent variable),</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\beta_0, \beta_1, \dots, \beta_n$ are the coefficients to be learned,</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\epsilon$ is the error term (the difference between the actual and predicted values),</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$n$ is the degree of the polynomial.</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align:justify"&gt;</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    Polynomial regression can model non-linear data by introducing polynomial terms (such as $X^2, X^3$, etc.), but the model is still linear in terms of the coefficients, which is why it is often treated as a type of linear regression.</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mathematical Derivation of Polynomial Regression</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    The objective of polynomial regression, like linear regression, is to minimize the **sum of squared errors (SSE)** between the observed values $y_i$ and the predicted values $\hat{y}_i$. This can be done by applying the **ordinary least squares (OLS)** method.</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>For simplicity, let’s assume a second-degree polynomial regression model:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>\hat{y} = \beta_0 + \beta_1 X + \beta_2 X^2</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>The error for each data point is the difference between the actual value $y_i$ and the predicted value $\hat{y}_i$:</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>e_i = y_i - \hat{y}_i = y_i - (\beta_0 + \beta_1 X_i + \beta_2 X_i^2)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>We aim to minimize the sum of squared errors (SSE):</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>SSE = \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{m} (y_i - (\beta_0 + \beta_1 X_i + \beta_2 X_i^2))^2</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>Where $m$ is the number of data points.</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>We can represent this problem in matrix form to generalize for higher-degree polynomials and simplify the calculation:  </span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>Let $X$ represent the **design matrix**, where each column corresponds to a power of the independent variable $X$:</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>X =</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>1 &amp; X_1 &amp; X_1^2 <span class="sc">\\</span></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>1 &amp; X_2 &amp; X_2^2 <span class="sc">\\</span></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>\vdots &amp; \vdots &amp; \vdots <span class="sc">\\</span></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>1 &amp; X_m &amp; X_m^2</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>Let $\beta$ be the **coefficient vector**:</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>\beta =</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>\beta_0 <span class="sc">\\</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>\beta_1 <span class="sc">\\</span></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>\beta_2</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>And $y$ be the **output vector**:</span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>y =</span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>y_1 <span class="sc">\\</span></span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>y_2 <span class="sc">\\</span></span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>y_m</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>The predicted values can be written as:</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>\hat{y} = X \beta</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>To find the optimal coefficients $\beta$, we minimize the SSE, which can be rewritten in matrix form as:</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a>SSE = (y - X\beta)^T(y - X\beta)</span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a>To minimize this, we take the derivative of the SSE with respect to $\beta$ and set it to zero:</span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>\frac{\partial}{\partial \beta} (y - X\beta)^T(y - X\beta) = -2X^T(y - X\beta) = 0</span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a>Solving for $\beta$:</span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>\beta = (X^T X)^{-1} X^T y</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a>This gives the optimal solution for the coefficients $\beta$, which can be used to predict the output $\hat{y}$. The detail proof of this parameter $\hat{\beta}$ can be found in the &lt;a href="/dsandml/multiplelinreg/index.qmd" style="text-decoration:none" target="_blank"&gt; multiple linear regression &lt;/a&gt; page.  </span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python Implementation of Polynomial Regression (One Variable)  </span></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a>We use <span class="in">`PolynomialFeatures`</span> from <span class="in">`Scikit-learn`</span> to transform our input data $X$ to include polynomial terms (e.g., $X^2, X^3$, etc.).  </span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> X <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> (X <span class="op">**</span> <span class="dv">2</span>) <span class="op">+</span> np.random.normal(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[:, np.newaxis]</span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, y, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Sample Data"</span>)</span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a>poly <span class="op">=</span> PolynomialFeatures(degree<span class="op">=</span><span class="dv">2</span>, interaction_only<span class="op">=</span><span class="va">False</span>, include_bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a>X_poly <span class="op">=</span> poly.fit_transform(X)</span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-169"><a href="#cb13-169" aria-hidden="true" tabindex="-1"></a>Now we fit a linear regression model on the transformed polynomial features.</span>
<span id="cb13-170"><a href="#cb13-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb13-176"><a href="#cb13-176" aria-hidden="true" tabindex="-1"></a>model.fit(X_poly, y)</span>
<span id="cb13-177"><a href="#cb13-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_poly)</span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Coefficients: </span><span class="sc">{</span>model<span class="sc">.</span>coef_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Intercept: </span><span class="sc">{</span>model<span class="sc">.</span>intercept_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mean_squared_error(y, y_pred)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-183"><a href="#cb13-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-184"><a href="#cb13-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a>Finally, let’s plot the polynomial curve that fits the data.</span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> operator</span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a>sort_axis <span class="op">=</span> operator.itemgetter(<span class="dv">0</span>)</span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a>sorted_zip <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">zip</span>(X, y_pred), key<span class="op">=</span>sort_axis)</span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a>X_sorted, y_pred_sorted <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>sorted_zip)</span>
<span id="cb13-196"><a href="#cb13-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-197"><a href="#cb13-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the polynomial curve</span></span>
<span id="cb13-198"><a href="#cb13-198" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, y, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb13-199"><a href="#cb13-199" aria-hidden="true" tabindex="-1"></a>plt.plot(X_sorted, y_pred_sorted, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb13-200"><a href="#cb13-200" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb13-201"><a href="#cb13-201" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb13-202"><a href="#cb13-202" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Polynomial Regression Fit"</span>)</span>
<span id="cb13-203"><a href="#cb13-203" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-204"><a href="#cb13-204" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-205"><a href="#cb13-205" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-206"><a href="#cb13-206" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-207"><a href="#cb13-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-208"><a href="#cb13-208" aria-hidden="true" tabindex="-1"></a>We can evaluate the performance of the model by comparing the **mean squared error (MSE)** between the actual and predicted values:</span>
<span id="cb13-209"><a href="#cb13-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-212"><a href="#cb13-212" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-213"><a href="#cb13-213" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-214"><a href="#cb13-214" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y, y_pred)</span>
<span id="cb13-215"><a href="#cb13-215" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-216"><a href="#cb13-216" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-217"><a href="#cb13-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-218"><a href="#cb13-218" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python Implementation of Polynomial Regression (Two Variables)  </span></span>
<span id="cb13-219"><a href="#cb13-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-220"><a href="#cb13-220" aria-hidden="true" tabindex="-1"></a>We’ll generate some non-linear data and try to fit a polynomial regression model to it.</span>
<span id="cb13-221"><a href="#cb13-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-224"><a href="#cb13-224" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-225"><a href="#cb13-225" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-226"><a href="#cb13-226" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-227"><a href="#cb13-227" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb13-228"><a href="#cb13-228" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.plotting <span class="im">import</span> scatter_matrix</span>
<span id="cb13-229"><a href="#cb13-229" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb13-230"><a href="#cb13-230" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb13-231"><a href="#cb13-231" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> <span class="dv">4</span><span class="op">*</span>np.random.normal(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">100</span>)</span>
<span id="cb13-232"><a href="#cb13-232" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">2</span><span class="op">+</span><span class="dv">3</span><span class="op">*</span>x1 <span class="op">-</span><span class="dv">4</span><span class="op">*</span>x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> x2 <span class="op">+</span> np.random.normal(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb13-233"><a href="#cb13-233" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>{</span>
<span id="cb13-234"><a href="#cb13-234" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>:x1,</span>
<span id="cb13-235"><a href="#cb13-235" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x2'</span>:x2,</span>
<span id="cb13-236"><a href="#cb13-236" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>:y</span>
<span id="cb13-237"><a href="#cb13-237" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-238"><a href="#cb13-238" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(df)</span>
<span id="cb13-239"><a href="#cb13-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span>
<span id="cb13-240"><a href="#cb13-240" aria-hidden="true" tabindex="-1"></a>scatter_matrix(df)</span>
<span id="cb13-241"><a href="#cb13-241" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-242"><a href="#cb13-242" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-243"><a href="#cb13-243" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-244"><a href="#cb13-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb13-245"><a href="#cb13-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-246"><a href="#cb13-246" aria-hidden="true" tabindex="-1"></a>Since it's clear that the relationships are not linear. So if we fit a linear regression model, it won't be a good fit.  </span>
<span id="cb13-247"><a href="#cb13-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-250"><a href="#cb13-250" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-251"><a href="#cb13-251" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-252"><a href="#cb13-252" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-253"><a href="#cb13-253" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.y</span>
<span id="cb13-254"><a href="#cb13-254" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> LinearRegression()</span>
<span id="cb13-255"><a href="#cb13-255" aria-hidden="true" tabindex="-1"></a>model1.fit(X,y)</span>
<span id="cb13-256"><a href="#cb13-256" aria-hidden="true" tabindex="-1"></a>pred1 <span class="op">=</span> model1.predict(X)</span>
<span id="cb13-257"><a href="#cb13-257" aria-hidden="true" tabindex="-1"></a>residual1 <span class="op">=</span> y <span class="op">-</span> pred1</span>
<span id="cb13-258"><a href="#cb13-258" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(residual1)</span>
<span id="cb13-259"><a href="#cb13-259" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb13-260"><a href="#cb13-260" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-261"><a href="#cb13-261" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-262"><a href="#cb13-262" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-263"><a href="#cb13-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-264"><a href="#cb13-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-265"><a href="#cb13-265" aria-hidden="true" tabindex="-1"></a>Therefore, we generate some non linear features from the given data. </span>
<span id="cb13-266"><a href="#cb13-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-269"><a href="#cb13-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-270"><a href="#cb13-270" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-271"><a href="#cb13-271" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x1_squared'</span>]<span class="op">=</span>df.x1<span class="op">**</span><span class="dv">2</span></span>
<span id="cb13-272"><a href="#cb13-272" aria-hidden="true" tabindex="-1"></a>scatter_matrix(df)</span>
<span id="cb13-273"><a href="#cb13-273" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-274"><a href="#cb13-274" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-275"><a href="#cb13-275" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-276"><a href="#cb13-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb13-277"><a href="#cb13-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-278"><a href="#cb13-278" aria-hidden="true" tabindex="-1"></a>From this plot, we see that $x1$ is parabolic and $x2$ is linear in relationship with $y$. So, how about a model that combines a linear and quadratic model? </span>
<span id="cb13-279"><a href="#cb13-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-282"><a href="#cb13-282" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-283"><a href="#cb13-283" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb13-284"><a href="#cb13-284" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'y'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-285"><a href="#cb13-285" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.y</span>
<span id="cb13-286"><a href="#cb13-286" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> LinearRegression()</span>
<span id="cb13-287"><a href="#cb13-287" aria-hidden="true" tabindex="-1"></a>model2.fit(X,y)</span>
<span id="cb13-288"><a href="#cb13-288" aria-hidden="true" tabindex="-1"></a>pred2 <span class="op">=</span> model2.predict(X)</span>
<span id="cb13-289"><a href="#cb13-289" aria-hidden="true" tabindex="-1"></a>residual2 <span class="op">=</span> y <span class="op">-</span> pred2</span>
<span id="cb13-290"><a href="#cb13-290" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(residual2)</span>
<span id="cb13-291"><a href="#cb13-291" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb13-292"><a href="#cb13-292" aria-hidden="true" tabindex="-1"></a>plt.gca().set_facecolor(<span class="st">'#f4f4f4'</span>) </span>
<span id="cb13-293"><a href="#cb13-293" aria-hidden="true" tabindex="-1"></a>plt.gcf().patch.set_facecolor(<span class="st">'#f4f4f4'</span>)</span>
<span id="cb13-294"><a href="#cb13-294" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-295"><a href="#cb13-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb13-296"><a href="#cb13-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-297"><a href="#cb13-297" aria-hidden="true" tabindex="-1"></a>This one is much better. </span>
<span id="cb13-298"><a href="#cb13-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-299"><a href="#cb13-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-300"><a href="#cb13-300" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align:justify"&gt;</span>
<span id="cb13-301"><a href="#cb13-301" aria-hidden="true" tabindex="-1"></a>Polynomial regression is a powerful technique that extends the basic linear regression model to capture non-linear relationships between variables. By transforming the input data into polynomial terms, the model becomes more flexible, allowing it to better fit data that doesn’t follow a linear pattern.&lt;br&gt;</span>
<span id="cb13-302"><a href="#cb13-302" aria-hidden="true" tabindex="-1"></a>&lt;br&gt;</span>
<span id="cb13-303"><a href="#cb13-303" aria-hidden="true" tabindex="-1"></a>The mathematical derivation shows that polynomial regression is still linear in terms of its parameters, allowing us to use simple optimization techniques like ordinary least squares (OLS) for parameter estimation.&lt;br&gt;</span>
<span id="cb13-304"><a href="#cb13-304" aria-hidden="true" tabindex="-1"></a>&lt;br&gt;</span>
<span id="cb13-305"><a href="#cb13-305" aria-hidden="true" tabindex="-1"></a>In Python, using Scikit-learn makes it easy to implement polynomial regression. We can increase the degree of the polynomial to improve model accuracy, but we need to be careful of **overfitting**, where the model becomes too complex and fits the noise in the data rather than the underlying pattern.</span>
<span id="cb13-306"><a href="#cb13-306" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt; </span>
<span id="cb13-307"><a href="#cb13-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-308"><a href="#cb13-308" aria-hidden="true" tabindex="-1"></a>**You may also like**</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Powered by <a href="https://quarto.org/">Quarto</a> 1.5.57</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024 @ Rafiq Islam
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.txt">
<p>License</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/rafiqr35" target="_blank">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://youtube.com/@quanttube" target="_blank">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:rafiqfsu@gmail.com?subject&amp;body" target="_blank">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"descPosition":"bottom","selector":".lightbox","openEffect":"zoom","closeEffect":"zoom","loop":false});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rafiq Islam">
<meta name="dcterms.date" content="2024-10-07">

<title>Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code – Mohammad Rafiqul Islam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//_assets/images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-listing/list.min.js"></script>
<script src="../../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-image','listing-date','listing-title','listing-author','listing-reading-time',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      page: 18,
    pagination: { item: "<li class='page-item'><a class='page page-link' href='#'></a></li>" },
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description","listing-categories"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z5NP67GHFC"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Z5NP67GHFC', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6878992848042528" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code – Mohammad Rafiqul Islam">
<meta property="og:description" content="">
<meta property="og:image" content="https://mrislambd.github.io/dsandml/logreg/logreg.png">
<meta property="og:site_name" content="Mohammad Rafiqul Islam">
<meta property="og:image:height" content="464">
<meta property="og:image:width" content="581">
<meta name="twitter:title" content="Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code – Mohammad Rafiqul Islam">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://mrislambd.github.io/dsandml/logreg/logreg.png">
<meta name="twitter:image-height" content="464">
<meta name="twitter:image-width" content="581">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../dsandml/logreg/index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../_assets/images/fsu-logo.png" alt="Florida State University" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../dsandml/logreg/index.html">
    <span class="navbar-title">Mohammad Rafiqul Islam</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html"> 
<span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-blog" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Blog</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-blog">    
        <li>
    <a class="dropdown-item" href="../../posts/machinelearning/index.html">
 <span class="dropdown-text">Data Science and Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/jobandintern/index.html">
 <span class="dropdown-text">Job and Intern</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../blog.html">
 <span class="dropdown-text">All Other Blogs</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/mohammad-rafiqul-islam/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mrislambd" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#what-is-logistic-regression" id="toc-what-is-logistic-regression" class="nav-link" data-scroll-target="#what-is-logistic-regression">What is Logistic Regression?</a></li>
  <li><a href="#the-sigmoid-function" id="toc-the-sigmoid-function" class="nav-link" data-scroll-target="#the-sigmoid-function">The Sigmoid Function</a></li>
  <li><a href="#logistic-regression-model" id="toc-logistic-regression-model" class="nav-link" data-scroll-target="#logistic-regression-model">Logistic Regression Model</a></li>
  <li><a href="#cost-function-for-logistic-regression" id="toc-cost-function-for-logistic-regression" class="nav-link" data-scroll-target="#cost-function-for-logistic-regression">Cost Function for Logistic Regression</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient Descent</a></li>
  <li><a href="#python-code-implementation-from-scratch" id="toc-python-code-implementation-from-scratch" class="nav-link" data-scroll-target="#python-code-implementation-from-scratch">Python Code Implementation from Scratch</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    <h5 class="quarto-listing-category-title">Categories</h5><div class="quarto-listing-category category-default"><div class="category" data-category="">All <span class="quarto-category-count">(56)</span></div><div class="category" data-category="Algorithms">Algorithms <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Artificial Intelligence">Artificial Intelligence <span class="quarto-category-count">(18)</span></div><div class="category" data-category="Bayesian Inference">Bayesian Inference <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Bayesian Statistics">Bayesian Statistics <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Data Engineering">Data Engineering <span class="quarto-category-count">(9)</span></div><div class="category" data-category="Data Science">Data Science <span class="quarto-category-count">(20)</span></div><div class="category" data-category="Machine Learning">Machine Learning <span class="quarto-category-count">(20)</span></div><div class="category" data-category="Programming">Programming <span class="quarto-category-count">(1)</span></div><div class="category" data-category="PyTorch">PyTorch <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Python">Python <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Statistics">Statistics <span class="quarto-category-count">(4)</span></div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Data Science</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Artificial Intelligence</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rafiq Islam </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 7, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Logistic Regression is a popular classification algorithm used for binary and multi-class classification problems. Unlike Linear Regression, which is used for regression problems, Logistic Regression is used to predict categorical outcomes. In binary classification, the output is either 0 or 1, and the relationship between the input features and the outcome is modeled using a logistic function (also called the sigmoid function).
</p>
</section>
<section id="what-is-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="what-is-logistic-regression">What is Logistic Regression?</h2>
<p style="text-align: justify">
Logistic Regression is a type of regression analysis used when the dependent variable is categorical. In binary logistic regression, the output can have only two possible outcomes (e.g., 0 or 1, pass or fail, spam or not spam). <br> Logistic Regression works by modeling the probability of an event occurring based on one or more input features. It estimates the probability that a given input belongs to a particular category (0 or 1) using the <strong>logistic function (sigmoid function)</strong>.
</p>
</section>
<section id="the-sigmoid-function" class="level2">
<h2 class="anchored" data-anchor-id="the-sigmoid-function">The Sigmoid Function</h2>
<p>The sigmoid function maps any real-valued number to a value between 0 and 1, making it ideal for modeling probabilities.</p>
<p>The sigmoid function is given by the formula:</p>
<p><span class="math display">\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(z\)</span> is the input to the sigmoid function (in logistic regression, <span class="math inline">\(z = \mathbf{x} \cdot \theta\)</span>)</li>
<li><span class="math inline">\(e\)</span> is the base of the natural logarithm</li>
</ul>
<p>The output of the sigmoid function is interpreted as the probability <span class="math inline">\(P(y=1|X)\)</span>.</p>
</section>
<section id="logistic-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-model">Logistic Regression Model</h2>
<p>In Logistic Regression, the hypothesis is modeled as:</p>
<p><span class="math display">\[
h_\theta(X) = \frac{1}{1 + e^{-\theta^T X}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(X\)</span> is the input feature vector</li>
<li><span class="math inline">\(\theta\)</span> is the parameter vector (weights)</li>
</ul>
</section>
<section id="cost-function-for-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="cost-function-for-logistic-regression">Cost Function for Logistic Regression</h2>
<p style="text-align: justify">
Unlike Linear Regression, which uses the Mean Squared Error (MSE) as the cost function, Logistic Regression uses <strong>log loss</strong> or <strong>binary cross-entropy</strong> as the cost function, as the output is binary (0 or 1).
</p>
<p>So, basically we model probability from the given data. In other words, we can write</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(y= 1 \text{ or }0 |\text{ given }X)&amp;=p(\mathbf{x})=\sigma(\mathbf{x}\cdot\theta)=\frac{1}{1+e^{-\mathbf{x}\cdot \theta}}\\
\implies p_{\theta}(\mathbf{x})&amp; = \frac{1}{1+e^{-(\theta_0+\theta_1x_1+\cdots+\theta_dx_d)}}\\
\implies p_{\theta}(\mathbf{x})&amp; = \begin{cases}
                                p_{\theta}(\mathbf{x}) &amp; \text{ if } y=1\\
                                1-p_{\theta}(\mathbf{x}) &amp; \text{ if } y=0
                          \end{cases}
\end{align*}\]</span></p>
<p>Where, <span class="math inline">\(\mathbf{\theta},\mathbf{x}\in \mathbb{R}^{d+1}\)</span> and <span class="math inline">\(d\)</span> is the dimension of the data. For single data vector <span class="math inline">\(\mathbf{x}\)</span> the binary cross-entropy function can be written as</p>
<p><span class="math display">\[
l(\theta) = yp_{\theta}(\mathbf{x})+ (1-y)(1-p_{\theta}(\mathbf{x}))
\]</span></p>
<p>Since we have <span class="math inline">\(n\)</span> of those i.i.d data vectors therefore, we can write</p>
<p><span class="math display">\[
L(\theta) = \prod_{i=1}^{n} \left(y_ip_{\theta}(\mathbf{x_i})+ (1-y_i)(1-p_{\theta}(\mathbf{x_i}))\right)
\]</span></p>
<p>Since our goal is to minimize the loss, we need to perform derivatives of the loss function. Therefore, to change from the product form to addition form we take negative log of the above expression</p>
<p><span class="math display">\[\begin{align*}
\ell (\theta) = -\log{L(\theta)} = -\sum_{i=1}^{n}y_i\log{p_{\theta}(\mathbf{x})}+(1-y_i)\log{(1-p_{\theta}(\mathbf{x}))}
\end{align*}\]</span></p>
<p>For the ease of calculation, let’s rewrite the above equation in terms of <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> where <span class="math inline">\(m\in \mathbb{R}^d = (\theta_1,\theta_2,\cdots,\theta_d)^T\)</span> and <span class="math inline">\(b\in \mathbb{R}\)</span>.</p>
<p><span class="math display">\[
\ell (\theta) = -\sum_{i=1}^{n}y_i\log{p_{m,b}(\mathbf{x})}+(1-y_i)\log{(1-p_{m,b}(\mathbf{x}))}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(n\)</span> is the number of training examples<br>
</li>
<li><span class="math inline">\(m\)</span> is the number of features</li>
<li><span class="math inline">\(y^{(i)}\)</span> is the true label of the <span class="math inline">\(i^{th}\)</span> example</li>
<li><span class="math inline">\(b\)</span> is the bias for the <span class="math inline">\(i^{th}\)</span> example</li>
</ul>
</section>
<section id="gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h2>
<p>To minimize the cost function and find the optimal values for <span class="math inline">\(\theta\)</span>, we use <strong>gradient descent</strong>. We start from the last form of the loss function and convert this to a form that is easy to take the partial dervivatives.</p>
<p><span class="math display">\[\begin{align*}
\ell (\theta) &amp;= -\sum_{i=1}^{n}y_i\log{p_{m,b}(\mathbf{x})}+(1-y_i)\log{(1-p_{m,b}(\mathbf{x}))}\\
              &amp;= -\sum_{i=1}^{n}y_i\log{(\sigma(mx_i+b))}+(1-y_i)\log{(1-\sigma(mx_i+b))}\\
              &amp;= -\sum_{i=1}^{n}y_i\log{(\sigma(mx_i+b))}+(1-y_i)\log{(\sigma(-(mx_i+b)))};\hspace{3mm}\text{ Since } 1-\sigma(x)=\sigma(-x)\\
              &amp;= -\sum_{i=1}^{n}y_i\left[\log{(\sigma(mx_i+b))}-\log{(\sigma(-(mx_i+b)))}\right]+\log{(-\sigma(mx_i+b))}\\
              &amp;= -\sum_{i=1}^{n}y_i\log{\left(\frac{\sigma(mx_i+b)}{\sigma(-(mx_i+b))}\right)}+\log{(-\sigma(mx_i+b))}\\
              &amp;= -\sum_{i=1}^{n}y_i(mx_i+b)+\log{(\sigma(-(mx_i+b)))};\hspace{3mm}\text{ Since }\frac{\sigma(x)}{-\sigma(x)}=e^x\\
\end{align*}\]</span></p>
<p>Now we again use the beautiful features of the sigmoid function<br>
<span class="math display">\[\begin{align*}
\frac{d\sigma(x)}{dx}&amp;=\frac{d}{dx}\left(\frac{1}{1+e^{-x}}\right)=\frac{e^{-x}}{\left(1+e^{-x}\right)^2}=\frac{1}{1+e^{-x}}\cdot \frac{e^{-x}}{1+e^{-x}}\\
&amp;=\sigma(x)\left(1-\frac{1}{1+e^{-x}}\right)=\sigma(x)(1-\sigma(x))\\
&amp;=\sigma(x)\sigma(-x)
\end{align*}\]</span></p>
<p>Finally, we are ready to take the partial derivatives of the loss function with respect to <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span>,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial \ell}{\partial m} &amp;= -\sum_{i=1}^{n}y_ix_i+\frac{1}{\sigma(-(mx_i+b))}\frac{d}{dx}(\sigma(-(mx_i+b)))\\
&amp; =-\sum_{i=1}^{n}y_ix_i+\frac{1}{\sigma(-(mx_i+b))}\sigma(-(mx_i+b))\sigma(mx_i+b)(-x_i)\\
&amp; = -\sum_{i=1}^{n} x_i(y_i-\sigma(mx_i+b))\\
&amp; = \sum_{i=1}^{n}x_i(p_{m,b}(x_i)-y_i)=\sum_{i=1}^{n} x_i(\hat{y_i}-y_i)\\
&amp; = \mathbf{x_i}\cdot(\mathbf{\hat{y_i}}-\mathbf{y_i})\\
\text{ and } &amp; \\
&amp; \\
\frac{\partial \ell}{\partial b} &amp; = -\sum_{i=1}^{n} y_i +\frac{1}{\sigma(-(mx_i+b))}\frac{d}{dx}(\sigma(-(mx_i+b)))\\
&amp; =  -\sum_{i=1}^{n} y_i - \frac{1}{\sigma(-(mx_i+b))}\sigma(-(mx_i+b))\sigma(mx_i+b)\\
&amp; = \sum_{i=1}^{n} p_{m,b}(x_i)-y_i= \sum_{i=1}^{n} \hat{y}_i-y_i\\
&amp; = \hat{\mathbf{y}}_i-\mathbf{y}_i
\end{align*}\]</span></p>
<p>Using this gradient, we update the parameter vector <span class="math inline">\(\theta\)</span> iteratively:</p>
<p><span class="math display">\[
\theta_{j+1} := \theta_j - \alpha \nabla \ell (\theta_j)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> is the learning rate</li>
<li><span class="math inline">\(\nabla \ell (\theta_j)\)</span> is the partial derivative of the cost function with respect to <span class="math inline">\(\theta_j\)</span> and <span class="math display">\[
\nabla \ell (\theta) = \begin{bmatrix}\sum_{i=1}^{n} \hat{y}_i-y_i \\
\sum_{i=1}^{n} x_i(\hat{y_i}-y_i) \end{bmatrix}  =\begin{bmatrix}\hat{\mathbf{y}}_i-\mathbf{y}_i \\
\mathbf{x_i}\cdot(\mathbf{\hat{y_i}}-\mathbf{y_i}) \end{bmatrix}= X^T(\hat{\mathbf{y}}_i-\mathbf{y}_i)=X^T(\sigma(X\vec{\theta})-\vec{y})
\]</span></li>
</ul>
<hr>
</section>
<section id="python-code-implementation-from-scratch" class="level2">
<h2 class="anchored" data-anchor-id="python-code-implementation-from-scratch">Python Code Implementation from Scratch</h2>
<p>Here’s how to implement Logistic Regression from scratch in Python. We will use two different forms for our class</p>
<div id="14a4032e" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegression1:</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, learning_rate <span class="op">=</span> <span class="fl">0.1</span>, n_iterations <span class="op">=</span> <span class="dv">1000</span>):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">        Hyper Parameters</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">        - learning_rate: learning rate; float; default 0.01</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - n_itearations: number of iterations; int; default 1000</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Model Parameters</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">        - weights: weights of the features; float or int</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">        - bias: bias of the model; float or int</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iterations <span class="op">=</span> n_iterations </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="va">None</span> </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _sigmoid(<span class="va">self</span>, x):</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>x))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X,y):</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">        n_sample = number of samples in the data set: the value n</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co">        n_features = number of features or the dimension of the data set: the value d</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        n_sample,n_features <span class="op">=</span> X.shape</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.zeros(n_features) </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iterations):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            linear <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> <span class="va">self</span>._sigmoid(linear)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>            dw <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_sample)<span class="op">*</span> np.dot(X.T,(pred<span class="op">-</span>y))</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>            db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_sample) <span class="op">*</span> np.<span class="bu">sum</span>(pred<span class="op">-</span>y)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights <span class="op">=</span> <span class="va">self</span>.weights <span class="op">-</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dw </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bias <span class="op">=</span> <span class="va">self</span>.bias <span class="op">-</span> <span class="va">self</span>.learning_rate <span class="op">*</span> db</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        linear <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        predicted_y <span class="op">=</span> <span class="va">self</span>._sigmoid(linear)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        class_of_y <span class="op">=</span> [<span class="dv">0</span> <span class="cf">if</span> y<span class="op">&lt;=</span><span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">1</span> <span class="cf">for</span> y <span class="kw">in</span> predicted_y]</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> class_of_y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s use this using the <code>scikit-learn</code> breast cancer data set.</p>
<div id="3f666a11" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>b_cancer <span class="op">=</span> load_breast_cancer()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> b_cancer.data, b_cancer.target</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X,y, random_state<span class="op">=</span><span class="dv">123</span>, stratify<span class="op">=</span>y, test_size<span class="op">=</span><span class="fl">0.30</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>clf1 <span class="op">=</span> LogisticRegression1(learning_rate<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>clf1.fit(X_train, y_train)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> clf1.predict(X_test)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(accuracy_score(predicted_y, y_test),<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.91</code></pre>
</div>
</div>
<p>Now lets compare this with the standard <code>scikit-learn</code> library</p>
<div id="0c6f3a1e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>clf2 <span class="op">=</span> LogisticRegression()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>clf2.fit(X_train, y_train)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> clf2.predict(X_test)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(accuracy_score(predicted_y, y_test),<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.96</code></pre>
</div>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer.</li>
<li>Gradient descent is a widely used optimization technique in machine learning.</li>
<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</li>
<li>Nocedal, J., &amp; Wright, S. (2006). <em>Numerical Optimization</em> (2nd ed.). Springer.</li>
<li>Regularization techniques like L2 (Ridge) and L1 (Lasso) are commonly used in logistic regression to prevent overfitting.</li>
<li>Ng, A. (2004). <em>Feature Selection, L1 vs.&nbsp;L2 Regularization, and Rotational Invariance</em>. ICML Proceedings.</li>
<li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010). <em>Regularization Paths for Generalized Linear Models via Coordinate Descent</em>. Journal of Statistical Software, 33(1), 1-22.</li>
<li>The extension of logistic regression to multiclass classification via the softmax function is part of the core material for understanding classification tasks.</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</li>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>VanderPlas, J. (2016). <em>Python Data Science Handbook: Essential Tools for Working with Data</em>. O’Reilly Media.</li>
<li>Raschka, S., &amp; Mirjalili, V. (2017). <em>Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2</em>. Packt Publishing.</li>
</ul>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/logreg/" data-width="" data-numposts="5">

</div>
<hr>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1730178665986" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2269">
<a href="../../dsandml/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1728684641298" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../dsandml/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="../lda/lda.png" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1729137600000" data-listing-file-modified-sort="1729805911258" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="27" data-listing-word-count-sort="5383">
<a href="../../dsandml/lda/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../dsandml/lda/lda.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Linear Discriminant Analysis (LDA)
</h5>
<div class="listing-reading-time card-text text-muted">
27 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 17, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Classification: {Logistic} {Regression} - {A} {Comprehensive}
    {Guide} with {Mathematical} {Derivation} and {Python} {Code}},
  date = {2024-10-07},
  url = {https://mrislambd.github.io/dsandml/logreg/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Islam, Rafiq. 2024. <span>“Classification: Logistic Regression - A
Comprehensive Guide with Mathematical Derivation and Python
Code.”</span> October 7, 2024. <a href="https://mrislambd.github.io/dsandml/logreg/">https://mrislambd.github.io/dsandml/logreg/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrislambd\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-10-07"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Rafiq Islam</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Data Science, Machine Learning, Artificial Intelligence]</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span><span class="co"> true</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="an">search:</span><span class="co"> true</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> logreg.png</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="an">lightbox:</span><span class="co"> true</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="an">listing:</span><span class="co"> </span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">    contents: "/../../dsandml"</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">    max-items: 3</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">    type: grid</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">    categories: true</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">    date-format: full</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">    fields: [image, date, title, author, reading-time]</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span>  </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>Logistic Regression is a popular classification algorithm used for binary and multi-class classification problems. Unlike Linear Regression, which is used for regression problems, Logistic Regression is used to predict categorical outcomes. In binary classification, the output is either 0 or 1, and the relationship between the input features and the outcome is modeled using a logistic function (also called the sigmoid function).</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is Logistic Regression?  </span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>&lt;p style="text-align: justify"&gt;</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>Logistic Regression is a type of regression analysis used when the dependent variable is categorical. In binary logistic regression, the output can have only two possible outcomes (e.g., 0 or 1, pass or fail, spam or not spam).</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>&lt;br&gt;</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>Logistic Regression works by modeling the probability of an event occurring based on one or more input features. It estimates the probability that a given input belongs to a particular category (0 or 1) using the **logistic function (sigmoid function)**.</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Sigmoid Function</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>The sigmoid function maps any real-valued number to a value between 0 and 1, making it ideal for modeling probabilities.</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>The sigmoid function is given by the formula:</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>\sigma(z) = \frac{1}{1 + e^{-z}}</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>Where:  </span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$z$ is the input to the sigmoid function (in logistic regression, $z = \mathbf{x} \cdot \theta$)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$e$ is the base of the natural logarithm</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>The output of the sigmoid function is interpreted as the probability $P(y=1|X)$.</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic Regression Model</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>In Logistic Regression, the hypothesis is modeled as:</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>h_\theta(X) = \frac{1}{1 + e^{-\theta^T X}}</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>Where:  </span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$X$ is the input feature vector</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta$ is the parameter vector (weights)</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cost Function for Logistic Regression</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>&lt;p style = "text-align: justify"&gt;</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>Unlike Linear Regression, which uses the Mean Squared Error (MSE) as the cost function, Logistic Regression uses **log loss** or **binary cross-entropy** as the cost function, as the output is binary (0 or 1).</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>&lt;/p&gt;  </span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>So, basically we model probability from the given data. In other words, we can write </span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(y= 1 \text{ or }0 |\text{ given }X)&amp;=p(\mathbf{x})=\sigma(\mathbf{x}\cdot\theta)=\frac{1}{1+e^{-\mathbf{x}\cdot \theta}}<span class="sc">\\</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>\implies p_{\theta}(\mathbf{x})&amp; = \frac{1}{1+e^{-(\theta_0+\theta_1x_1+\cdots+\theta_dx_d)}}<span class="sc">\\</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>\implies p_{\theta}(\mathbf{x})&amp; = \begin{cases} </span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>                                p_{\theta}(\mathbf{x}) &amp; \text{ if } y=1<span class="sc">\\</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>                                1-p_{\theta}(\mathbf{x}) &amp; \text{ if } y=0</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>                          \end{cases}</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>\end{align*}  </span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>Where, $\mathbf{\theta},\mathbf{x}\in \mathbb{R}^{d+1}$ and $d$ is the dimension of the data. For single data vector $\mathbf{x}$ the binary cross-entropy function can be written as  </span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>l(\theta) = yp_{\theta}(\mathbf{x})+ (1-y)(1-p_{\theta}(\mathbf{x}))</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>$$  </span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>Since we have $n$ of those i.i.d data vectors therefore, we can write </span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>L(\theta) = \prod_{i=1}^{n} \left(y_ip_{\theta}(\mathbf{x_i})+ (1-y_i)(1-p_{\theta}(\mathbf{x_i}))\right)</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>$$  </span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>Since our goal is to minimize the loss, we need to perform derivatives of the loss function. Therefore, to change from the product form to addition form we take negative log of the above expression  </span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>\ell (\theta) = -\log{L(\theta)} = -\sum_{i=1}^{n}y_i\log{p_{\theta}(\mathbf{x})}+(1-y_i)\log{(1-p_{\theta}(\mathbf{x}))}</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>For the ease of calculation, let's rewrite the above equation in terms of $m$ and $b$ where $m\in \mathbb{R}^d = (\theta_1,\theta_2,\cdots,\theta_d)^T$ and $b\in \mathbb{R}$.</span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>\ell (\theta) = -\sum_{i=1}^{n}y_i\log{p_{m,b}(\mathbf{x})}+(1-y_i)\log{(1-p_{m,b}(\mathbf{x}))}</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>Where:  </span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$n$ is the number of training examples  </span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$m$ is the number of features</span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$y^{(i)}$ is the true label of the $i^{th}$ example</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$b$ is the bias for the $i^{th}$ example</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient Descent</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>To minimize the cost function and find the optimal values for $\theta$, we use **gradient descent**. We start from the last form of the loss function and convert this to a form that is easy to take the partial dervivatives.  </span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>\ell (\theta) &amp;= -\sum_{i=1}^{n}y_i\log{p_{m,b}(\mathbf{x})}+(1-y_i)\log{(1-p_{m,b}(\mathbf{x}))}<span class="sc">\\</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>              &amp;= -\sum_{i=1}^{n}y_i\log{(\sigma(mx_i+b))}+(1-y_i)\log{(1-\sigma(mx_i+b))}<span class="sc">\\</span></span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>              &amp;= -\sum_{i=1}^{n}y_i\log{(\sigma(mx_i+b))}+(1-y_i)\log{(\sigma(-(mx_i+b)))};\hspace{3mm}\text{ Since } 1-\sigma(x)=\sigma(-x)<span class="sc">\\</span></span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>              &amp;= -\sum_{i=1}^{n}y_i\left<span class="co">[</span><span class="ot">\log{(\sigma(mx_i+b))}-\log{(\sigma(-(mx_i+b)))}\right</span><span class="co">]</span>+\log{(-\sigma(mx_i+b))}<span class="sc">\\</span></span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>              &amp;= -\sum_{i=1}^{n}y_i\log{\left(\frac{\sigma(mx_i+b)}{\sigma(-(mx_i+b))}\right)}+\log{(-\sigma(mx_i+b))}<span class="sc">\\</span></span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>              &amp;= -\sum_{i=1}^{n}y_i(mx_i+b)+\log{(\sigma(-(mx_i+b)))};\hspace{3mm}\text{ Since }\frac{\sigma(x)}{-\sigma(x)}=e^x<span class="sc">\\</span></span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a>Now we again use the beautiful features of the sigmoid function  </span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>\frac{d\sigma(x)}{dx}&amp;=\frac{d}{dx}\left(\frac{1}{1+e^{-x}}\right)=\frac{e^{-x}}{\left(1+e^{-x}\right)^2}=\frac{1}{1+e^{-x}}\cdot \frac{e^{-x}}{1+e^{-x}}<span class="sc">\\</span></span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>&amp;=\sigma(x)\left(1-\frac{1}{1+e^{-x}}\right)=\sigma(x)(1-\sigma(x))<span class="sc">\\</span></span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>&amp;=\sigma(x)\sigma(-x)</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a>\end{align*}  </span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>Finally, we are ready to take the partial derivatives of the loss function with respect to $m$ and $b$,  </span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ell}{\partial m} &amp;= -\sum_{i=1}^{n}y_ix_i+\frac{1}{\sigma(-(mx_i+b))}\frac{d}{dx}(\sigma(-(mx_i+b)))<span class="sc">\\</span></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>&amp; =-\sum_{i=1}^{n}y_ix_i+\frac{1}{\sigma(-(mx_i+b))}\sigma(-(mx_i+b))\sigma(mx_i+b)(-x_i)<span class="sc">\\</span></span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>&amp; = -\sum_{i=1}^{n} x_i(y_i-\sigma(mx_i+b))<span class="sc">\\</span></span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>&amp; = \sum_{i=1}^{n}x_i(p_{m,b}(x_i)-y_i)=\sum_{i=1}^{n} x_i(\hat{y_i}-y_i)<span class="sc">\\</span></span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>&amp; = \mathbf{x_i}\cdot(\mathbf{\hat{y_i}}-\mathbf{y_i})<span class="sc">\\</span></span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a>\text{ and } &amp; <span class="sc">\\</span></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>&amp; <span class="sc">\\</span></span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ell}{\partial b} &amp; = -\sum_{i=1}^{n} y_i +\frac{1}{\sigma(-(mx_i+b))}\frac{d}{dx}(\sigma(-(mx_i+b)))<span class="sc">\\</span></span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>&amp; =  -\sum_{i=1}^{n} y_i - \frac{1}{\sigma(-(mx_i+b))}\sigma(-(mx_i+b))\sigma(mx_i+b)<span class="sc">\\</span></span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>&amp; = \sum_{i=1}^{n} p_{m,b}(x_i)-y_i= \sum_{i=1}^{n} \hat{y}_i-y_i<span class="sc">\\</span></span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a>&amp; = \hat{\mathbf{y}}_i-\mathbf{y}_i</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a>Using this gradient, we update the parameter vector $\theta$ iteratively:</span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>\theta_{j+1} := \theta_j - \alpha \nabla \ell (\theta_j)</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a>Where:  </span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\alpha$ is the learning rate</span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\nabla \ell (\theta_j)$ is the partial derivative of the cost function with respect to $\theta_j$ and </span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a>  \nabla \ell (\theta) = \begin{bmatrix}\sum_{i=1}^{n} \hat{y}_i-y_i <span class="sc">\\</span></span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a>  \sum_{i=1}^{n} x_i(\hat{y_i}-y_i) \end{bmatrix}  =\begin{bmatrix}\hat{\mathbf{y}}_i-\mathbf{y}_i <span class="sc">\\</span></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>  \mathbf{x_i}\cdot(\mathbf{\hat{y_i}}-\mathbf{y_i}) \end{bmatrix}= X^T(\hat{\mathbf{y}}_i-\mathbf{y}_i)=X^T(\sigma(X\vec{\theta})-\vec{y})</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python Code Implementation from Scratch</span></span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a>Here’s how to implement Logistic Regression from scratch in Python. We will use two different forms for our class  </span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegression1:</span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, learning_rate <span class="op">=</span> <span class="fl">0.1</span>, n_iterations <span class="op">=</span> <span class="dv">1000</span>):</span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a><span class="co">        Hyper Parameters</span></span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a><span class="co">        - learning_rate: learning rate; float; default 0.01</span></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a><span class="co">        - n_itearations: number of iterations; int; default 1000</span></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a><span class="co">        Model Parameters</span></span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a><span class="co">        - weights: weights of the features; float or int</span></span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a><span class="co">        - bias: bias of the model; float or int</span></span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iterations <span class="op">=</span> n_iterations </span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="va">None</span> </span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _sigmoid(<span class="va">self</span>, x):</span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>x))</span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X,y):</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a><span class="co">        n_sample = number of samples in the data set: the value n</span></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a><span class="co">        n_features = number of features or the dimension of the data set: the value d</span></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a>        n_sample,n_features <span class="op">=</span> X.shape</span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.zeros(n_features) </span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iterations):</span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a>            linear <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> <span class="va">self</span>._sigmoid(linear)</span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>            dw <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_sample)<span class="op">*</span> np.dot(X.T,(pred<span class="op">-</span>y))</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a>            db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_sample) <span class="op">*</span> np.<span class="bu">sum</span>(pred<span class="op">-</span>y)</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights <span class="op">=</span> <span class="va">self</span>.weights <span class="op">-</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dw </span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bias <span class="op">=</span> <span class="va">self</span>.bias <span class="op">-</span> <span class="va">self</span>.learning_rate <span class="op">*</span> db</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a>        linear <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a>        predicted_y <span class="op">=</span> <span class="va">self</span>._sigmoid(linear)</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a>        class_of_y <span class="op">=</span> [<span class="dv">0</span> <span class="cf">if</span> y<span class="op">&lt;=</span><span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">1</span> <span class="cf">for</span> y <span class="kw">in</span> predicted_y]</span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> class_of_y</span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a>Now let's use this using the <span class="in">`scikit-learn`</span> breast cancer data set.  </span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a>b_cancer <span class="op">=</span> load_breast_cancer()</span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> b_cancer.data, b_cancer.target</span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X,y, random_state<span class="op">=</span><span class="dv">123</span>, stratify<span class="op">=</span>y, test_size<span class="op">=</span><span class="fl">0.30</span>)</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a>clf1 <span class="op">=</span> LogisticRegression1(learning_rate<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>clf1.fit(X_train, y_train)</span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> clf1.predict(X_test)</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(accuracy_score(predicted_y, y_test),<span class="dv">2</span>))</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>Now lets compare this with the standard <span class="in">`scikit-learn`</span> library  </span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>clf2 <span class="op">=</span> LogisticRegression()</span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a>clf2.fit(X_train, y_train)</span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> clf2.predict(X_test)</span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(accuracy_score(predicted_y, y_test),<span class="dv">2</span>))</span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.</span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. Springer.</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gradient descent is a widely used optimization technique in machine learning.</span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). *Deep Learning*. MIT Press.</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Nocedal, J., &amp; Wright, S. (2006). *Numerical Optimization* (2nd ed.). Springer.</span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regularization techniques like L2 (Ridge) and L1 (Lasso) are commonly used in logistic regression to prevent overfitting.</span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ng, A. (2004). *Feature Selection, L1 vs. L2 Regularization, and Rotational Invariance*. ICML Proceedings.</span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010). *Regularization Paths for Generalized Linear Models via Coordinate Descent*. Journal of Statistical Software, 33(1), 1-22.</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The extension of logistic regression to multiclass classification via the softmax function is part of the core material for understanding classification tasks.</span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.</span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.</span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>VanderPlas, J. (2016). *Python Data Science Handbook: Essential Tools for Working with Data*. O'Reilly Media.</span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Raschka, S., &amp; Mirjalili, V. (2017). *Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2*. Packt Publishing.</span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a>**Share on**   </span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a>::::{.columns}</span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;"&gt;</span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands facebook size=3x &gt;}}</span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;"&gt;</span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands linkedin size=3x &gt;}}</span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a>:::{.column width="33%"}</span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>&lt;a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"&gt;</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a>{{&lt; fa brands twitter size=3x &gt;}}</span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a>&lt;/a&gt;</span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a>&lt;script src="https://giscus.app/client.js"</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>        data-repo="mrislambd/mrislambd.github.io" </span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>        data-repo-id="R_kgDOMV8crA"</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>        data-category="Announcements"</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>        data-category-id="DIC_kwDOMV8crM4CjbQW"</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>        data-mapping="pathname"</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>        data-strict="0"</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>        data-reactions-enabled="1"</span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>        data-emit-metadata="0"</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a>        data-input-position="bottom"</span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a>        data-theme="light"</span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a>        data-lang="en"</span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>        crossorigin="anonymous"</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>        async&gt;</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a>&lt;/script&gt;</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>&lt;div id="fb-root"&gt;&lt;/div&gt;</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a>&lt;script async defer crossorigin="anonymous"</span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a> src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"&gt;&lt;/script&gt;</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>&lt;div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/logreg/" data-width="" data-numposts="5"&gt;&lt;/div&gt;</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>**You may also like**  </span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Powered by <a href="https://quarto.org/">Quarto</a> 1.5.54</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024 @ Rafiq Islam
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license.txt">
<p>License</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/rafiqr35" target="_blank">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://youtube.com/@quanttube" target="_blank">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:rafiqfsu@gmail.com?subject&amp;body" target="_blank">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>
---
title: "Data Science & Machine Learning Basics"
date: "2024-09-20"
author: Rafiq Islam
categories: [Data Science, Machine Learning, Artificial Intelligence]
search: true
lightbox: true
image: ml.jpeg
listing: 
    contents: "/../../posts"
    max-items: 3
    type: grid
    categories: true
    date-format: full
    fields: [image, date, title, author, reading-time]
---  

<p align="center">
  <img src="/_assets/images/uc.jpeg" alt="Post under construction" width="400" height="400"/>
</p>

<p style="text-align: justify">
    This page is my personal repository of most common and useful machine learning algorithms using Python and other data science tricks and tips.
</p>  


## **$\text{Data Science}$**  
Data science involves extracting knowledge from structured and unstructured data. It combines principle from statistics, machine learning, data analysis, and domain knoledge to understand and interpret the data

#### Data Collection \& Accuisition  

- **[Web srcaping](/dsandml/datacollection/index.qmd){target="_blank" style="text-decoration:none"}:** Data collection through Webscraping  
- API integration  
- Data Lakes, Data Warehouse  

#### Data Cleaning \& Preprocessing  

This involves *[Handling Missing Values, Data Transformation](/codepages/titanic/index.qmd#handling-missing-data){target="_blank" style="text-decoration:none"}, [Feature Engineering](/dsandml/eda/index.qmd#feature-engineering){target="_blank" style="text-decoration:none"}, [Encoding Categorical Variables](/codepages/titanic/index.qmd){target="_blank" style="text-decoration:none"}, Handling Outliers*  

#### Exploratory Data Analysis (EDA)  

This usually includes the *[Descriptive Statistics](/dsandml/eda/index.qmd#discriptive-statistics){target="_blank" style="text-decoration:none"}, [Data Visualization, Identifying Patterns, Trends, Correlations](/dsandml/dataviz/index.qmd){target="_blank" style="text-decoration:none"}* of the features and labels.  
  
#### Statistical Methods  

- **[ANOVA - Categorical Features'](/dsandml/dataengineering/index.qmd){target="_blank" style="text-decoration:none"}:** How do we treat the categorical features for our data science project?
- Hypothesis Testing  
- Probability Distributions  
- Inferential Statistics  
- Sampling Methods  

#### Big Data Techniques  

- Hadoop, Spark  
- Distributed Data Storage  (e.g., HDFS, NoSQL)
- Data PipeLines, ETL (Extract, Transform, Load)

## **$\text{Machine Learning Algorithms}$**  

### $\text{Supervised Learning}$  
(Training with labeled data: input-output pairs)  

#### **Regression**  

::::{.grid}
:::{.g-col-6}
##### Parametric    

- [Simple Linear Regression](/dsandml/simplelinreg/index.qmd){target="_blank" style="text-decoration:none"}
- [Multiple Linear Regression](/dsandml/multiplelinreg/index.qmd){target="_blank" style="text-decoration:none"}
- [Polynomial Regression](/dsandml/polyreg/index.qmd){target="_blank" style="text-decoration:none"}
:::  

:::{.g-col-6}
##### Non-Parametric  

- [K-Nearest Neighbor (KNN) Regression](/dsandml/knn/index.qmd){target="_blank" style="text-decoration:none"}
- [Decesion Trees Regression](/dsandml/decisiontree/index.qmd){target="_blank" style="text-decoration:none"}
- [Random Forest Regression](/dsandml/randomforest/index.qmd){target="_blank" style="text-decoration:none"}
- [Support Vector Machine (SVM) Regression](/dsandml/svm/index.qmd){target="_blank" style="text-decoration:none"}
:::
::::  

#### **Classification**  

::::{.columns}
:::{.column width="33%"}
##### Parametric    

- [Logistic Regression](/dsandml/logreg/index.qmd){target="_blank" style="text-decoration:none"}
- [Naive Bayes](/dsandml/naivebayes/index.qmd){target="_blank" style="text-decoration:none"}
- [Linear Discriminant Analysis (LDA)](/dsandml/lda/index.qmd){target="_blank" style="text-decoration:none"}  
- Quadratic Discriminant Analysis (QDA)
:::  

:::{.column width="33%"}
##### Non-Parametric  

- [KNN Classification](/dsandml/knn/index.qmd){target="_blank" style="text-decoration:none"}
- [Decision Tree Classification](/dsandml/decisiontree/index.qmd){target="_blank" style="text-decoration:none"}
- [Random Forest Classification](/dsandml/randomforest/index.qmd){target="_blank" style="text-decoration:none"}
- [Support Vector Machine (SVM) Classification](/dsandml/svm/index.qmd){target="_blank" style="text-decoration:none"}
:::  

:::{.column width="33%"}
##### Multi-Class Classification  

- [Multi-class Classification](/dsandml/multiclass/index.qmd){target="_blank" style="text-decoration:none"}
:::  


:::{.column width="33%"}
##### Bayesian or Probabilistic Classification  

- [What is Bayesian or Probabilistic Classification?](/dsandml/bayesianclassification/index.qmd){target="_blank" style="text-decoration:none"}    
- [Linear Discriminant Analysis (LDA)](/dsandml/lda/index.qmd){target="_blank" style="text-decoration:none"}  
- Quadratic Discriminant Analysis (QDA)  
- Naive Bayes 
- Bayesian Network Classifier (Tree Augmented Naive Bayes (TAN))
:::  

:::{.column width="33%"}
##### Non-probabilistic Classification  

- [Support Vector Machine (SVM) Classification](/dsandml/svm/index.qmd){target="_blank" style="text-decoration:none"}  
- [Decision Tree Classification](/dsandml/decisiontree/index.qmd){target="_blank" style="text-decoration:none"}  
- [Random Forest Classification](/dsandml/randomforest/index.qmd){target="_blank" style="text-decoration:none"}  
- [KNN Classification](/dsandml/knn/index.qmd){target="_blank" style="text-decoration:none"}  
- Perceptron
:::
::::  


### $\text{Unsupervised Learning}$  
(Training with unlabeled data)  

::::{.columns}
:::{.column width="33%"}
##### Clustering      

- [k-Means Clustering](/dsandml/kmeans/index.qmd){target="_blank" style="text-decoration:none"}  
- Hierarchical Clustering  
- DBSCAN (Density-Based Spatial Clustering)  
- Gaussian Mixture Models (GMM)
:::  

:::{.column width="33%"}
##### Dimensionality Reduction  

- [Principal Component Analysis](/dsandml/pca/index.qmd){target="_blank" style="text-decoration:none"}  
- Latent Dirichlet Allocation (LDA)
- t-SNE (t-distributed Stochastic Neihbor Embedding)  
- Factor Analysis  
- Autoencoders  
:::  

:::{.column width="33%"}
##### Anomaly Detection  

- Isolation Forests  
- One-Class SVM
:::
::::    

### $\text{Semi-Supervised Learning}$  
(Combination of labeled and unlabeled data)  

- Self-training  
- Co-training  
- Label Propagation 

### $\text{Reinforcement Learning}$  
(Learning via rewards and penalties)  

- Markov Decision Process (MDP)  
- Q-Learning  
- Deep Q-Networks (DQN)  
- Policy Gradient Method  

## **$\text{Deep Learnings}$**  

- [PyTorch](/dsandml/pytorch/index.qmd){target="_blank" style="text-decoration:none"}  
- Artificial Neural Networks (ANN)  
- Convolutional Neural Networks (CNN)  
- Recurrent Neural Networks (RNN)  
- Long Short-Term Memory (LSTM)  
- Generative Adversarial Networks (GAN)  

## **$\text{Model Evaluation and Fine Tuning}$**  

#### Model Evaluation Metrics  

- **For Regression:** Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), $R^2$ score  
- **For Classification:** [Accuracy, Precision, Recall, F1 Score, ROC-AUC](/dsandml/classificationmetrics/index.qmd){target="_blank" style="text-decoration:none"}    
- **Cross-validation:** kFold, Stratified k-fold, leave-one-out  

#### Model Optimization  

- **Bias-Variance:** [Bias Variance Trade off](/dsandml/biasvariance/index.qmd){target="_blank" style="text-decoration:none"}  
- **Hyperparameter Tuning:** Grid Search, Random Search, Bayesian Optimization  
- **Features Selection Techniques:** Recursive Feature Elimination (RFE), [L1 or Rasso Regurlarization](/dsandml/regularization/index.qmd){target="_blank" style="text-decoration:none"}, [L2 or Ridge Regularization](/dsandml/regularization/index.qmd){target="_blank" style="text-decoration:none"}  
- **Model Interpretability:** SHAP (Shapley values), LIME (Local Interpretable Model-agnostic Explanations)  

#### Ensemble Methods  

- **Bagging:** [Random Forest](/dsandml/randomforest/index.qmd){target="_blank" style="text-decoration:none"}, Bootstrap Aggregating  
- **Boosting:** [Gradient Boosting](/dsandml/gradientboosting/index.qmd){target="_blank" style="text-decoration:none"}, AdaBoost, XGBoost, CatBoost  
- **Stacking:** Stacked Generalization


<!---
## Machine Learning Algorithms  

```{=html}
<style>
  tr:nth-child(even){
    background-color: #dddddd
  }
</style>
<table>
  <thead>
    <tr>
      <th> Learning Type </th>
      <th> Parametric </th>
      <th> Non-Parametric </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th> Supervised </th>
      <th>
        <ul>
          <li><a href="/dsandml/simplelinreg/index.qmd" style="text-decoration:none" target="_blank">Simple Linear Regression</a></li>
          <li><a href="/dsandml/multiplelinreg/index.qmd" style="text-decoration:none" target="_blank">Multiple Linear Regression</a></li>
          <li><a href="/dsandml/polyreg/index.qmd" style="text-decoration:none" target="_blank">Polynomial Regression</a></li>
          <li><a href="/dsandml/logreg/index.qmd" style="text-decoration:none" target="_blank">Logistic Regression</a></li>
          <li><a href="/dsandml/naivebayes/index.qmd" style="text-decoration:none" target="_blank">Naive Bayes</a></li>
        </ul>
      </th>
      <th> 
        <ul>
          <li><a href="/dsandml/knn/index.qmd" style="text-decoration:none" target="_blank">KNN Regression and Classification</a></li>
          <li><a href="/dsandml/decisiontree/index.qmd" style="text-decoration:none" target="_blank">Decision Trees</a></li>
          <li><a  href="/dsandml/randomforest/index.qmd" style="text-decoration:none" target="_blank">Random Forest</a></li>
          <li><a  style="text-decoration:none">Support Vector Machine (SVM)</a></li>
        </ul>
      </th>
    </tr>
    <tr>
      <th>Unsupervised </th>
      <th>
        <ul>
          <li><a href="/dsandml/pca/index.qmd" style="text-decoration:none" target="_blank">Principle Component Analysis (PCA)</a></li>
          <li><a  style="text-decoration:none">Gaussian Mixture Model (GMM)</a></li>
          <li><a  style="text-decoration:none">Latent Dirichilet Allocation (LDA)</a></li>
      </th>
      <th>
        <ul>
          <li><a  href="/dsandml/kmeans/index.qmd" style="text-decoration:none" target="_blank">K-Means</a></li>
          <li><a  style="text-decoration:none">Hierarchial Clustering</a></li>
          <li><a  style="text-decoration:none">Density-Based Spatial Clustering of Applications with Noise (DBSCAN)</a></li>
      </th>
    </tr>
    <tr>
      <th> Semi-Supervised </th>
      <th> Self-training</th>
    </tr>
    <tr>
      <th>Reinforcement Learning </th>
      <th>
        <ul>
          <li><a  style="text-decoration:none">Q-Learning</a></li>
          <li><a  style="text-decoration:none">DQN</a></li>
          <li><a  style="text-decoration:none">Policy Gradient</a></li>
      </th>
    </tr>
    <tr>
      <th>Dimensionality Reduction </th>
      <th>
        <ul>
          <li><a href="/dsandml/pca/index.qmd" style="text-decoration:none" target="_blank">Principle Component Analysis (PCA)</a></li>
          <li><a  style="text-decoration:none">Linear Discriminant Analysis (LDA)</a></li>
      </th>
      <th>
        <ul>
          <li><a  style="text-decoration:none">t-SNE</a></li>
          <li><a  style="text-decoration:none">Autoencoders</a></li>
      </th>
    </tr>
    <tr>
      <th>Ensemble Methods </th>
      <th>
        <ul>
          <li><a  style="text-decoration:none">Bagging</a></li>
          <li><a href="/dsandml/gradientboosting/index.qmd" style="text-decoration:none" target="_blank">Gradient Boosting</a></li>
      </th>
      <th>
        <ul>
          <li><a  style="text-decoration:none">Stacking</a></li>
      </th>
    </tr>
    <tr>
      <th>Deep Learning </th>
      <th>
        <ul>
          <li><a  style="text-decoration:none">Artificial Neural Networks (ANN)</a></li>
          <li><a  style="text-decoration:none">Convolutional Neural Networks (CNN)</a></li>
          <li><a  style="text-decoration:none">Recurrent Neural Networks (RNN)</a></li>
          <li><a  style="text-decoration:none">Long Short-Term Memory (LSTM)</a></li>
          <li><a  style="text-decoration:none">Generative Adversarial Networks (GAN)</a></li>
      </th>
    </tr>
  </tbody>
</table>
```  

## Data Science Techniques  
 

```{=html}
<style>
  tr:nth-child(even){
    background-color: #dddddd
  }
</style>
<table>
  <thead>
    <tr>
      <th>Techniques</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th><a href="/dsandml/dataengineering/index.qmd" style="text-decoration:none" target="_blank">Categorical Features</a></th>
      <th> How do we treat the categorical features for our data science project?</th>
    </tr>
    <tr>
      <th><a href="/dsandml/datacollection/index.qmd" style="text-decoration:none" target="_blank">Webscraping</a></th>
      <th>Data collection through Webscraping</th>
    </tr>
    <tr>
      <th><a href="/dsandml/biasvariance/index.qmd" style="text-decoration:none" target="_blank">Bias-Variance</a></th>
      <th>Model Fine Tuning: Bias-Variance Trade Off</th>
    </tr>
    <tr>
      <th><a href="/dsandml/regularization/index.qmd" style="text-decoration:none" target="_blank">Regularization</a></th>
      <th>Model Fine Tuning: Regularization</th>
    </tr>
  </tbody>
</table>
```

---  

-->

---

**You may also like**